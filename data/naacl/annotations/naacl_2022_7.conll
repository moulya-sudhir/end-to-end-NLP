-DOCSTART- O
Semantic B-MethodName
Diversity I-MethodName
in I-MethodName
Dialogue I-MethodName
with I-MethodName
Natural I-MethodName
Language I-MethodName
Inference I-MethodName

Generating O
diverse O
, O
interesting O
responses O
to O
chitchat O
conversations O
is O
a O
problem O
for O
neural O
conversational O
agents. O
This O
paper O
makes O
two O
substantial O
contributions O
to O
improving O
diversity O
in O
dialogue B-TaskName
generation. I-TaskName
First O
, O
we O
propose O
a O
novel O
metric O
which O
uses O
Natural B-TaskName
Language I-TaskName
Inference I-TaskName
( I-TaskName
NLI I-TaskName
) I-TaskName
to O
measure O
the O
semantic B-MetricName
diversity I-MetricName
of O
a O
set O
of O
model O
responses O
for O
a O
conversation. O
We O
evaluate O
this O
metric O
using O
an O
established O
framework O
( O
Tevet O
and O
Berant O
, O
2021 O
) O
and O
find O
strong O
evidence O
indicating O
NLI B-TaskName
Diversity B-MetricName
is O
correlated O
with O
semantic B-MetricName
diversity. I-MetricName
Specifically O
, O
we O
show O
that O
the O
contradiction O
relation O
is O
more O
useful O
than O
the O
neutral O
relation O
for O
measuring O
this O
diversity O
and O
that O
incorporating O
the O
NLI B-TaskName
model O
's O
confidence B-MetricName
achieves O
state-of-the-art O
results. O
Second O
, O
we O
demonstrate O
how O
to O
iteratively O
improve O
the O
semantic B-MetricName
diversity I-MetricName
of O
a O
sampled O
set O
of O
responses O
via O
a O
new O
generation O
procedure O
called O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
, O
which O
results O
in O
an O
average O
137 B-MetricValue
% I-MetricValue
increase O
in O
NLI B-MetricName
Diversity O
compared O
to O
standard O
generation O
procedures O
. O

Introduction O
Dialogue O
models O
often O
struggle O
to O
produce O
engaging O
utterances O
in O
conversations O
, O
tending O
to O
generate O
responses O
which O
are O
common O
in O
the O
training O
data O
, O
such O
as O
" O
OK O
, O
" O
" O
Yeah O
, O
" O
or O
" O
I O
do O
n't O
know O
" O
( O
Li O
et O
al. O
, O
2016 O
) O
. O
While O
these O
responses O
are O
appropriate O
for O
a O
wide O
variety O
of O
contexts O
, O
their O
over-production O
can O
result O
in O
a O
dull O
conversation O
( O
See O
et O
al. O
, O
2019 O
) O
. O

An O
evaluation O
task O
has O
emerged O
that O
consists O
of O
measuring O
the O
diversity B-MetricName
of O
chitchat O
model O
responses O
over O
a O
test O
set. O
While O
some O
past O
work O
uses O
human B-MetricName
evaluation I-MetricName
to O
measure O
model O
response O
diversity B-MetricName
according O
to O
engagingness B-MetricName
, O
specificity B-MetricName
, O
or O
interestingness B-MetricName
( O
Li O
et O
al. O
, O
2016 O
; O
See O
et O
al. O
, O
2019 O
; O
Ghandeharioun O
et O
al. O
, O
2019 O
) O
, O
several O
automated O
metrics O
have O
also O
been O
proposed O
to O
measure O
diversity O
of O
model O
responses. O
Some O
metrics O
measure O
lexical B-MetricName
diversity I-MetricName
, O
typically O
via O
n-gram B-MetricName
overlap I-MetricName
( O
Li O
Figure O
1 O
: O
Illustration O
of O
NLI O
Diversity O
using O
human O
responses O
from O
DailyDialog++. O
Contradictions O
are O
weighted O
by O
1 O
, O
entailments O
by O
-1 O
, O
and O
neutrals O
by O
0 O
, O
so O
the O
score O
is O
( O
2 O
× O
1 O
) O
+ O
( O
3 O
× O
0 O
) O
+ O
( O
1 O
× O
−1 O
) O
= O
1. O
et O
al. O
, O
2016 O
) O
or O
computing O
the O
BLEU B-MetricName
score O
( O
Zhu O
et O
al. O
, O
2018 O
) O
among O
model O
responses O
generated O
from O
the O
test O
set. O
Other O
past O
work O
attempts O
to O
measure O
semantic B-MetricName
diversity I-MetricName
via O
repurposing O
sentence B-MetricName
similarity I-MetricName
metrics O
( O
Tevet O
and O
Berant O
, O
2021 O
; O
Zhang O
et O
al. O
, O
2020a O
; O
Cer O
et O
al. O
, O
2017 O
) O
. O

We O
propose O
a O
new O
metric O
aimed O
at O
measuring O
semantic B-MetricName
diversity I-MetricName
by O
leveraging O
a O
Natural B-TaskName
Language I-TaskName
Inference I-TaskName
( I-TaskName
NLI I-TaskName
) I-TaskName
model O
to O
score O
a O
set O
of O
multiple O
dialogue O
model O
responses O
for O
a O
single O
conversation O
, O
as O
illustrated O
in O
Figure O
1. O
NLI B-TaskName
is O
a O
three-way O
classification O
task O
to O
determine O
whether O
one O
sentence O
entails O
, O
contradicts O
, O
or O
is O
neutral O
toward O
a O
second O
sentence. O
We O
hypothesize O
that O
a O
diverse O
set O
of O
responses O
for O
a O
conversation O
captures O
contradictory O
ways O
one O
could O
respond O
, O
which O
can O
be O
measured O
by O
the O
NLI B-TaskName
model. O
We O
aggregate O
the O
contradiction O
, O
neutral O
, O
and O
entailment O
predictions O
among O
pairs O
of O
responses O
from O
the O
set O
and O
combine O
the O
predictions O
into O
a O
new O
diversity O
metric O
, O
called O
NLI B-MetricName
Diversity I-MetricName
. O

We O
additionally O
explore O
two O
modifications O
of O
NLI B-MetricName
Diversity. I-MetricName
First O
, O
because O
the O
neutral O
prediction O
may O
be O
indicative O
of O
diversity O
, O
we O
propose O
Neutral B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
where O
neutral O
predictions O
are O
weighted O
the O
same O
as O
contradiction O
predictions. O
Second O
, O
since O
our O
Baseline O
NLI B-MetricName
Diversity I-MetricName
method O
does O
not O
take O
into O
account O
the O
confidence B-MetricName
of O
the O
model O
's O
prediction O
, O
we O
propose O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
which O
aggregates O
the O
probability O
mass O
of O
the O
model O
's O
predicted O
class O
instead O
of O
aggregating O
the O
number O
of O
predictions O
for O
each O
class O
. O

We O
assess O
NLI B-MetricName
Diversity I-MetricName
using O
Tevet O
and O
Berant O
( O
2021 O
) O
's O
diversity O
metric O
evaluation O
framework O
, O
finding O
that O
NLI B-MetricName
Diversity I-MetricName
is O
highly O
correlated O
both O
with O
human O
judgments O
of O
diversity B-MetricName
and O
with O
the O
diversity B-MetricName
parameter O
, O
a O
gold O
standard O
diversity B-MetricName
value O
used O
to O
generate O
the O
set O
of O
responses. O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
achieves O
state-of-the-art O
performance O
in O
terms O
of O
correlation O
with O
semantic B-MetricName
diversity. I-MetricName
Also O
, O
through O
an O
ablation O
study O
, O
we O
find O
positive O
, O
neutral O
, O
and O
negative O
correlations O
between O
human O
judgments O
and O
the O
number O
of O
contradiction O
, O
neutral O
, O
and O
entailment O
predictions O
, O
respectively O
. O

We O
next O
explore O
the O
use O
of O
a O
dialogue O
model O
to O
generate O
a O
set O
of O
candidate O
responses O
with O
a O
minimum O
target O
level O
of O
semantic B-MetricName
diversity I-MetricName
, O
such O
as O
10 B-MetricValue
Contradictions. O
Our O
new O
generation O
procedure O
, O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
, O
iteratively O
improves O
a O
set O
of O
model O
responses O
until O
this O
intended O
threshold O
is O
reached. O
If O
a O
set O
of O
sampled O
responses O
does O
not O
meet O
the O
intended O
threshold O
, O
the O
lowest-scoring O
response O
is O
thrown O
out O
and O
a O
new O
response O
is O
sampled O
until O
the O
diversity O
threshold O
is O
reached. O
We O
show O
this O
procedure O
results O
in O
a O
more O
diverse O
set O
of O
responses O
than O
the O
original O
sampled O
set O
, O
often O
with O
only O
a O
few O
resampled O
responses. O
Results O
of O
automated O
analysis O
shows O
relevancy O
is O
maintained O
from O
initial O
to O
final O
sets O
of O
responses O
. O

In O
summary O
, O
our O
contributions O
are O
: O
• O
A O
novel O
diversity O
metric O
, O
NLI B-MetricName
Diversity I-MetricName
, O
evaluated O
using O
Tevet O
and O
Berant O
( O
2021 O
) O

Measuring O
Model O
Response O
Diversity O
Traditionally O
, O
a O
model O
's O
diversity B-MetricName
has O
been O
measured O
in O
terms O
of O
its O
predictions O
over O
the O
test O
set O
( O
Li O
et O
al. O
, O
2016 O
) O
, O
which O
we O
call O
Test B-MetricName
Set I-MetricName
Diversity. I-MetricName
In O
this O
setup O
, O
the O
model O
predicts O
one O
response O
for O
each O
conversation O
in O
the O
test O
set O
( O
containing O
n O
conversations O
) O
, O
resulting O
in O
n O
predictions. O
The O
diversity B-MetricName
measure O
is O
computed O
over O
these O
n O
predictions O
, O
resulting O
in O
a O
score O
over O
the O
entire O
test O
set O
. O

The O
notion O
of O
diversity B-MetricName
we O
investigate O
, O
however O
, O
measures O
the O
model O
's O
ability O
to O
generate O
a O
set O
of O
responses O
for O
a O
single O
conversation O
Tevet O
and O
Berant O
, O
2021 O
) O
, O
which O
we O
call O
Multi-Response B-MetricName
Diversity. I-MetricName
Instead O
of O
generating O
one O
response O
for O
each O
of O
the O
conversations O
in O
the O
test O
set O
, O
we O
evaluate O
a O
model O
's O
ability O
to O
generate O
m O
responses O
for O
each O
of O
the O
n O
conversations O
. O

As O
shown O
by O
Tevet O
and O
Berant O
( O
2021 O
) O
, O
metrics O
which O
have O
been O
proposed O
in O
the O
Test B-MetricName
Set I-MetricName
Diversity I-MetricName
setting O
can O
still O
be O
applied O
in O
the O
Multi-Response O
Diversity O
setting O
, O
however O
, O
by O
treating O
each O
set O
of O
m O
responses O
as O
its O
own O
" O
test O
set O
" O
and O
averaging O
over O
the O
n O
total O
sets O
. O

Diversity O
Metrics O
Lexical B-MetricName
diversity I-MetricName
metrics O
measure O
differences O
in O
word O
choice O
, O
as O
opposed O
to O
diversity O
of O
content. O
Li O
et O
al. O
( O
2016 O
) O
propose O
distinct-n O
, O
which O
measures O
the O
number O
of O
unique O
n-grams O
generated O
divided O
by O
the O
total O
number O
of O
n-grams O
generated O
in O
the O
Test B-MetricName
Set I-MetricName
Diversity I-MetricName
setting. O
Some O
past O
work O
has O
applied O
this O
metric O
to O
the O
Multi-Response B-MetricName
Diversity I-MetricName
setting O
( O
Tevet O
and O
Berant O
, O
2021 O
) O
. O
Cao O
and O
Clark O
( O
2017 O
) O
propose O
examining O
the O
percent O
of O
unique O
responses O
over O
the O
test O
set. O
Other O
past O
work O
has O
proposed O
using O
BLEU B-MetricName
score O
over O
a O
set O
of O
model O
responses O
in O
the O
Test B-MetricName
Set I-MetricName
Diversity I-MetricName
setting O
( O
Zhu O
et O
al. O
, O
2018 O
) O
. O

Semantic B-MetricName
diversity I-MetricName
metrics O
, O
on O
the O
other O
hand O
, O
compare O
diversity B-MetricName
of O
the O
content O
present O
in O
each O
response. O
Many O
of O
these O
measures O
are O
adapted O
from O
semantic B-MetricName
similarity I-MetricName
scores I-MetricName
, O
since O
lower O
similarity B-MetricName
can O
indicate O
higher O
diversity B-MetricName
( O
Tevet O
and O
Berant O
, O
2021 O
) O
. O
BERTScore B-MetricName
measures O
the O
similarity O
of O
BERT O
embeddings O
for O
each O
token O
in O
two O
sentences O
( O
Zhang O
et O
al. O
, O
2020a O
) O
. O
Bert-STS B-MetricName
assigns O
a O
score O
based O
on O
the O
semantic B-MetricName
similarity I-MetricName
of O
two O
sentences O
( O
Tevet O
and O
Berant O
, O
2021 O
) O
. O
The O
Sent-BERT B-MetricName
metric O
computes O
cosine O
similarity O
between O
BERT O
sentence O
embeddings O
( O
Reimers O
and O
Gurevych O
, O
2019 O
) O
. O
Larson O
et O
al. O
( O
2019 O
) O
propose O
identifying O
diverse O
paraphrases O
by O
identifying O
embedding O
outliers O
. O

Other O
past O
work O
has O
used O
human B-MetricName
evaluation I-MetricName
to O
measure O
a O
model O
's O
diversity. B-MetricName
Li O
et O
al. O
( O
2016 O
) O
ask O
humans O
to O
choose O
the O
better O
of O
two O
responses O
based O
on O
specificity O
to O
the O
past O
conversation. O
See O
et O
al. O
( O
2019 O
) O
ask O
humans O
to O
rank O
dialogue O
responses O
on O
a O
variety O
of O
factors O
, O
including O
interestingness B-MetricName
and O
inquisitiveness. B-MetricName
Tevet O
and O
Berant O
( O
2021 O
) O
compare O
participants O
' O
ability O
to O
judge O
diversity B-MetricName
of O
a O
set O
of O
responses O
in O
two O
ways O
: O
( O
i O
) O
by O
ranking O
one O
response O
as O
more O
diverse O
than O
a O
second O
response O
and O
( O
ii O
) O
by O
judging O
the O
diversity O
of O
a O
single O
response O
on O
a O
Likert B-MetricName
scale I-MetricName
, O
finding O
that O
participants O
were O
equally O
able O
to O
judge O
diversity B-MetricName
in O
both O
conditions. O
They O
also O
find O
that O
human O
judges O
are O
better O
at O
distinguishing O
semantic B-MetricName
diversity I-MetricName
than O
lexical B-MetricName
diversity I-MetricName
. O

Other O
past O
work O
has O
incorporated O
diversity B-MetricName
metrics O
into O
the O
dialogue B-MethodName
dataset I-MethodName
creation I-MethodName
pipeline. I-MethodName
Stasaski O
et O
al. O
( O
2020 O
) O
propose O
a O
method O
which O
measures O
the O
diversity B-MetricName
of O
a O
crowdworker O
's O
contributions O
compared O
to O
a O
corpus O
, O
using O
that O
information O
to O
determine O
when O
to O
stop O
collecting O
data O
from O
the O
worker. O
This O
results O
in O
a O
more O
diverse O
dataset O
. O

Evaluation O
of O
Diversity B-MetricName
Metrics I-MetricName
Tevet O
and O
Berant O
( O
2021 O
) O
propose O
a O
framework O
to O
examine O
the O
reliability O
of O
diversity O
metrics. O
They O
propose O
the O
notion O
of O
a O
diversity O
parameter O
, O
which O
is O
used O
to O
generate O
a O
set O
of O
model O
responses O
, O
e.g. O
, O
the O
p-value O
in O
nucleus O
sampling O
, O
which O
specifies O
the O
vocabulary O
probability O
distribution O
cutoff O
used O
to O
restrict O
sampling O
to O
the O
most-likely O
words O
whose O
combined O
likelihood O
≥ O
p. O
If O
p O
is O
higher O
, O
the O
set O
of O
responses O
should O
have O
higher O
diversity B-MetricName
, O
and O
viceversa. O
This O
diversity O
parameter O
is O
treated O
as O
a O
gold O
standard O
for O
a O
set O
of O
responses O
' O
diversity. B-MetricName
Diversity B-MetricName
metrics O
assign O
scores O
in O
the O
Multi-Response B-MetricName
Diversity I-MetricName
condition O
and O
are O
evaluated O
in O
terms O
of O
correlation O
to O
the O
diversity O
parameter. O
They O
further O
propose O
two O
datasets O
to O
evaluate O
diversity O
metrics O
: O
one O
which O
includes O
model O
responses O
and O
contains O
varying O
levels O
of O
lexical B-MetricName
diversity I-MetricName
and O
one O
which O
is O
human-created O
and O
maintains O
high O
lexical B-MetricName
diversity I-MetricName
to O
allow O
focused O
evaluation O
of O
semantic B-MetricName
diversity I-MetricName
. O

Natural B-TaskName
Language I-TaskName
Inference I-TaskName
Natural B-TaskName
Language I-TaskName
Inference I-TaskName
is O
a O
task O
aimed O
at O
predicting O
whether O
one O
sentence O
contradicts O
, O
entails O
, O
or O
is O
neutral O
towards O
a O
second O
sentence. O
Models O
for O
NLI B-TaskName
are O
typically O
trained O
using O
one O
of O
two O
datasets O
: O
Stanford B-DatasetName
Natural I-DatasetName
Language I-DatasetName
Inference I-DatasetName
( O
SNLI B-DatasetName
) O
( O
Bowman O
et O
al. O
, O
2015 O
) O
or O
Multi-Genre B-DatasetName
NLI I-DatasetName
( O
MNLI B-DatasetName
) O
( O
Williams O
et O
al. O
, O
2018 O
) O
. O
More O
recent O
datasets O
include O
FEVER B-DatasetName
( O
Thorne O
et O
al. O
, O
2018 O
; O
Nie O
et O
al. O
, O
2019 O
) O
, O
adapted O
from O
a O
fact-checking O
dataset O
, O
and O
ANLI B-DatasetName
( O
Nie O
et O
al. O
, O
2020 O
) O
, O
collected O
in O
an O
adversarial O
human-in-the-loop O
procedure. O
With O
the O
rise O
of O
transformer O
architectures O
, O
models O
have O
achieved O
high O
performance O
on O
NLI B-TaskName
tasks O
( O
Liu O
et O
al. O
, O
2019 O
) O
. O

In O
a O
dialogue O
setting O
, O
NLI B-TaskName
has O
been O
used O
to O
improve O
consistency O
between O
a O
persona O
and O
model O
responses O
over O
the O
course O
of O
a O
conversation O
by O
integrating O
an O
NLI-based B-TaskName
reward O
into O
a O
reinforcement B-MethodName
learning I-MethodName
training I-MethodName
procedure O
( O
Song O
et O
al. O
, O
2020 O
) O
. O

To O
our O
knowledge O
, O
however O
, O
NLI B-TaskName
has O
not O
been O
used O
to O
measure O
the O
diversity B-MetricName
of O
model O
responses O
in O
either O
the O
Test B-MetricName
Set I-MetricName
Diversity I-MetricName
or O
the O
Multi-Response B-MetricName
Diversity I-MetricName
setting O
. O

Generating O
Diverse O
Sets O
of O
Hypotheses O
While O
work O
has O
only O
recently O
begun O
to O
explore O
the O
task O
of O
generating O
multiple O
dialogue O
responses O
to O
a O
conversation O
Tevet O
and O
Berant O
, O
2021 O
) O
, O
past O
work O
has O
explored O
generating O
diverse O
sets O
of O
hypotheses O
in O
some O
other O
application O
areas. O
Carbonell O
and O
Goldstein O
( O
1998 O
) O
explored O
using O
Maximal B-MethodName
Mutual I-MethodName
Relevance I-MethodName
to O
reduce O
redundancy O
without O
sacrificing O
relevancy O
in O
document B-TaskName
selection I-TaskName
for O
summarization. B-TaskName
Batra O
et O
al. O
( O
2012 O
) O
proposed O
a O
greedy O
iterative O
algorithm O
to O
generate O
diverse O
, O
probable O
hypotheses O
for O
multiple O
vision O
tasks. O
Most O
related O
to O
our O
work O
is O
Gimpel O
et O
al. O
( O
2013 O
) O
, O
which O
applied O
Batra O
et O
al. O
( O
2012 O
) O
's O
approach O
to O
machine B-TaskName
translation I-TaskName
, O
generating O
a O
set O
of O
translations O
instead O
of O
a O
single O
translation. O
In O
contrast O
to O
Gimpel O
et O
al. O
( O
2013 O
) O
, O
by O
holding O
the O
sampling O
procedure O
constant O
throughout O
the O
iterative O
process O
, O
our O
method O
can O
explore O
the O
extent O
to O
which O
diversity B-MetricName
can O
be O
increased O
without O
altering O
standard O
decoding O
practices O
. O

NLI B-MetricName
Diversity I-MetricName
Metric I-MetricName
We O
propose O
three O
diversity O
metrics O
in O
the O
Multi-Response B-MetricName
Diversity I-MetricName
setting O
which O
leverage O
the O
predictions O
of O
an O
NLI O
model. O
Two O
metrics O
( O
Baseline O
and O
Neutral O
) O
aggregate O
the O
NLI O
model O
's O
class O
predictions O
and O
one O
metric O
( O
Confidence O
) O
aggregates O
the O
weight O
of O
these O
predictions O
. O

Baseline O
NLI B-MetricName
Diversity I-MetricName
We O
propose O
a O
new O
metric O
, O
called O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
which O
uses O
an O
NLI B-TaskName
model O
's O
predictions O
to O
measure O
diversity. B-MetricName
More O
formally O
, O
for O
a O
given O
conversation O
, O
c O
, O
and O
a O
dialogue B-TaskName
generation I-TaskName
model O
M O
, O
a O
set O
of O
utterances O
u O
1 O
, O
... O
, O
u O
n O
is O
produced O
by O
the O
model. O
Each O
pair O
of O
utterances O
is O
compared O
in O
both O
directions O
using O
an O
NLI B-MetricName
model O
, O

N O
LI O
( O
u O
1 O
, O
u O
2 O
) O
, O
N O
LI O
( O
u O
2 O
, O
u O
1 O
) O
, O
... O
, O
N O
LI O
( O
u O
n O
, O
u O
n−1 O
) O
. O

The O
NLI B-TaskName
model O
predicts O
a O
distribution O
over O
the O
three O
potential O
classes O
: O
contradiction O
, O
neutral O
, O
and O
entailment. O
We O
take O
the O
argmax O
over O
these O
classes O
, O
resulting O
in O
a O
list O
of O
NLI B-TaskName
predictions O
, O

N O
LI O
preds O
( O
N O
LI O
( O
u O
1 O
, O
u O
2 O
) O
, O
... O
, O
N O
LI O
( O
u O
n−1 O
, O
u O
n O
) O
) O
of O
size O
n O
( O
n O
− O
1 O
) O
. O

To O
produce O
an O
overall O
diversity B-MetricName
score I-MetricName
for O
N O
LI O
preds O
( O
u O
1 O
, O
... O
, O
u O
n O
) O
, O
we O
assign O
each O
of O
these O
classes O
a O
value O
representing O
their O
diversity O
, O
denoted O
N B-MetricName
LI I-MetricName
score I-MetricName
( O
N O
LI O
preds O
( O
u O
1 O
, O
... O
, O
u O
n O
) O
) O
. O

We O
hypothesize O
that O
larger O
numbers O
of O
entailment O
predictions O
found O
in O
a O
set O
of O
model-generated O
utterances O
is O
indicative O
of O
a O
lack O
of O
diversity O
; O
similarly O
, O
larger O
number O
of O
contradiction O
predictions O
is O
indicative O
of O
a O
larger O
amount O
of O
diversity. O
Because O
we O
want O
a O
higher O
value O
of O
N B-MetricName
LI I-MetricName
score I-MetricName
to O
indicate O
higher O
diversity B-MetricName
, O
we O
assign O
values O
as O
: O

N B-MetricName
LI I-MetricName
score I-MetricName
= O
 O
 O
 O
 O
 O
1 O
if O
contradiction O
0 O
if O
neutral O
-1 O
if O
entailment O

The O
sum O
of O
the O
N B-MetricName
LI I-MetricName
score I-MetricName
values O
for O
the O
set O
of O
utterances O
results O
in O
the O
final O
NLI B-MetricName
Diversity I-MetricName
score I-MetricName
, O
formally O
defined O
as O
: O

Baseline B-MetricName
N I-MetricName
LIDiversity I-MetricName
= O
u O
i O
, O
u O
j O
∈u O
1 O
, O
... O
, O
un O
N B-MetricName
LI I-MetricName
score I-MetricName
( O
N O
LI O
pred O
( O
N O
LI O
( O
u O
i O
, O
u O
j O
) O
) O

While O
the O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
metric O
aggregates O
all O
classes O
, O
we O
also O
investigate O
the O
separate O
number O
of O
entailment O
, O
contradiction O
, O
and O
neutral O
predictions O
in O
N O
LI O
preds O
, O
denoted O
# O
Entailment O
, O
# O
Contradiction O
, O
and O
# O
Neutral O
, O
respectively O
. O

Neutral B-MetricName
NLI I-MetricName
Diversity I-MetricName
Our O
primary O
hypothesis O
is O
that O
contradictions O
indicate O
diversity O
and O
entailments O
indicate O
lack O
of O
diversity. B-MetricName
Because O
it O
is O
unclear O
what O
the O
role O
of O
neutrals O
might O
be O
, O
we O
explore O
a O
version O
of O
NLI B-MetricName
Diversity I-MetricName
which O
weights O
neutral O
and O
contradiction O
predictions O
as O
equally O
diverse. O
This O
metric O
is O
the O
same O
as O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
except O
the O
N B-MetricName
LI I-MetricName
score I-MetricName
used O
to O
assign O
values O
is O
: O

N B-MetricName
LI I-MetricName
score_neutral I-MetricName
= O
 O
 O
 O
 O
 O
1 O
if O
contradiction O
1 O
if O
neutral O
-1 O
if O
entailment O

Confidence B-MetricName
NLI B-MetricName
Diversity I-MetricName
Because O
the O
prior O
two O
NLI B-MetricName
Diversity I-MetricName
metrics O
do O
not O
incorporate O
the O
confidence O
of O
the O
NLI O
model O
's O
class O
predictions O
, O
we O
explore O
an O
additional O
metric O
which O
incorporates O
this O
value. O
Letting O
conf O
class O
( O
u O
1 O
, O
u O
2 O
) O
represent O
the O
model O
's O
probability O
mass O
assigned O
to O
the O
predicted O
NLI O
class O
after O
sof O
tmax O
, O
the O
function O
is O
defined O
as O
: O

N B-MetricName
LI I-MetricName
score_conf I-MetricName
idence I-MetricName
= O
 O
 O
 O
 O
 O
1 O
× O
conf O
con O
( O
u O
1 O
, O
u O
2 O
) O
if O
contradiction O
0 O
if O
neutral O
-1 O
× O
conf O
ent O
( O
u O
1 O
, O
u O
2 O
) O
if O
entailment O

Intuitively O
, O
instead O
of O
assigning O
a O
1 O
value O
for O
a O
contradiction O
prediction O
, O
this O
metric O
assigns O
the O
probability O
of O
the O
contradiction O
class. O
Likewise O
, O
instead O
of O
a O
-1 O
for O
an O
entailment O
prediction O
, O
this O
metric O
assigns O
the O
negative O
probability O
mass O
of O
the O
entailment O
class O
. O

Evaluation O
of O
NLI B-MetricName
Diversity I-MetricName
We O
evaluate O
NLI B-MetricName
Diversity I-MetricName
by O
computing O
the O
correlation O
between O
the O
metric O
and O
both O
human O
labels O
and O
diversity B-MetricName
parameter O
labels. O
Below O
we O
first O
describe O
the O
models O
and O
data O
and O
then O
present O
the O
results O
of O
the O
evaluation O
. O

Models O
We O
explore O
two O
NLI O
models O
: O
a O
Roberta-large B-MethodName
model O
( O
Liu O
et O
al. O
, O
2019 O
) O
Tevet O
and O
Berant O
( O
2021 O
) O
. O
Corresponding O
temperature B-HyperparameterValue
parameter O
( O
higher O
is O
more O
diverse O
) O
or O
semantic B-MetricName
and O
lexical B-MetricName
diversity I-MetricName
levels O
accompany O
each O
example. O
containing O
300M O
parameters. O
We O
refer O
to O
these O
models O
as O
NLI B-MethodName
Diversity I-MethodName
-MNLI I-MethodName
and O
NLI B-MethodName
Diversity I-MethodName
-Combined I-MethodName
, O
respectively. O
We O
do O
not O
employ O
additional O
fine-tuning O
of O
these O
models O
. O

Data O
There O
are O
two O
different O
English O
datasets O
released O
to O
evaluate O
diversity O
metrics O
in O
Tevet O
and O
Berant O
( O
2021 O
) O
: O
conTest B-DatasetName
and O
decTest B-DatasetName
, O
described O
in O
Table O
1. O
The O
conTest B-DatasetName
dataset O
is O
human-created O
and O
captures O
content O
, O
or O
semantic O
, O
diversity B-MetricName
independent O
of O
lexical B-MetricName
diversity. I-MetricName
Low-diversity O
examples O
in O
this O
dataset O
have O
high O
lexical B-MetricName
diversity I-MetricName
but O
low O
semantic B-MetricName
diversity. I-MetricName
This O
dataset O
was O
created O
by O
asking O
crowdworkers O
to O
generate O
sets O
of O
utterances O
with O
either O
low O
or O
high O
semantic B-MetricName
diversity I-MetricName
using O
varied O
language O
, O
in O
order O
to O
keep O
a O
high O
level O
of O
lexical B-MetricName
diversity I-MetricName
constant O
across O
both O
conditions O
. O

The O
decTest B-DatasetName
dataset O
includes O
model-generated O
responses O
, O
with O
diversity O
controlled O
by O
a O
decoding B-HyperparameterName
parameter O
, O
such O
as O
a O
temperature B-HyperparameterName
parameter. O
The O
dataset O
can O
include O
duplicate O
responses O
, O
and O
does O
not O
attempt O
to O
mediate O
lexical B-MetricName
diversity I-MetricName
; O
therefore O
, O
low-diversity O
examples O
in O
this O
dataset O
may O
reflect O
low O
lexical B-MetricName
as O
well O
as O
low O
semantic B-MetricName
diversity I-MetricName
. O

While O
the O
original O
dataset O
includes O
multiple O
generation O
tasks O
, O
we O
evaluate O
on O
the O
dialogue O
task O
, O
respGen B-TaskName
, O
which O
is O
drawn O
from O
Reddit O
conversations O
( O
Hashimoto O
et O
al. O
, O
2019 O
) O
3 O
. O
There O
are O
200 O
conversations O
for O
each O
of O
conTest B-DatasetName
and O
decTest B-DatasetName
for O
the O
respGen B-TaskName
task O
, O
with O
multiple O
responses O
for O
each O
conversation O
( O
5 O
for O
conTest O
, O
10 O
for O
decTest O
) O
. O

Diversity B-HyperparameterName
Parameter I-HyperparameterName
Correlation O
The O
diversity B-HyperparameterName
parameter I-HyperparameterName
from O
Tevet O
and O
Berant O
( O
2021 O
) O
represents O
either O
a O
parameter O
directly O
used O
to O
generate O
responses O
via O
a O
dialogue O
model O
, O
such O
as O
p O
in O
nucleus O
sampling O
, O
or O
a O
binary O
value O
indicating O
whether O
crowdworkers O
were O
instructed O
to O
generate O
a O
high-or O
low-diversity O
set O
of O
responses. O
A O
measure O
which O
is O
able O
to O
capture O
diversity O
will O
be O
positively O
correlated O
with O
this O
diversity O
parameter O
. O

Table O
2 O
shows O
Spearman O
's O
correlations O
between O
NLI B-MetricName
Diversity I-MetricName
and O
the O
diversity B-HyperparameterName
parameter. I-HyperparameterName
On O
the O
conTest B-DatasetName
semantic B-MetricName
diversity I-MetricName
dataset O
, O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
achieves O
the O
highest O
correlation O
of O
all O
metrics O
( O
0.62 O
) O
and O
approaches O
human O
performance. O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
performs O
comparably O
to O
the O
top-performing O
automatic O
metric O
from O
Tevet O
and O
Berant O
( O
2021 O
) O
, O
at O
0.59 B-MetricValue
correlation. O
We O
note O
the O
95 B-MetricValue
% I-MetricValue
confidence B-MetricName
intervals O
overlaps O
between O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
Sent-BERT B-MetricName
, O
and O
human B-MetricName
judgements I-MetricName
, O
indicating O
a O
lack O
of O
significant O
differences O
( O
see O
Appendix O
A O
) O
. O
Although O
Neutral B-MetricName
NLI I-MetricName
Diversity I-MetricName
does O
relatively O
poorly O
on O
conTest B-DatasetName
( O
0.24 O
) O
, O
it O
is O
the O
highest-performing O
NLI B-TaskName
metric O
on O
decTest O
( O
0.72 O
) O
, O
suggesting O
that O
incorporating O
neutral O
predictions O
may O
capture O
lexical O
instead O
of O
semantic B-MetricName
diversity I-MetricName
. O

A O
histogram O
of O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
values O
for O
low O
and O
high O
semantic B-MetricName
diversity I-MetricName
sets O
of O
responses O
is O
shown O
in O
Figure O
2. O
We O
note O
the O
lack O
of O
large O
overlap O
between O
the O
distributions O
of O
low O
and O
high O
semantic B-MetricName
diversity I-MetricName
data. O
In O
addition O
to O

Human B-MetricName
Correlation I-MetricName
In O
this O
subsection O
, O
we O
examine O
the O
NLI B-MetricName
Diversity I-MetricName
metric O
's O
correlation B-MetricName
to O
the O
human O
annotations O
collected O
by O
Tevet O
and O
Berant O
( O
2021 O
) O
. O
Each O
set O
of O
responses O
in O
conTest B-DatasetName
and O
decTest B-DatasetName
is O
scored O
by O
10 O
annotators O
from O
1 O
( O
not O
diverse O
at O
all O
) O
to O
5 O
( O
very O
diverse O
) O
with O
half-point O
increments. O
We O
compute O
correlation O
with O
respect O
to O
the O
averaged O
rating O
. O

In O
addition O
to O
NLI B-MetricName
Diversity I-MetricName
, O
we O
explore O
the O
prediction O
counts O
for O
each O
category. O
We O
expect O
that O
a O
higher O
# O
Entailment O
value O
will O
be O
negatively O
correlated O
with O
diversity B-MetricName
because O
the O
more O
pairs O
of O
responses O
that O
entail O
each O
other O
, O
the O
more O
similar O
the O
set O
of O
responses O
is. O
Similarly O
, O
we O
expect O
that O
a O
higher O
# O
Contradiction O
value O
will O
be O
positively O
correlated O
with O
diversity. O
Since O
the O
NLI B-MetricName
Diversity I-MetricName
metric O
incorporates O
both O
# O
Entailment O
and O
# O
Contradiction O
, O
we O
would O
expect O
this O
metric O
to O
be O
highly O
correlated O
with O
human O
judgments O
as O
well. O
Spearmean B-MetricName
's I-MetricName
ρ I-MetricName
rank I-MetricName
correlation O
results O
between O
our O
metrics O
and O
the O
human B-MetricName
diversity I-MetricName
scores I-MetricName
are O
shown O
in O
Table O
3. O
The O
highest-performing O
correlation O
for O
lexical B-MetricName
diversity I-MetricName
is O
the O
Neutral B-MetricName
NLI I-MetricName
Diversity I-MetricName
( O
0.69 B-MetricValue
) O
. O
The O
highest-performing O
semantic B-MetricName
diversity I-MetricName
correlation O
is O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
( O
0.64 B-MetricValue
) O
. O
Additionally O
, O
Baseline O
and O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
correlations O
are O
stronger O
when O
evaluating O
with O
the O
conTest B-DatasetName
dataset O
than O
the O
decTest B-DatasetName
dataset O
( O
an O
increase O
of O
0.48 B-MetricValue
to O
0.63 B-MetricValue
for O
Baseline B-MetricName
MNLI I-MetricName
and O
0.41 B-MetricValue
to O
0.64 B-MetricValue
for O
Confidence B-MetricName
NLI I-MetricName
) O
, O
indicating O
these O
metrics O
are O
more O
correlated O
with O
human O
ratings O
of O
semantic B-MetricName
diversity I-MetricName
than O
lexical B-MetricName
diversity I-MetricName
. O

Across O
both O
datasets O
, O
# O
Entailment O
is O
negatively O
correlated O
with O
diversity B-MetricName
, O
# O
Neutral O
does O
not O
have O
a O
strong O
correlation O
, O
and O
# O
Contradiction O
is O
positively O
correlated O
, O
as O
hypothesized. O
This O
supports O
our O
motivation O
to O
use O
NLI B-TaskName
as O
a O
diversity O
metric O
. O

Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
We O
have O
verified O
that O
NLI B-MetricName
Diversity I-MetricName
is O
both O
able O
to O
capture O
semantic B-MetricValue
diversity I-MetricValue
and O
aligns O
with O
human B-MetricValue
judgements. I-MetricValue
We O
can O
additionally O
use O
NLI B-MetricName
Diversity I-MetricName
to O
define O
a O
straightforward O
desired O
diversity O
threshold O
, O
div O
thresh O
for O
a O
set O
of O
model-generated O
responses O
, O
u O
1 O
, O
... O
, O
u O
n O
. O
For O
example O
, O
we O
might O
intend O
there O
to O
be O
10 O
Contradictions O
within O
the O
set. O
We O
propose O
a O
generation O
procedure O
, O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
, O
designed O
to O
iteratively O
increase O
the O
diversity O
of O
a O
set O
of O
responses O
for O
a O
conversation O
. O

For O
a O
conversation O
, O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
begins O
by O
sampling O
n O
responses. O
We O
score O
the O
diversity B-MetricName
of O
these O
responses O
using O
a O
diversity B-MetricName
metric O
, O
div_metric O
( O
u O
1 O
, O
... O
, O
u O
n O
) O
. O
If O
the O
diversity O
score O
falls O
above O
div O
thresh O
, O
the O
process O
is O
finished O
. O

If O
, O
however O
, O
the O
score O
falls O
below O
div B-HyperparameterName
thresh I-HyperparameterName
, O
we O
identify O
the O
model O
response O
which O
contributes O
least O
to O
the O
diversity O
score O
by O
calculating O
div_metric O
( O
u O
1 O
, O
... O
, O
u O
n−1 O
) O
for O
each O
sub-group O
of O
model O
responses O
of O
size O
n O
− O
1. O
We O
discard O
the O
model O
response O
not O
present O
in O
the O
highestscoring O
subgroup O
and O
resample O
a O
new O
response. O
We O
re-calculate O
div_metric O
( O
u O
1 O
, O
... O
, O
u O
n O
) O
and O
if O
div_metric O
( O
u O
1 O
, O
... O
, O
u O
n O
) O
> O
div B-HyperparameterName
thresh I-HyperparameterName
, O
the O
process O
finishes. O
We O
continue O
resampling O
until O
the O
maximum O
cutoff O
of O
S O
is O
reached O
. O

Evaluation O
of O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
Method O

Models O
and O
Datasets O
We O
experiment O
with O
two O
neural O
dialogue O
models O
, O
DialoGPT B-MethodName
( O
700M O
parameters O
) O
( O
Zhang O
et O
al. O
, O
2020b O
) O
4 O
and O
BlenderBot B-MethodName
1.0 O
( O
300M O
parameters O
) O
( O
Roller O
et O
al. O
, O
2021 O
) O
5 O
. O
We O
use O
the O
default O
Transformers O
implementation O
for O
each O
model O
( O
Wolf O
et O
al. O
, O
2020 O
) O
and O
do O
not O
fine-tune O
them. O
Runtime O
was O
between O
3 O
and O
36 O
hours O
on O
one O
Titan-X O
GPU O
. O

All O
experiments O
involve O
the O
dialogue O
model O
M O
generating O
5 O
responses O
for O
each O
conversation. O
The O
maximum O
number O
of O
samples O
, O
S O
, O
is O
set O
to O
20. O
All O
experiments O
are O
averaged O
over O
10 O
trials O
for O
stability O
. O

We O
evaluate O
each O
model O
on O
the O
development O
set O
of O
two O
public O
English O
conversational O
datasets O
: O
Dai-lyDialog++ B-DatasetName
( O
1,028 O
conversations O
) O
( O
Sai O
et O
al. O
, O
2020 O
; O
Li O
et O
al. O
, O
2017 O
) O
and O
EmpatheticDialogues B-DatasetName
( O
2,763 O
conversations O
) O
( O
Rashkin O
et O
al. O
, O
2019 O
) O
. O
DailyDia-log++ B-DatasetName
includes O
5 O
human-written O
responses O
per O
conversation O
, O
allowing O
for O
multi-reference O
comparison. O
We O
split O
each O
EmpatheticDialogues B-DatasetName
conversation O
at O
a O
random O
turn O
( O
consistent O
for O
all O
experiments O
) O
for O
generation. O
Since O
BlenderBot O
supports O
up O
to O
128 O
positional O
embeddings O
, O
we O
pass O
in O
the O
last O
128 O
tokens O
of O
the O
conversation O
for O
this O
condition O
. O

Metrics O
We O
evaluate O
three O
diversity O
metrics O
: O
two O
semantic O
diversity O
metrics O
, O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
( O
Section O
3 O
) O
and O
Sent-BERT B-MetricName
( O
Reimers O
and O
Gurevych O
, O
2019 O
; O
Tevet O
and O
Berant O
, O
2021 O
) O
, O
and O
one O
lexical O
diversity O
metric O
, O
distinct-n B-MetricName
( O
Li O
et O
al. O
, O
2016 O
; O
Tevet O
and O
Berant O
, O
2021 O
) O
. O
For O
Sent-BERT B-MetricName
, O
we O
compute O
the O
average B-MetricName
negative I-MetricName
cosine I-MetricName
similarity I-MetricName
between O
BERT O
sentence O
embeddings O
for O
each O
pair O
of O
responses. O
Like O
Tevet O
and O
Berant O
( O
2021 O
) O
, O
for O
distinct-n B-MetricName
, O
we O
compute O
the O
average O
distinct O
n-grams O
from O
n O
∈ O
1 O
, O
2 O
, O
3 O
, O
4 O
, O
5 O
. O

Because O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
is O
more O
humaninterpretable O
than O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
we O
use O
this O
version O
for O
experimentation. O
For O
all O
NLI B-TaskName
Diversity O
experiments O
, O
div B-HyperparameterName
thresh I-HyperparameterName
is O
achieved O
when O
# O
Contradictions O
is O
greater O
than O
10 O
out O
of O
a O
total O
of O
20 O
pair-wise O
comparisons. O
For O
both O
Sent-BERT B-MetricName
and O
distinct-n B-MetricName
, O
however O
, O
we O
do O
not O
have O
a O
humanspecifiable O
threshold. O
We O
use O
empirical O
thresholds O
measured O
from O
the O
sets O
of O
5 O
human O
responses O
for O
each O
conversation O
in O
DailyDialog++. B-DatasetName
We O
choose O
the O
90th B-HyperparameterValue
percentile I-HyperparameterValue
for O
div B-HyperparameterName
thresh I-HyperparameterName
( O
0.98 B-HyperparameterValue
and O
-0.179 B-HyperparameterValue
for O
distinct-n B-MetricName
and O
Sent-BERT B-MetricName
, O
respectively O
) O
. O

We O
decode O
using O
nucleus O
sampling O
( O
p O
= O
0.9 O
) O
, O
as O
it O
has O
been O
shown O
to O
increase O
response O
diversity O
( O
Holtzman O
et O
al. O
, O
2020 O
) O
. O
However O
our O
method O
could O
be O
applied O
with O
other O
decoding O
procedures O
. O

In O
order O
to O
robustly O
evaluate O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
, O
we O
measure O
both O
( O
i O
) O
whether O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
is O
able O
to O
generate O
more O
diverse O
sets O
of O
responses O
than O
was O
originally O
sampled O
and O
( O
ii O
) O
whether O
the O
increased O
diversity O
comes O
at O
the O
expense O
of O
decreased O
relevancy O
of O
the O
responses O
. O

Diversity O
Results O
We O
aim O
to O
measure O
whether O
the O
diversity O
of O
the O
5 O
responses O
from O
M O
increases O
using O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
, O
compared O
to O
the O
initial O
5 O
sampled O
responses. O
Diversity O
of O
the O
starting O
and O
ending O
sets O
of O
utterances O
is O
measured O
by O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
distinct-n B-MetricName
, O
or O
Sent-BERT. B-MetricName
We O
also O
report O
the O
number O
of O
sampled O
utterances O
required O
to O
reach O
div O
thresh O
. O
Results O
for O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
are O
shown O
in O
Table O
4. O
For O
every O
condition O
, O
we O
see O
an O
increase O
from O
starting O
to O
ending O
diversity O
; O
for O
NLI B-MetricName
Diversity I-MetricName
, O
this O
results O
in O
an O
average O
137 O
% O
increase. O
For O
most O
conditions O
, O
distinct-n B-MetricName
requires O
more O
samples O
than O
Sent-BERT B-MetricName
and O
Baseline O
NLI B-MetricName
Diversity I-MetricName
. O

We O
can O
use O
the O
results O
of O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
to O
probe O
differences O
in O
the O
models. O
In O
our O
experimental O
setup O
, O
DialoGPT B-MethodName
generates O
more O
diverse O
utterances O
across O
all O
conditions O
than O
BlenderBot. B-MethodName
The O
models O
change O
by O
similar O
proportions O
from O
starting O
to O
ending O
diversity O
using O
the O
NLI B-TaskName
metric. O
However O
, O
the O
starting O
diversity O
for O
BlenderBot B-MethodName
is O
far O
lower O
than O
DialoGPT B-MethodName
; O
the O
negative O
value O
for O
BlenderBot B-MethodName
indicates O
that O
a O
large O
number O
of O
entailment O
predictions O
were O
present O
in O
the O
starting O
response O
set O
. O

We O
can O
also O
examine O
differences O
between O
the O
datasets. O
For O
instance O
, O
we O
observe O
lower O
starting O
diversities O
for O
the O
Empathetic B-DatasetName
Dialogues I-DatasetName
dataset O
than O
for O
DailyDialog++ B-DatasetName
for O
both O
models. O
Additionally O
, O
the O
number O
of O
samples O
required O
for O
Em-patheticDialogues B-DatasetName
is O
consistently O
higher O
than O
for O
DailyDialog++. B-DatasetName
This O
is O
likely O
because O
div O
thresh O
for O
both O
datasets O
was O
calculated O
using O
human O
responses O
from O
DailyDialog++ B-DatasetName
, O
since O
EmpatheticDialogues B-DatasetName
does O
not O
include O
multiple O
human O
responses O
. O

Sampled O
responses O
can O
be O
seen O
in O
Appendix O
B O
and O
results O
reporting O
the O
average O
overlap O
from O
starting O
to O
ending O
sets O
of O
responses O
is O
in O
Appendix O
C. O
Appendix O
D O
includes O
results O
using O
beam O
search O
instead O
of O
nucleus O
sampling O
, O
and O
Appendix O
E O
reports O
the O
stability B-MetricName
of O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
. O

Relevance O
Results O
Since O
past O
work O
has O
documented O
a O
tradeoff O
between O
diversity B-MetricName
and O
relevancy B-MetricName
, O
we O
also O
report O
results O
for O
the O
relevancy O
of O
the O
starting O
and O
ending O
sets O
of O
responses O
for O
Diversity B-MethodName
Threshold I-MethodName
Generation. I-MethodName
We O
use O
two O
established O
relevancy O
metrics O
: O
BLEU B-MetricName
Score O
( O
Papineni O
et O
al. O
, O
2002 O
) O
6 O
and O
BERTScore B-MetricName
( O
Zhang O
et O
al. O
, O
2020a O
) O
7 O
. O
We O
show O
results O
on O
DailyDialog++ B-DatasetName
, O
which O
has O
multiple O
human-generated O
responses O
for O
comparison O
, O
which O
is O
more O
correlated O
to O
human O
judgements O
than O
single-reference O
evaluation O
( O
Gupta O
et O
al. O
, O
2019 O
) O
. O

Results O
are O
shown O
in O
Table O
5. O
The O
key O
takeaway O
is O
that O
the O
relevancy O
values O
remain O
virtually O
unchanged O
when O
using O
the O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
procedure O
, O
according O
to O
both O
BLEU B-MetricName
score O
and O
BERTScore. B-MetricName
The O
average O
percent O
difference O
is O
0.08 O
% O
for O
BertScore B-MetricName
and O
1.1 O
% O
for O
BLEU B-MetricName
. O

Conclusion O
We O
propose O
a O
novel O
semantic O
diversity O
metric O
, O
NLI B-MetricName
Diversity I-MetricName
, O
which O
is O
highly O
correlated O
to O
human O
judgments. O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
achieves O
state-ofthe-art O
results O
on O
measuring O
semantic O
diversity. O
We O
propose O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
to O
incentivize O
production O
of O
diverse O
sets O
of O
responses O
for O
a O
conversation. O
This O
results O
in O
more O
diverse O
sets O
of O
responses O
than O
originally O
sampled O
for O
multiple O
models O
, O
datasets O
, O
and O
metrics O
while O
maintaining O
relevancy O
, O
and O
can O
also O
be O
used O
to O
investigate O
a O
model O
's O
ability O
to O
produce O
diverse O
responses O
. O

A O
Confidence O
Interval O
Analysis O
We O
perform O
experimentation O
using O
bootstrapping O
to O
determine O
confidence B-MetricName
intervals O
for O
conTest B-DatasetName
correlations O
to O
the O
diversity O
parameter. O
We O
sample O
a O
dataset O
of O
110 O
elements O
( O
50 O
% O
of O
the O
original O
con-Test B-DatasetName
dataset O
's O
size O
) O
from O
conTest B-DatasetName
with O
replacement O
and O
compute O
corresponding O
Spearman B-MetricName
's I-MetricName
correlation I-MetricName
values O
using O
the O
sampled O
dataset O
for O
Sent-BERT B-MetricName
, O
Baseline B-MetricName
NLI I-MetricName
Diversity I-MetricName
, O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
, I-MetricName
and O
human B-MetricName
judgements. I-MetricName
We O
repeat O
this O
process O
1,000 O
times O
for O
stability B-MetricName
and O
calculate O
95 B-MetricValue
% I-MetricValue
Confidence B-MetricName
Intervals. O
The O
full O
conTest B-DatasetName
correlation O
value O
plotted O
with O
these O
intervals O
can O
be O
seen O
in O
Figure O
3. O
While O
the O
Confidence O
Interval O
values O
overlap O
between O
all O
4 O
conditions O
, O
the O
Confidence B-MetricName
NLI I-MetricName
Diversity I-MetricName
distribution O
closely O
matches O
the O
human O
distribution O
. O

B O
Sampled O
Responses O
Table O
7 O
shows O
randomly-sampled O
examples O
from O
the O
DailyDialog++ B-DatasetName
dataset O
, O
created O
using O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
with O
the O
DialoGPT B-MethodName
model O
and O
NLI B-MetricName
Diversity O
as O
the O
intended O
div_metric O
. O

C O
Average B-MetricName
Utterance I-MetricName
Overlap I-MetricName
We O
measure O
the O
number O
of O
utterances O
which O
occur O
in O
both O
the O
starting O
and O
ending O
sets O
of O
responses O
, O
called O
utterance B-MetricName
overlap. I-MetricName
A O
high O
utterance O
overlap O
represents O
a O
set O
of O
responses O
which O
did O
not O
need O
to O
be O
significantly O
changed O
to O
reach O
div B-HyperparameterName
thresh I-HyperparameterName
. O
For O
example O
, O
an O
utterance B-MetricName
overlap I-MetricName
of O
4 B-MetricValue
indicates O
that O
only O
1 O
response O
needed O
to O
be O
resampled O
( O
potentially O
multiple O
times O
) O
from O
the O
starting O
set O
to O
reach O
div B-HyperparameterName
thresh I-HyperparameterName
. O
Results O
are O
seen O
in O
Table O
6. O
Keeping O
in O
mind O
that O
higher O
Average O
Overlap O
indicates O
less O
resampling O
was O
needed O
, O
we O
note O
higher O
overlap O
for O
DialoGPT B-MethodName
than O
BlenderBot B-MethodName
1.0 I-MethodName
( O
with O
the O
exception O
of O
distinct-n B-MetricName
and O
EmpatheticDialogues B-DatasetName
) O
. O

D O
Beam O
Search O
We O
evaluate O
beam O
search O
's O
ability O
to O
generate O
diverse O
utterances O
using O
Diversity B-MethodName
Threshold I-MethodName
Generation I-MethodName
for O
DailyDialog++ B-DatasetName
and O
NLI B-TaskName
Diversity. B-MetricName
To O
compare O
nucleus O
sampling O
to O
beam O
search O
, O
we O
generate O
25 O
beams O
and O
consider O
these O
responses O
from O
most O
to O
least O
probable O
, O
i.e. O
if O
the O
5 O
most O
likely O
beams O
do O
not O
satisfy O
the O
diversity O
threshold O
, O
we O
remove O
the O
lowest-scoring O
beam O
and O
replace O
it O
with O
the O
6th O
most O
likely O
beam. O
We O
find O
the O
starting O
NLI B-MetricName
Diversity I-MetricName
for O
beam O
search O
is O
-5.05 B-MetricValue
, O
the O
ending O
diversity O
is O
5.35 B-MetricValue
, O
and O
an O
average O
of O
10.97 O
sampled O
utterances O
is O
required. O
While O
the O
NLI B-TaskName
Diversity B-MetricName
does O
improve O
from O
the O
starting O
to O
ending O
set O
of O
responses O
, O
beam O
search O
has O
a O
much O
lower O
ending O
diversity O
than O
nucleus O
sampling. O
While O
past O
work O
has O
confirmed O
that O
nucleus O
sampling O
is O
more O
lexically O
diverse O
than O
beam O
search O
using O
Self-BLEU B-MetricName
( O
Holtzman O
et O
al. O
, O
2020 O
) O
, O
our O
results O
confirm O
that O
nucleus O
sampling O
is O
also O
able O
to O
generate O
more O
semantically O
diverse O
utterances O
. O