Putting the Con in Context: Identifying Deceptive Actors in the Game of Mafia
While neural networks demonstrate a remarkable ability to model linguistic content, capturing contextual information related to a speaker's conversational role is an open area of research. In this work, we analyze the effect of speaker role on language use through the game of Mafia, in which participants are assigned either an honest or a deceptive role. In addition to building a framework to collect a dataset of Mafia game records, we demonstrate that there are differences in the language produced by players with different roles. We confirm that classification models are able to rank deceptive players as more suspicious than honest ones based only on their use of language. Furthermore, we show that training models on two auxiliary tasks outperforms a standard BERT-based text classification approach. We also present methods for using our trained models to identify features that distinguish between player roles, which could be used to assist players during the Mafia game.
Introduction Correct interpretation of language must take into account not only the meaning of utterances, but also characteristics of the speaker and the context in which their utterances are produced. Modeling the impact of this context on language is still challenging for NLP systems. For example, differences in language identification accuracy, speech recognition word error rates, and translation quality have been observed on the basis of attributes such as a speaker's gender, race, dialect, or role (Blodgett and O'Connor, 2017;Tatman and Kasten, 2017;Tatman, 2017;Stanovsky et al., 2019). Moreover, these systems systematically underperform on data generated by those in the minority, having implications for the ethics and fairness of using these technologies. * Equal contribution. This work explores language used for deception: a type of speaker context that is particularly challenging to model because it is intentionally hidden by the speaker. To do so, we collect and release a set of records for the game of Mafia, in which each player is assigned either an honest or a deceptive role. Then, we develop models that distinguish players' roles based only on the text of the players' dialog. We describe two auxiliary tasks that improve classification accuracy over a BERT-based text classifier.
The novel contributions of this paper include:
1. A methodology for collecting records of online Mafia games and a dataset collected from 460 human subjects, 2. Three classification models that can distinguish between honest and deceptive players,
3. An approach for identifying features of the game dialog text that can be used to help identify deceptive players during the game.
The task of identifying deception in dialog is far from solved. Our classification methods, while not accurate enough to reliably identify deceptive players in a game, do show that the text of a dialog in the setting we study does contain information about the roles of the participants, even when those participants are motivated to hide those characteristics by deceiving the listener. Although the models and results described in this work only apply to a particular game setting rather than dialog in general, the approaches we describe are general in character and therefore may inform future work on determining speaker roles from the contents of dialog.
Dataset A total of 460 English-speaking participants based in the United States were recruited from Amazon Mechanical Turk using the experiment platform Dallinger 1 . Between 4 and 10 participants were recruited for each Mafia game: 1 to 2 participants were designated mafia, and the rest were bystanders. Forty-four of these Mafia games are included in the final analysis. Participants were paid $2.50 for completing the task, plus bonuses for time spent waiting for other participants to arrive in a chatroom to begin the experiment. Waiting was paid at $5/hour.
Upon recruitment, participants were shown a consent form, per IRB approval, followed by an instructional video and accompanying transcript describing how to play the text-based Mafia game using an interface we developed (see Appendix). After they completed a quiz demonstrating they understood the information, they entered a waiting room until the desired number of participants was reached. Participants were then assigned a role (mafioso or bystander) and fake name, after which they began playing the game.
The game dynamics were as follows. Each mafia member was aware of the roles of their fellow mafia members and thus, by process of elimination, knew the roles of the bystanders. However, the bystanders did not know the true role of anyone else in the game. The goal of the mafia was to eliminate bystanders until the number of mafia was greater than or equal to that of the bystanders. The goal of the bystanders was to identify and eliminate all of the mafia members. Since the incentive structure was set up such that bystanders benefited from true beliefs about who the mafia members were, whereas mafia members benefited from false beliefs, bystanders were thus motivated to be honest actors, whereas mafia members were motivated to M and B denote the mafioso and bystander classes, respectively, while T denotes the total number for both groups. The last row shows the distribution of roles among the players with no utterances throughout the game. Note that nearly all of the no-utterance players are bystanders.
be deceptive actors in the Mafia game. The game proceeded in phases, alternating between nighttime and daytime (Figure 1). During the nighttime, mafia members could secretly communicate to decide on who to eliminate, after which they discretely voted, and the person with the majority vote was eliminated from the game. If there was a tie, one of the people involved in the tie was randomly chosen to be eliminated. During the daytime, everyone was made aware of who was eliminated during the nighttime, and then all players could openly communicate to decide who to eliminate. All the players then voted publicly, and the person with the majority vote was eliminated and announced to be a bystander or mafioso. Thus, during the nighttime mafia could secretly communicate and eliminate anyone, whereas during the daytime mafia could participate in the voting and communication protocols in the same way as bystanders. The game proceeded until there was a winning faction according to the goals described above.
From these experiments, we collected a dataset consisting of both mafia and bystander utterances over the course of each game, as well as the participants' voting behavior. Dataset statistics appear in Table 1. Figure 2 displays a snippet of the daytime dialog from one Mafia game. As shown, many utterances are either social interactions (eg. "hi erybody") or discussions about what to do in the game, such as accusations or comments about voting (eg. "I bet it's Mandy...").
Upon further inspection of the data, we can observe several strategies used by mafia members to deceive bystanders: Figure 1: Mafia experiment screenshot during (left) first nighttime phase, with participant as a mafioso, and (right) first daytime phase, with participant as a bystander (note that mafia messages are not visible to the bystander).
1. Mafia members may suggest that there is not enough information to decide on who to eliminate, despite their knowledge of everyone's roles (eg. "Should we wait to eliminate someone?" / "It's a little early to tell." / "It's a shot in the dark."), 2. Mafia members may raise suspicion about another player, despite knowing that said player is a bystander (eg. hmm ok analyzing this conversation....I think bianca was a little to flippant in how she was like "sucks to be andrew" haha / I'm going to vote bianca. she's so casual with life and death), 3. Mafia members may invent a false motive and assign that motive to another player, despite knowing that the player is a bystander (eg. It might be Jonathan Kim... killing off Erin who accused him "yesterday").
Approach Given our mafia dataset, there are several tasks that one might address, for example, predicting participants' daytime voting behavior or generating mafia members' nighttime dialog. As our aim is to identify deceptive actors, however, we focus on predicting participants' roles, i.e. bystander or mafioso. Due to the asymmetry in the knowledge available to each group and the goals which incentivize bystanders to increase true belief and mafia members to reduce it, the bystanders are said to take on an honest role in the game, whereas the mafia members take on a deceptive role. To focus on the relationship between language and deception, we ignore voting behavior and consider just the daytime dialog in the game, as only the mafia members were able to converse during the nighttime. As shown in Table 1, since most of the players with no utterances are bystanders, we only consider players who make at least one utterance throughout the game.
To investigate whether linguistic information can be used to identify players' roles, we train and evaluate classifiers that predict the role of a particular player. Since we have a small dataset, we chose to fine-tune pre-trained Transformer models rather than train them from scratch (Vaswani et al., 2017). To predict the role for a player p, we construct an input representation r(C, p) of the full game dialog C that encodes the player of interest p. We develop three approaches which differ in both the dialog representation function r and the modeling approach.
Standard Classification Our baseline approach uses a standard BERT-based text classifier (Devlin et al., 2018). To classify player p via the full record of the game C, let boolean variable M p be true if p is a mafioso. Let T p be the concatenation 2 of utterances made by p. We train BERT parameters θ M to predict
P (M p |T p ; θ M ).
This approach, which provides as input to the classifier only the utterances of the player to be classified, outperformed an alternative representation r(C, p) that included the entire record of all utterances by all players. 
Auxiliary Tasks Limiting the input representation r to contain only the speech of the player p being classified is not ideal; correctly interpreting a dialog requires considering all other players' statements as well. We introduce two auxiliary tasks that involve the entire game dialog C:
1. Given all of the prior utterances, is a bystander or a mafia member more likely to have produced the current utterance? (Utterance Classification)
2. Given all of the prior utterances, what current utterance would a player produce, given that they are a bystander or a mafia member? (Utterance Generation)
We develop a BERT-based classification model for task 1 and fine-tune the GPT-2 language model for task 2 (Radford et al., 2019). Then, we use each of these auxiliary models to classify the role of a particular player p in the game.
Utterance Classification To classify player p using the auxiliary task of utterance classification, let boolean variable S i be true if utterance C i was made by a mafioso (rather than a bystander). Let C be the full record of utterances in the game and C ≤i be the concatenation of all utterances C 1 . . . C i . We train BERT parameters θ S to predict P (S i |C ≤i ; θ S ). Finally, let I p be the set of indices of utterances by player p. M relates to S in that if M p is true, then S i is true for all i ∈ I p . We thus calculate
P (M p |C; θ S ) ∝ i∈Ip P (S i |C ≤i ; θ S ) N ,
where N = |I p |. The original data is shown on the left-hand side, while the right-hand side shows the processed data containing two versions of each utterance, one assuming that the target player is a mafioso and one assuming that they are a bystander, with the prior conversation context preceding each and labels corresponding to whether the assumed role matches the actual role of the player.
Utterance Generation To classify player p using the auxiliary task of utterance generation, we fine-tune GPT-2 to generate utterance C i conditioned on prior utterances C <i and the role S i of the speaker that produced C i . From Bayes' rule, we have P (M p |C) ∝ P (M p )P (C|M p ). To estimate P (C|M p ), let C p include all C i for i ∈ I p . We make the simplifying assumption that P (C|M p ) ∝ P (C p |M p ), which assumes that the utterances made by players other than p are independent of the role of player p. Then, if M p is true, S i is true for all i ∈ I p , and so,
P (C p |M p ; θ C ) = i∈Ip P (C i |C <i , S i ; θ C ).
Using the full dialog C, the final probability of player p being mafioso is calculated as follows:
P (M p |C) = P (M p )P (C p |M p ; θ C ) R∈{M,¬M } P (R p )P (C p |R p ; θ C )(1)
Figure 4: Data processing for fine-tuning GPT-2. The original data is shown on the left-hand side, while the right-hand side shows the processed data containing a version of the corresponding utterance with the prior conversation context preceding.
Figure 5: Prediction pipeline for our fine-tuned GPT-2 model. Similar to the pipeline used to produce the training utterances, for prediction, there are now two versions of each, one assuming that the target player is a mafioso and one assuming that they are a bystander.
The losses for each utterance of the target player are summed together in order to calculate the mafia and bystander probabilities as described in Equation 1.
Data Processing To train models for utterance classification (using BERT) and utterance generation (using GPT-2), we perform data processing procedures on the games' original dataset to create input representations r(C, p) for each player p and obtain our training datasets as shown in Figures 3 and 4. The left side of each figure shows a snippet of a game's data, where "Mafioso" and "Bystander" denote the true roles of the players. The utterances to the right of each figure are training examples used for finetuning the BERT and GPT-2 models. Structuring the data in this way provides both the prior context of utterances and the current utterance that happened within this context. This not only gives us the information needed for the auxiliary tasks, but also provides us with more training examples, as we only have 44 games and only 421 players in total, with only 2162 total utterances. Moreover, this mimics the real game scenario from the bystander view in that they can only confirm their own role, but no one else's, which is the appropriate setting for us in which to detect deception. Figure 5 shows the pipeline for using the GPT-2 model to predict players' roles. Let us assume that the target player for whom we want to predict their role is Mafioso 1. From the original game log on the left, we first perform the data processing scheme from Figure 4 twice, assuming that the target player is a mafioso (top of Figure 5) and a bystander (bottom of Figure 5). Using our trained GPT-2 model, we then obtain a loss for each utterance denoted by L1 through L4. Summing all the losses for each role, as they denote log probabilities, we calculate P (M p |C) and P (¬M p |C) via Equation 1. The target player's role as predicted by the model is finally given by comparing the two probabilities. A similar process is used to calculate P (M p |C) and P (¬M p |C) for the utterance classification BERT model.
Random Baseline This random classifier classifies each player as a mafioso or a bystander with probabilities equal to the prior distribution of each class, estimated as the ratio of roles across all training games. This serves as a baseline to be compared to for all other methods. In the game setting, this mimics a bystander player with only public information of how many mafia and bystanders are in the game.
Standard Classification We initialize the model by loading a pre-trained BERT Base model (12 layers, 768 hidden dimension size, 12 attention heads). We train with a maximum sequence length of 256, which is sufficient for our post-processed dataset, setting the batch size to 16, the learning rate to 1e-5, and the maximum number of epochs to 25.
Utterance Classification We initialize the model by loading a pre-trained BERT Base model (12 layers, 768 hidden dimension size, 12 attention heads). We train with a maximum sequence length of 512, which is sufficient for our post-processed dataset, setting the batch size to 5, the learning rate to 5e-5, and the maximum number of epochs to 25. Table 2: Experiment results on the validation set for random baseline (Random), standard classification (Std Class), utterance classification (Utt Class), and utterance generation (Utt Gen) approaches. Methods that use auxiliary tasks (Utt Class and Utt Gen) outperform other methods in terms of average ranking overall and per game while also maintaining higher accuracy and F1-score for each class.
Utterance Generation We initialize the model by loading a pre-trained 12-layer GPT-2 model with an embedding size of 768. For the dataset, we set the maximum length of each sentence to be 512, which is sufficient for our dataset after post-processing. During training, we set the batch size to be 5 and the learning rate to be 1e-5. We train the model for a maximum of 100 epochs.
Metrics These approaches each estimate a probability P (M p |C) that a player p is a mafioso given the full record of game texts C. In Mafia, bystanders do not declare who is and is not a mafioso, but instead vote each day to eliminate one of the players. Because the act of voting involves choosing one player among them all, a natural metric for evaluating the usefulness of a model is to order all players p from greatest to least P (M p |C), their probability of being a mafioso under the model, and then to compute the average rank of the true mafia members. Therefore, the first metric in Table 2 is the average ranking of all mafia members when each player is ranked by P (M p |C) across the entire validation set composed of 5 games. It is also natural to consider player ranking within a single game, so we calculate the average ranking of mafia members within each game as a second metric. Smaller average ranking for mafia members means that the model is able to assign mafia players a high P (M p |C) relative to bystanders, which is desired.
In addition, we evaluate the accuracy of the classifiers and the F1-score for each class. To calculate these metrics, we first assign the mafioso label to the top k players with the highest P (M p |C) and the rest of the players with the bystander label, where k is the known number of mafia among all validation games (k = 10 in our case). Aside from the ranking metrics, these give further information of the models' quality after utilizing available game information.
Results and Analysis We trained all models on 39 training games and evaluated on the remaining 5 validation games. The evaluation results are shown in Table 2. We have a total of 49 players in the validation games, but only considered the 39 players who had spoken at least one utterance throughout the game when calculating the metrics. Players with no utterances are almost exclusively bystanders and are therefore easy to classify without considering language.
First, we see that it is possible to achieve an average rank that is smaller than the random baseline, which demonstrates that there is information in the dialog about the roles of players, despite the fact that mafia members seek to hide their role while conversing. However, standard classification is comparable to random. Next, we observe that both models using auxiliary tasks outperform the standard classifier in rank-based metrics, which demonstrates that the auxiliary tasks provide useful inductive bias for the mafia classification task. Additionally, the accuracy is similar for all approaches, including random classification, which indicates that there is not enough information in the text of a Mafia game for these models to determine players' roles reliably. If the goal of the game were to guess the role of each player individually, then always guessing bystander (i.e. the majority class) would be the best strategy. However, since the goal for the bystanders is to vote to eliminate a mafia member each round, the utterance classification and utterance generation approaches, which achieve the lowest average mafia ranking per game and overall, respectively, are the most favorable.
Note that the precision for the mafia is much lower than that of the bystanders for all models. This is due to the usual lack of information avail-  able to predict that any player is a mafioso, which makes finding the mafia a much harder task than finding bystanders.
