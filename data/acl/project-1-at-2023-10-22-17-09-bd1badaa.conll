-DOCSTART- -X- O
GLM -X- _ B-MethodName
: -X- _ O
General -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
Pretraining -X- _ I-MethodName
with -X- _ O
Autoregressive -X- _ O
Blank -X- _ O
Infilling -X- _ O

There -X- _ O
have -X- _ O
been -X- _ O
various -X- _ O
types -X- _ O
of -X- _ O
pretraining -X- _ O
architectures -X- _ O
including -X- _ O
autoencoding -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
BERT -X- _ O
) -X- _ O
, -X- _ O
autoregressive -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPT -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
encoder-decoder -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
T5 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
frameworks -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
for -X- _ O
all -X- _ O
tasks -X- _ O
of -X- _ O
three -X- _ O
main -X- _ O
categories -X- _ O
including -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ I-TaskName
NLU -X- _ I-TaskName
) -X- _ I-TaskName
, -X- _ O
unconditional -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
and -X- _ O
conditional -X- _ B-TaskName
generation. -X- _ I-TaskName
We -X- _ O
propose -X- _ O
a -X- _ O
General -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
( -X- _ O
GLM -X- _ B-MethodName
) -X- _ O
based -X- _ O
on -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
challenge. -X- _ O
GLM -X- _ B-MethodName
improves -X- _ O
blank -X- _ O
filling -X- _ O
pretraining -X- _ O
by -X- _ O
adding -X- _ O
2D -X- _ O
positional -X- _ O
encodings -X- _ O
and -X- _ O
allowing -X- _ O
an -X- _ O
arbitrary -X- _ O
order -X- _ O
to -X- _ O
predict -X- _ O
spans -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
performance -X- _ O
gains -X- _ O
over -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
T5 -X- _ B-MethodName
on -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
Meanwhile -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
be -X- _ O
pretrained -X- _ O
for -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
tasks -X- _ O
by -X- _ O
varying -X- _ O
the -X- _ O
number -X- _ O
and -X- _ O
lengths -X- _ O
of -X- _ O
blanks. -X- _ O
On -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
across -X- _ O
NLU -X- _ B-TaskName
, -X- _ O
conditional -X- _ O
and -X- _ O
unconditional -X- _ O
generation -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
outperforms -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
T5 -X- _ B-MethodName
, -X- _ O
and -X- _ O
GPT -X- _ B-MethodName
given -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
sizes -X- _ O
and -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
pretrained -X- _ O
model -X- _ O
with -X- _ O
1.25× -X- _ B-MethodName
parameters -X- _ O
of -X- _ O
BERT -X- _ O
Large -X- _ O
, -X- _ O
demonstrating -X- _ O
its -X- _ O
generalizability -X- _ O
to -X- _ O
different -X- _ O
downstream -X- _ O
tasks. -X- _ O
1 -X- _ O

Introduction -X- _ O
Language -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
unlabeled -X- _ O
texts -X- _ O
have -X- _ O
substantially -X- _ O
advanced -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
ranging -X- _ O
from -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ O
NLU -X- _ B-TaskName
) -X- _ O
to -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Raffel -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Downstream -X- _ O
task -X- _ O
performance -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
have -X- _ O
also -X- _ O
constantly -X- _ O
increased -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
few -X- _ O
years. -X- _ O
* -X- _ O
The -X- _ O
first -X- _ O
two -X- _ O
authors -X- _ O
contributed -X- _ O
equally -X- _ O
. -X- _ O

† -X- _ O
Corresponding -X- _ O
authors. -X- _ O
1 -X- _ O
The -X- _ O
code -X- _ O
and -X- _ O
pre-trained -X- _ O
models -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
THUDM -X- _ O
/ -X- _ O
GLM -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
existing -X- _ O
pretraining -X- _ O
frameworks -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
into -X- _ O
three -X- _ O
families -X- _ O
: -X- _ O
autoregressive -X- _ B-MethodName
, -X- _ O
autoencoding -X- _ B-MethodName
, -X- _ O
and -X- _ O
encoder-decoder -X- _ B-MethodName
models. -X- _ O
Autoregressive -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
learn -X- _ O
left-to-right -X- _ O
language -X- _ O
models. -X- _ O
While -X- _ O
they -X- _ O
succeed -X- _ O
in -X- _ O
long-text -X- _ O
generation -X- _ O
and -X- _ O
show -X- _ O
fewshot -X- _ O
learning -X- _ O
ability -X- _ O
when -X- _ O
scaled -X- _ O
to -X- _ O
billions -X- _ O
of -X- _ O
parameters -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
inherent -X- _ O
disadvantage -X- _ O
is -X- _ O
the -X- _ O
unidirectional -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
fully -X- _ O
capture -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
context -X- _ O
words -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
Autoencoding -X- _ B-MethodName
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
learn -X- _ O
bidirectional -X- _ O
context -X- _ O
encoders -X- _ O
via -X- _ O
denoising -X- _ B-TaskName
objectives -X- _ I-TaskName
, -X- _ O
e.g. -X- _ O
Masked -X- _ B-TaskName
Language -X- _ I-TaskName
Model -X- _ I-TaskName
( -X- _ O
MLM -X- _ B-TaskName
) -X- _ O
. -X- _ O
The -X- _ O
encoders -X- _ O
produce -X- _ O
contextualized -X- _ O
representations -X- _ O
that -X- _ O
suit -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
but -X- _ O
could -X- _ O
not -X- _ O
be -X- _ O
directly -X- _ O
applied -X- _ O
for -X- _ O
text -X- _ B-TaskName
generation. -X- _ I-TaskName
Encoder-decoder -X- _ B-MethodName
models -X- _ O
adopt -X- _ O
bidirectional -X- _ O
attention -X- _ O
for -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
unidirectional -X- _ O
attention -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
cross -X- _ O
attention -X- _ O
between -X- _ O
them -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Bi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
typically -X- _ O
deployed -X- _ O
in -X- _ O
conditional -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
response -X- _ B-TaskName
generation. -X- _ I-TaskName
2 -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
unifies -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
conditional -X- _ B-TaskName
generation -X- _ I-TaskName
via -X- _ O
encoder-decoder -X- _ O
models -X- _ O
but -X- _ O
requires -X- _ O
more -X- _ O
parameters -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BRET-based -X- _ B-MethodName
models -X- _ O
such -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
DeBERTa -X- _ B-MethodName
( -X- _ O
He -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

None -X- _ O
of -X- _ O
these -X- _ O
pretraining -X- _ O
frameworks -X- _ O
is -X- _ O
flexible -X- _ O
enough -X- _ O
to -X- _ O
perform -X- _ O
competitively -X- _ O
across -X- _ O
all -X- _ O
NLP -X- _ O
tasks. -X- _ O
Previous -X- _ O
works -X- _ O
have -X- _ O
tried -X- _ O
to -X- _ O
unify -X- _ O
different -X- _ O
frameworks -X- _ O
by -X- _ O
combining -X- _ O
their -X- _ O
objectives -X- _ O
via -X- _ O
multi-task -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Bao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
autoencoding -X- _ O
and -X- _ O
autoregressive -X- _ O
objectives -X- _ O
differ -X- _ O
by -X- _ O
nature -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
unification -X- _ O
can -X- _ O
not -X- _ O
fully -X- _ O
inherit -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
both -X- _ O
frameworks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
pretraining -X- _ O
framework -X- _ O
named -X- _ O
GLM -X- _ B-MethodName
( -X- _ O
General -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
) -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling. -X- _ O
We -X- _ O
randomly -X- _ O
blank -X- _ O
out -X- _ O
continuous -X- _ O
spans -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
autoencoding -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
sequentially -X- _ O
reconstruct -X- _ O
the -X- _ O
spans -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
blanking -X- _ O
filling -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
text-to-text -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
improvements -X- _ O
, -X- _ O
namely -X- _ O
span -X- _ O
shuffling -X- _ O
and -X- _ O
2D -X- _ O
positional -X- _ O
encoding. -X- _ O
Empirically -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
and -X- _ O
computational -X- _ O
cost -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
of -X- _ O
4.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
-5.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
outperforms -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
BART -X- _ B-MethodName
when -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
similar -X- _ O
size -X- _ O
( -X- _ O
158GB -X- _ O
) -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
also -X- _ O
significantly -X- _ O
outperforms -X- _ O
T5 -X- _ B-MethodName
on -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
generation -X- _ O
tasks -X- _ O
with -X- _ O
fewer -X- _ O
parameters -X- _ O
and -X- _ O
data -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
Pattern-Exploiting -X- _ B-MethodName
Training -X- _ I-MethodName
( -X- _ O
PET -X- _ B-MethodName
) -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
reformulate -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
as -X- _ O
manually-crafted -X- _ O
cloze -X- _ O
questions -X- _ O
that -X- _ O
mimic -X- _ O
human -X- _ O
language. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
BERTbased -X- _ B-MethodName
models -X- _ O
used -X- _ O
by -X- _ O
PET -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
naturally -X- _ O
handle -X- _ O
multi-token -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
cloze -X- _ O
question -X- _ O
via -X- _ O
autoregressive -X- _ O
blank -X- _ O
filling -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
by -X- _ O
varying -X- _ O
the -X- _ O
number -X- _ O
and -X- _ O
lengths -X- _ O
of -X- _ O
missing -X- _ O
spans -X- _ O
, -X- _ O
the -X- _ O
autoregressive -X- _ B-TaskName
blank -X- _ I-TaskName
filling -X- _ I-TaskName
objective -X- _ O
can -X- _ O
pretrain -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
conditional -X- _ B-TaskName
and -X- _ O
unconditional -X- _ B-TaskName
generation. -X- _ I-TaskName
Through -X- _ O
multi-task -X- _ B-TaskName
learning -X- _ I-TaskName
of -X- _ O
different -X- _ O
pretraining -X- _ O
objectives -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
excel -X- _ O
in -X- _ O
both -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
( -X- _ O
conditional -X- _ B-TaskName
and -X- _ I-TaskName
unconditional -X- _ I-TaskName
) -X- _ I-TaskName
text -X- _ I-TaskName
generation. -X- _ I-TaskName
Empirically -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
standalone -X- _ O
baselines -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
multi-task -X- _ B-TaskName
pretraining -X- _ I-TaskName
achieves -X- _ O
improvements -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
, -X- _ O
conditional -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
and -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
tasks -X- _ O
altogether -X- _ O
by -X- _ O
sharing -X- _ O
the -X- _ O
parameters -X- _ O
. -X- _ O

GLM -X- _ B-MethodName
Pretraining -X- _ O
Framework -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
general -X- _ O
pretraining -X- _ O
framework -X- _ O
GLM -X- _ B-MethodName
based -X- _ O
on -X- _ O
a -X- _ O
novel -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
objective. -X- _ O
GLM -X- _ B-MethodName
formulates -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
as -X- _ O
cloze -X- _ O
questions -X- _ O
that -X- _ O
contain -X- _ O
task -X- _ O
descriptions -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
answered -X- _ O
by -X- _ O
autoregressive -X- _ O
generation -X- _ O
. -X- _ O

Pretraining -X- _ O
Objective -X- _ O

Autoregressive -X- _ O
Blank -X- _ O
Infilling -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
by -X- _ O
optimizing -X- _ O
an -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
objective. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
text -X- _ O

Each -X- _ O
span -X- _ O
is -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
, -X- _ O
forming -X- _ O
a -X- _ O
corrupted -X- _ O
text -X- _ O
x -X- _ O
corrupt -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
missing -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
spans -X- _ O
from -X- _ O
the -X- _ O
corrupted -X- _ O
text -X- _ O
in -X- _ O
an -X- _ O
autoregressive -X- _ O
manner -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
missing -X- _ O
tokens -X- _ O
in -X- _ O
a -X- _ O
span -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
corrupted -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
previously -X- _ O
predicted -X- _ O
spans. -X- _ O
To -X- _ O
fully -X- _ O
capture -X- _ O
the -X- _ O
interdependencies -X- _ O
between -X- _ O
different -X- _ O
spans -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
permute -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
spans -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
permutation -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
let -X- _ O
Z -X- _ O
m -X- _ O
be -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
permutations -X- _ O
of -X- _ O
the -X- _ O
length-m -X- _ O
index -X- _ O
sequence -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
m -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
s -X- _ O
z -X- _ O
< -X- _ O
i -X- _ O
be -X- _ O
[ -X- _ O
s -X- _ O
z -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
s -X- _ O
z -X- _ O
i−1 -X- _ O
] -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
pretraining -X- _ O
objective -X- _ O
as -X- _ O

Position -X- _ O
1 -X- _ O
1 -X- _ O
2 -X- _ O
3 -X- _ O
4 -X- _ O
5 -X- _ O
5 -X- _ O
5 -X- _ O
5 -X- _ O
3 -X- _ O
3 -X- _ O
Position -X- _ O
2 -X- _ O
0 -X- _ O
0 -X- _ O
0 -X- _ O
0 -X- _ O
0 -X- _ O
1 -X- _ O
2 -X- _ O
3 -X- _ O
1 -X- _ O
2 -X- _ O
output -X- _ O
respectively. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
automatically -X- _ O
learns -X- _ O
a -X- _ O
bidirectional -X- _ O
encoder -X- _ O
( -X- _ O
for -X- _ O
Part -X- _ O
A -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
unidirectional -X- _ O
decoder -X- _ O
( -X- _ O
for -X- _ O
Part -X- _ O
B -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
model. -X- _ O
The -X- _ O
implementation -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O
We -X- _ O
randomly -X- _ O
sample -X- _ O
spans -X- _ O
of -X- _ O
length -X- _ O
drawn -X- _ O
from -X- _ O
a -X- _ O
Poisson -X- _ O
distribution -X- _ O
with -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
3. -X- _ B-HyperparameterValue
We -X- _ O
repeatedly -X- _ O
sample -X- _ O
new -X- _ O
spans -X- _ O
until -X- _ O
at -X- _ O
least -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
original -X- _ O
tokens -X- _ O
are -X- _ O
masked. -X- _ O
Empirically -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
ratio -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

Multi-Task -X- _ O
Pretraining -X- _ O
In -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
masks -X- _ O
short -X- _ O
spans -X- _ O
and -X- _ O
is -X- _ O
suited -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
pretraining -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
handle -X- _ O
both -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
text -X- _ B-TaskName
generation. -X- _ I-TaskName
We -X- _ O
then -X- _ O
study -X- _ O
a -X- _ O
multi-task -X- _ B-TaskName
pretraining -X- _ I-TaskName
setup -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
second -X- _ O
objective -X- _ O
of -X- _ O
generating -X- _ O
longer -X- _ O
text -X- _ O
is -X- _ O
jointly -X- _ O
optimized -X- _ O
with -X- _ O
the -X- _ O
blank -X- _ O
infilling -X- _ O
objective. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
objectives -X- _ O
: -X- _ O

• -X- _ O
Document-level. -X- _ O
We -X- _ O
sample -X- _ O
a -X- _ O
single -X- _ O
span -X- _ O
whose -X- _ O
length -X- _ O
is -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
uniform -X- _ O
distribution -X- _ O
over -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
-100 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
original -X- _ O
length. -X- _ O
The -X- _ O
objective -X- _ O
aims -X- _ O
for -X- _ O
long -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O

• -X- _ O
Sentence-level. -X- _ O
We -X- _ O
restrict -X- _ O
that -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
must -X- _ O
be -X- _ O
full -X- _ O
sentences. -X- _ O
Multiple -X- _ O
spans -X- _ O
( -X- _ O
sentences -X- _ O
) -X- _ O
are -X- _ O
sampled -X- _ O
to -X- _ O
cover -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
original -X- _ O
tokens. -X- _ O
This -X- _ O
objective -X- _ O
aims -X- _ O
for -X- _ O
seq2seq -X- _ O
tasks -X- _ O
whose -X- _ O
predictions -X- _ O
are -X- _ O
often -X- _ O
complete -X- _ O
sentences -X- _ O
or -X- _ O
paragraphs -X- _ O
. -X- _ O

Model -X- _ O
Architecture -X- _ O
GLM -X- _ B-MethodName
uses -X- _ O
a -X- _ O
single -X- _ O
Transformer -X- _ O
with -X- _ O
several -X- _ O
modifications -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
rearrange -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
layer -X- _ O
normalization -X- _ O
and -X- _ O
the -X- _ O
residual -X- _ O
connection -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
critical -X- _ O
for -X- _ O
large-scale -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
avoid -X- _ O
numerical -X- _ O
errors -X- _ O
( -X- _ O
Shoeybi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
single -X- _ O
linear -X- _ O
layer -X- _ O
for -X- _ O
the -X- _ O
output -X- _ O
token -X- _ O
prediction -X- _ O
; -X- _ O

Finetuning -X- _ O
GLM -X- _ B-MethodName
Typically -X- _ O
, -X- _ O
for -X- _ O
downstream -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
takes -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
sequences -X- _ O
or -X- _ O
tokens -X- _ O
produced -X- _ O
by -X- _ O
pretrained -X- _ O
models -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
correct -X- _ O
labels. -X- _ O
The -X- _ O
practices -X- _ O
are -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
generative -X- _ O
pretraining -X- _ O
task -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
inconsistency -X- _ O
between -X- _ O
pretraining -X- _ O
and -X- _ O
finetuning -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
we -X- _ O
reformulate -X- _ O
NLU -X- _ B-TaskName
classification -X- _ O
tasks -X- _ O
as -X- _ O
generation -X- _ O
tasks -X- _ O
of -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
, -X- _ O
following -X- _ O
PET -X- _ B-TaskName
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
labeled -X- _ O
example -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
convert -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
x -X- _ O
to -X- _ O
a -X- _ O
cloze -X- _ O
question -X- _ O
c -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
via -X- _ O
a -X- _ O
pattern -X- _ O
containing -X- _ O
a -X- _ O
single -X- _ O
mask -X- _ O
token. -X- _ O
The -X- _ O
pattern -X- _ O
is -X- _ O
written -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
task. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
sentiment -X- _ O
classification -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
" -X- _ O
{ -X- _ O
SENTENCE -X- _ O
} -X- _ O
. -X- _ O
It -X- _ O
's -X- _ O
really -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
candidate -X- _ O
labels -X- _ O
y -X- _ O
∈ -X- _ O
Y -X- _ O
are -X- _ O
also -X- _ O
mapped -X- _ O
to -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
cloze -X- _ O
, -X- _ O
called -X- _ O
verbalizer -X- _ O
v -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
sentiment -X- _ O
classification -X- _ O
, -X- _ O
the -X- _ O
labels -X- _ O
" -X- _ O
positive -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
negative -X- _ O
" -X- _ O
are -X- _ O
mapped -X- _ O
to -X- _ O
the -X- _ O
words -X- _ O
" -X- _ O
good -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
bad -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
conditional -X- _ O
probability -X- _ O
of -X- _ O
predicting -X- _ O
y -X- _ O
given -X- _ O
x -X- _ O
is -X- _ O

Then -X- _ O
we -X- _ O
finetune -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
a -X- _ O
cross-entropy -X- _ O
loss -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
given -X- _ O
context -X- _ O
constitutes -X- _ O
the -X- _ O
Part -X- _ O
A -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
mask -X- _ O
token -X- _ O
appended -X- _ O
at -X- _ O
the -X- _ O
end. -X- _ O
The -X- _ O
model -X- _ O
generates -X- _ O
the -X- _ O
text -X- _ O
of -X- _ O
Part -X- _ O
B -X- _ O
autoregressively. -X- _ O
We -X- _ O
can -X- _ O
directly -X- _ O
apply -X- _ O
the -X- _ O
pretrained -X- _ O
GLM -X- _ B-MethodName
for -X- _ O
unconditional -X- _ O
generation -X- _ O
, -X- _ O
or -X- _ O
finetune -X- _ O
it -X- _ O
on -X- _ O
downstream -X- _ O
conditional -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

Discussion -X- _ O
and -X- _ O
Analysis -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
GLM -X- _ O
and -X- _ O
other -X- _ O
pretraining -X- _ O
models. -X- _ O
We -X- _ O
are -X- _ O
mainly -X- _ O
concerned -X- _ O
with -X- _ O
how -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
downstream -X- _ O
blank -X- _ O
infilling -X- _ O
tasks -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
pointed -X- _ O
out -X- _ O
by -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
fails -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
interdependencies -X- _ O
of -X- _ O
masked -X- _ O
tokens -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
independence -X- _ O
assumption -X- _ O
of -X- _ O
MLM. -X- _ B-TaskName
Another -X- _ O
disadvantage -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
blanks -X- _ O
of -X- _ O
multiple -X- _ O
tokens -X- _ O
properly. -X- _ O
To -X- _ O
infer -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
an -X- _ O
answer -X- _ O
of -X- _ O
length -X- _ O
l -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
needs -X- _ O
to -X- _ O
perform -X- _ O
l -X- _ O
consecutive -X- _ O
predictions. -X- _ O
If -X- _ O
the -X- _ O
length -X- _ O
l -X- _ O
is -X- _ O
unknown -X- _ O
, -X- _ O
we -X- _ O
may -X- _ O
need -X- _ O
to -X- _ O
enumerate -X- _ O
all -X- _ O
possible -X- _ O
lengths -X- _ O
, -X- _ O
since -X- _ O
BERT -X- _ B-MethodName
needs -X- _ O
to -X- _ O
change -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
length -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
GLM -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
are -X- _ O
pretrained -X- _ O
with -X- _ O
autoregressive -X- _ O
objectives -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
differences -X- _ O
between -X- _ O
them. -X- _ O
First -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
uses -X- _ O
the -X- _ O
original -X- _ O
position -X- _ O
encodings -X- _ O
before -X- _ O
corruption. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
either -X- _ O
know -X- _ O
or -X- _ O
enumerate -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
problem -X- _ O
as -X- _ O
BERT. -X- _ B-MethodName
Second -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
uses -X- _ O
a -X- _ O
two-stream -X- _ O
self-attention -X- _ O
mechanism -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
right-shift -X- _ O
, -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
information -X- _ O
leak -X- _ O
within -X- _ O
Transformer. -X- _ O
It -X- _ O
doubles -X- _ O
the -X- _ O
time -X- _ O
cost -X- _ O
of -X- _ O
pretraining -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
proposes -X- _ O
a -X- _ O
similar -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
to -X- _ O
pretrain -X- _ O
an -X- _ O
encoder-decoder -X- _ O
Transformer. -X- _ O
T5 -X- _ B-MethodName
uses -X- _ O
independent -X- _ O
positional -X- _ O
encodings -X- _ O
for -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
relies -X- _ O
on -X- _ O
multiple -X- _ O
sentinel -X- _ O
tokens -X- _ O
to -X- _ O
differentiate -X- _ O
the -X- _ O
masked -X- _ O
spans. -X- _ O
In -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
sentinel -X- _ O
tokens -X- _ O
is -X- _ O
used -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
waste -X- _ O
of -X- _ O
model -X- _ O
capacity -X- _ O
and -X- _ O
inconsistency -X- _ O
between -X- _ O
pretraining -X- _ O
and -X- _ O
finetuning. -X- _ O
Moreover -X- _ O
, -X- _ O
T5 -X- _ B-MethodName
always -X- _ O
predicts -X- _ O
spans -X- _ O
in -X- _ O
a -X- _ O
fixed -X- _ O
left-to-right -X- _ O
order. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
significantly -X- _ O
outperform -X- _ O
T5 -X- _ B-MethodName
on -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
seq2seq -X- _ B-TaskName
tasks -X- _ O
with -X- _ O
fewer -X- _ O
parameters -X- _ O
and -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
stated -X- _ O
in -X- _ O
Sections -X- _ O
3.2 -X- _ O
and -X- _ O
3.3 -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
UniLM -X- _ B-MethodName
combines -X- _ O
different -X- _ O
pretraining -X- _ O
objectives -X- _ O
under -X- _ O
the -X- _ O
autoencoding -X- _ O
framework -X- _ O
by -X- _ O
changing -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
among -X- _ O
bidirectional -X- _ O
, -X- _ O
unidirectional -X- _ O
, -X- _ O
and -X- _ O
cross -X- _ O
attention. -X- _ O
However -X- _ O
, -X- _ O
UniLM -X- _ B-MethodName
always -X- _ O
replaces -X- _ O
masked -X- _ O
spans -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
and -X- _ O
their -X- _ O
context. -X- _ O
GLM -X- _ B-MethodName
feeds -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
token -X- _ O
and -X- _ O
autoregressively -X- _ O
generates -X- _ O
the -X- _ O
next -X- _ O
token. -X- _ O
Finetuning -X- _ O
UniLM -X- _ B-MethodName
on -X- _ O
downstream -X- _ O
generation -X- _ O
tasks -X- _ O
also -X- _ O
relies -X- _ O
on -X- _ O
masked -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
, -X- _ O
which -X- _ O
is -X- _ O
less -X- _ O
efficient. -X- _ O
UniLMv2 -X- _ B-MethodName
( -X- _ O
Bao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
adopts -X- _ O
partially -X- _ O
autoregressive -X- _ O
modeling -X- _ O
for -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
autoencoding -X- _ O
objective -X- _ O
for -X- _ O
NLU -X- _ B-MethodName
tasks. -X- _ O
Instead -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
unifies -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
with -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
. -X- _ O

Pretraining -X- _ O
Setup -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
as -X- _ O
our -X- _ O
pretraining -X- _ O
data. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
uncased -X- _ O
wordpiece -X- _ O
tokenizer -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
30k -X- _ O
vocabulary. -X- _ O
We -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
with -X- _ O
the -X- _ O
same -X- _ O
architectures -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
containing -X- _ O
110M -X- _ B-HyperparameterValue
and -X- _ O
340M -X- _ B-HyperparameterValue
parameters -X- _ O
respectively -X- _ O
. -X- _ O

For -X- _ O
multi-task -X- _ B-TaskName
pretraining -X- _ I-TaskName
, -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
Largesized -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
the -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
and -X- _ O
the -X- _ O
document-level -X- _ O
or -X- _ O
sentencelevel -X- _ O
objective -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Sent -X- _ I-MethodName
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
larger -X- _ O
GLM -X- _ B-MethodName
models -X- _ O
of -X- _ O
410M -X- _ B-HyperparameterValue
( -X- _ O
30 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
1024 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
16 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
) -X- _ O
and -X- _ O
515M -X- _ B-HyperparameterValue
( -X- _ O
30 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
1152 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
18 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
) -X- _ O
parameters -X- _ O
with -X- _ O
documentlevel -X- _ B-TaskName
multi-task -X- _ I-TaskName
pretraining -X- _ I-TaskName
, -X- _ O
denoted -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
410M -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
515M -X- _ I-MethodName
. -X- _ O

To -X- _ O
compare -X- _ O
with -X- _ O
SOTA -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
Large-sized -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
, -X- _ O
tokenization -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
denoted -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
. -X- _ O
Due -X- _ O
to -X- _ O
resource -X- _ O
limitations -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
pretrain -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
250,000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
are -X- _ O
half -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
BART -X- _ B-MethodName
's -X- _ I-MethodName
training -X- _ O
steps -X- _ O
and -X- _ O
close -X- _ O
to -X- _ O
T5 -X- _ B-MethodName
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trained -X- _ O
tokens. -X- _ O
More -X- _ O
experiment -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

SuperGLUE -X- _ B-DatasetName
To -X- _ O
evaluate -X- _ O
our -X- _ O
pretrained -X- _ O
GLM -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
bench-mark -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
standard -X- _ O
metrics. -X- _ O
SuperGLUE -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
8 -X- _ O
challenging -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
We -X- _ O
reformulate -X- _ O
the -X- _ O
classification -X- _ O
tasks -X- _ O
as -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
with -X- _ I-TaskName
human-crafted -X- _ I-TaskName
cloze -X- _ I-TaskName
questions -X- _ I-TaskName
, -X- _ O
following -X- _ O
PET -X- _ B-TaskName
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
pretrained -X- _ O
GLM -X- _ B-MethodName
models -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2.3. -X- _ O
The -X- _ O
cloze -X- _ O
questions -X- _ O
and -X- _ O
other -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
B.1 -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
we -X- _ O
choose -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
as -X- _ O
our -X- _ O
baselines -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
corpus -X- _ O
and -X- _ O
for -X- _ O
a -X- _ O
similar -X- _ O
amount -X- _ O
of -X- _ O
time. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
standard -X- _ O
finetuning -X- _ O
( -X- _ O
i.e. -X- _ O
classification -X- _ O
on -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
representation -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
cloze -X- _ O
questions -X- _ O
is -X- _ O
reported -X- _ O
in -X- _ O
Section -X- _ O
3.4. -X- _ O
To -X- _ O
compare -X- _ O
with -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
, -X- _ O
we -X- _ O
choose -X- _ O
T5 -X- _ B-MethodName
, -X- _ O
BART -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
Large -X- _ I-MethodName
as -X- _ O
our -X- _ O
baselines. -X- _ O
T5 -X- _ B-MethodName
has -X- _ O
no -X- _ O
direct -X- _ O
match -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
so -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
both -X- _ O
T5 -X- _ B-MethodName
Base -X- _ I-MethodName
( -X- _ O
220M -X- _ B-HyperparameterValue
parameters -X- _ B-HyperparameterName
) -X- _ O
and -X- _ O
T5 -X- _ B-MethodName
Large -X- _ I-MethodName
( -X- _ O
770M -X- _ B-HyperparameterValue
parameters -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
other -X- _ O
baselines -X- _ O
are -X- _ O
of -X- _ O
similar -X- _ O
size -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
most -X- _ O
tasks -X- _ O
with -X- _ O
either -X- _ O
base -X- _ O
or -X- _ O
large -X- _ O
architecture. -X- _ O
The -X- _ O
only -X- _ O
exception -X- _ O
is -X- _ O
WiC -X- _ B-DatasetName
( -X- _ O
word -X- _ O
sense -X- _ O
disambiguation -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
scores -X- _ O
4.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
, -X- _ O
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
scores -X- _ O
5.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
It -X- _ O
clearly -X- _ O
demonstrates -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
In -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
can -X- _ O
still -X- _ O
achieve -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
smaller -X- _ O
margin. -X- _ O
Specifically -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
outperforms -X- _ O
T5 -X- _ B-MethodName
Large -X- _ I-MethodName
but -X- _ O
is -X- _ O
only -X- _ O
half -X- _ O
its -X- _ O
size. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
BART -X- _ B-MethodName
does -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
the -X- _ O
challenging -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark. -X- _ O
We -X- _ O
conjecture -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
low -X- _ O
parameter -X- _ O
efficiency -X- _ O
of -X- _ O
the -X- _ O
encoder-decoder -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
denoising -X- _ B-TaskName
sequence-to-sequence -X- _ I-TaskName
objective -X- _ O
. -X- _ O

Multi-Task -X- _ O
Pretraining -X- _ O
Then -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
GLM -X- _ B-MethodName
's -X- _ I-MethodName
performance -X- _ O
in -X- _ O
a -X- _ O
multi-task -X- _ O
setting -X- _ O
( -X- _ O
Section -X- _ O
2.1 -X- _ O
) -X- _ O
. -X- _ O
Within -X- _ O
one -X- _ O
training -X- _ O
batch -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
short -X- _ O
spans -X- _ O
and -X- _ O
longer -X- _ O
spans -X- _ O
( -X- _ O
document-level -X- _ O
or -X- _ O
sentence-level -X- _ O
) -X- _ O
with -X- _ O
equal -X- _ O
chances. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
multi-task -X- _ O
model -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
, -X- _ O
seq2seq -X- _ B-TaskName
, -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
, -X- _ O
and -X- _ O
zero-shot -X- _ B-TaskName
language -X- _ I-TaskName
modeling. -X- _ I-TaskName
SuperGLUE. -X- _ B-DatasetName
For -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark. -X- _ O
The -X- _ O
results -X- _ O
Sequence-to-Sequence -X- _ O
. -X- _ O

Considering -X- _ O
the -X- _ O
available -X- _ O
baseline -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Gigaword -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Rush -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
for -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Du -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
benchmarks -X- _ O
for -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
BookCorpus -X- _ B-DatasetName
and -X- _ O
Wikipedia. -X- _ B-DatasetName
Additionally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
( -X- _ O
See -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
XSum -X- _ B-DatasetName
( -X- _ O
Narayan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
datasets -X- _ O
for -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
as -X- _ O
the -X- _ O
benchmarks -X- _ O
for -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
larger -X- _ O
corpora -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
BookCorpus -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Tables -X- _ O
3 -X- _ O
and -X- _ O
4. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
performance -X- _ O
matching -X- _ O
the -X- _ O
other -X- _ O
pretraining -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
generation -X- _ O
tasks. -X- _ O
GLM -X- _ B-MethodName
Sent -X- _ I-MethodName
can -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
while -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
performs -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
documentlevel -X- _ O
objective -X- _ O
, -X- _ O
which -X- _ O
teaches -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
given -X- _ O
contexts -X- _ O
, -X- _ O
is -X- _ O
less -X- _ O
helpful -X- _ O
to -X- _ O
conditional -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
extract -X- _ O
useful -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
context. -X- _ O
Increasing -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
's -X- _ O
parameters -X- _ O
to -X- _ O
410M -X- _ B-HyperparameterValue
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
tasks. -X- _ O
The -X- _ O
results -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
larger -X- _ O
corpora -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
performance -X- _ O
matching -X- _ O
the -X- _ O
seq2seq -X- _ O
BART -X- _ B-MethodName
model -X- _ O
, -X- _ O
and -X- _ O
outperform -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
UniLMv2 -X- _ B-MethodName
. -X- _ O

Text -X- _ O
Infilling. -X- _ O
Text -X- _ B-TaskName
infilling -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
missing -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
which -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
surrounding -X- _ O
context -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Donahue -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
an -X- _ O
autoregressive -X- _ B-TaskName
blank -X- _ I-TaskName
infilling -X- _ I-TaskName
objective -X- _ O
, -X- _ O
thus -X- _ O
can -X- _ O
straightforwardly -X- _ O
solve -X- _ O
this -X- _ O
task. -X- _ O
We -X- _ O
evaluate -X- _ O
GLM -X- _ B-MethodName
on -X- _ O
the -X- _ O
Yahoo -X- _ B-DatasetName
Answers -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
Blank -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
( -X- _ O
BLM -X- _ B-MethodName
) -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
specifically -X- _ O
designed -X- _ O
model -X- _ O
for -X- _ O
text -X- _ O
infilling. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
methods -X- _ O
by -X- _ O
large -X- _ O
margins -X- _ O
( -X- _ O
1.3 -X- _ B-MetricValue
to -X- _ O
3.9 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
) -X- _ O
and -X- _ O
achieves -X- _ O
the -X- _ O
state-of-the-art -X- _ O
result -X- _ O
on -X- _ O
this -X- _ O
dataset. -X- _ O
We -X- _ O
notice -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
slightly -X- _ O
underperforms -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
our -X- _ O
observations -X- _ O
in -X- _ O
the -X- _ O
seq2seq -X- _ O
experiments. -X- _ O
Language -X- _ O
Modeling. -X- _ O
Most -X- _ O
language -X- _ O
modeling -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
WikiText103 -X- _ B-DatasetName
are -X- _ O
constructed -X- _ O
from -X- _ O
Wikipedia -X- _ O
documents -X- _ O
, -X- _ O
which -X- _ O
our -X- _ O
pretraining -X- _ O
dataset -X- _ O
already -X- _ O
contains. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
perplexity -X- _ O
on -X- _ O
a -X- _ O
held-out -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
our -X- _ O
pretraining -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
about -X- _ O
20M -X- _ B-HyperparameterValue
tokens -X- _ B-HyperparameterName
, -X- _ O
denoted -X- _ O
as -X- _ O
BookWiki. -X- _ B-DatasetName
We -X- _ O
also -X- _ O
evaluate -X- _ O
GLM -X- _ B-MethodName
on -X- _ O
the -X- _ O
LAMBADA -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Paperno -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
final -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
passage. -X- _ O
As -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
model -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
tokenization -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4. -X- _ O
All -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
zero-shot -X- _ O
setting. -X- _ O
Since -X- _ O
GLM -X- _ B-MethodName
learns -X- _ O
the -X- _ O
bidirectional -X- _ O
attention -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
evaluate -X- _ O
GLM -X- _ B-MethodName
under -X- _ O
the -X- _ O
setting -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
contexts -X- _ O
are -X- _ O
encoded -X- _ O
with -X- _ O
bidirectional -X- _ O
attention. -X- _ O
Without -X- _ O
generative -X- _ O
objective -X- _ O
during -X- _ O
pretraining -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
Large -X- _ O
can -X- _ O
not -X- _ O
complete -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
tasks -X- _ O
, -X- _ O
with -X- _ O
perplexity -X- _ O
larger -X- _ O
than -X- _ O
100. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
expected -X- _ O
since -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
also -X- _ O
optimizes -X- _ O
the -X- _ O
blank -X- _ O
infilling -X- _ O
objective. -X- _ O
Increasing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ O
to -X- _ O
410M -X- _ O
( -X- _ O
1.25× -X- _ O
of -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
) -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
performance -X- _ O
close -X- _ O
to -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
GLM -X- _ B-MethodName
515M -X- _ I-MethodName
( -X- _ O
1.5× -X- _ O
of -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
) -X- _ O
can -X- _ O
further -X- _ O
outperform -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
encoding -X- _ O
the -X- _ O
context -X- _ O
with -X- _ O
bidirectional -X- _ O
attention -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
language -X- _ O
modeling. -X- _ O
Under -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
410M -X- _ I-MethodName
outperforms -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
over -X- _ O
unidirectional -X- _ O
GPT. -X- _ B-MethodName
We -X- _ O
also -X- _ O
study -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
2D -X- _ O
positional -X- _ O
encoding -X- _ O
to -X- _ O
long -X- _ O
text -X- _ O
generation. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
2D -X- _ O
positional -X- _ O
encoding -X- _ O
leads -X- _ O
to -X- _ O
lower -X- _ O
accuracy -X- _ O
and -X- _ O
higher -X- _ O
perplexity -X- _ O
in -X- _ O
language -X- _ O
modeling. -X- _ O
Summary. -X- _ O
Above -X- _ O
all -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
effectively -X- _ O
shares -X- _ O
model -X- _ O
parameters -X- _ O
across -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
achieving -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
a -X- _ O
standalone -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
encoder-decoder -X- _ O
, -X- _ O
or -X- _ O
GPT -X- _ B-MethodName
model -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
our -X- _ O
ablation -X- _ O
analysis -X- _ O
for -X- _ O
GLM. -X- _ B-MethodName
First -X- _ O
, -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
apple-to-apple -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
model -X- _ O
with -X- _ O
our -X- _ O
implementation -X- _ O
, -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
( -X- _ O
row -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
is -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
official -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
and -X- _ O
significantly -X- _ O
worse -X- _ O
than -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
It -X- _ O
confirms -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
over -X- _ O
Masked -X- _ B-TaskName
LM -X- _ I-TaskName
pretraining -X- _ I-TaskName
on -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
performance -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
finetuned -X- _ O
as -X- _ O
sequence -X- _ B-TaskName
classifiers -X- _ I-TaskName
( -X- _ O
row -X- _ O
5 -X- _ O
) -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
clozestyle -X- _ O
finetuning -X- _ O
( -X- _ O
row -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
cloze-style -X- _ O
finetuning -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
benefits -X- _ O
from -X- _ O
the -X- _ O
autoregressive -X- _ O
pretraining. -X- _ O
Especially -X- _ O
on -X- _ O
ReCoRD -X- _ B-DatasetName
and -X- _ O
WSC -X- _ B-DatasetName
, -X- _ O
where -X- _ O
the -X- _ O
verbalizer -X- _ O
consists -X- _ O
of -X- _ O
multiple -X- _ O
tokens -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
BERT. -X- _ B-MethodName
This -X- _ O
demonstrates -X- _ O
GLM -X- _ B-MethodName
's -X- _ O
advantage -X- _ O
in -X- _ O
handling -X- _ O
variable-length -X- _ O
blank. -X- _ O
Another -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
cloze -X- _ O
formulation -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
's -X- _ I-MethodName
performance -X- _ O
on -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
For -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
, -X- _ O
clozestyle -X- _ O
finetuning -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
by -X- _ O
7 -X- _ O
points. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
GLM -X- _ B-MethodName
variants -X- _ O
with -X- _ O
different -X- _ O
pretraining -X- _ O
designs -X- _ O
to -X- _ O
understand -X- _ O
their -X- _ O
importance. -X- _ O
Row -X- _ O
6 -X- _ O
shows -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
span -X- _ O
shuffling -X- _ O
( -X- _ O
always -X- _ O
predicting -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
from -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
) -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
severe -X- _ O
performance -X- _ O
drop -X- _ O
on -X- _ O
SuperGLUE. -X- _ B-DatasetName
Row -X- _ O
7 -X- _ O
uses -X- _ O
different -X- _ O
sentinel -X- _ O
tokens -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
to -X- _ O
represent -X- _ O
different -X- _ O
masked -X- _ O
spans. -X- _ O
The -X- _ O
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
GLM. -X- _ B-MethodName
We -X- _ O
hypothesize -X- _ O
that -X- _ O
it -X- _ O
wastes -X- _ O
some -X- _ O
modeling -X- _ O
capacity -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
different -X- _ O
sentinel -X- _ O
tokens -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
with -X- _ O
only -X- _ O
one -X- _ O
blank. -X- _ O
In -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
second -X- _ O
dimension -X- _ O
of -X- _ O
2D -X- _ O
positional -X- _ O
encoding -X- _ O
hurts -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
long -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
T5 -X- _ B-MethodName
is -X- _ O
pretrained -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
blank -X- _ O
infilling -X- _ O
objective. -X- _ O
GLM -X- _ B-MethodName
differs -X- _ O
in -X- _ O
three -X- _ O
aspects -X- _ O
: -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
consists -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
encoder -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
shuffles -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
uses -X- _ O
a -X- _ O
single -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
instead -X- _ O
of -X- _ O
multiple -X- _ O
sentinel -X- _ O
tokens. -X- _ O
While -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
directly -X- _ O
compare -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
T5 -X- _ B-MethodName
due -X- _ O
to -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Tables -X- _ O
1 -X- _ O
and -X- _ O
6 -X- _ O
have -X- _ O
demonstrated -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
. -X- _ O

Among -X- _ O
encoder-decoder -X- _ O
models -X- _ O
, -X- _ O
BART -X- _ B-MethodName
conducts -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
by -X- _ O
feeding -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
taking -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
decoder. -X- _ O
Instead -X- _ O
, -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
formulates -X- _ O
most -X- _ O
language -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
text-to-text -X- _ O
framework. -X- _ O
However -X- _ O
, -X- _ O
both -X- _ O
models -X- _ O
require -X- _ O
more -X- _ O
parameters -X- _ O
to -X- _ O
outperform -X- _ O
autoencoding -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Bao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
unifies -X- _ O
three -X- _ O
pretraining -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
with -X- _ O
different -X- _ O
attention -X- _ O
masks -X- _ O
. -X- _ O

NLU -X- _ B-TaskName
as -X- _ O
Generation. -X- _ O
Previously -X- _ O
, -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
complete -X- _ O
classification -X- _ O
tasks -X- _ O
for -X- _ O
NLU -X- _ O
with -X- _ O
linear -X- _ O
classifiers -X- _ O
on -X- _ O
the -X- _ O
learned -X- _ O
representations. -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
and -X- _ O
GPT-3 -X- _ B-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
complete -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ O
answering -X- _ O
by -X- _ O
directly -X- _ O
predicting -X- _ O
the -X- _ O
correct -X- _ O
answers -X- _ O
without -X- _ O
finetuning -X- _ O
, -X- _ O
given -X- _ O
task -X- _ O
instructions -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
labeled -X- _ O
examples. -X- _ O
However -X- _ O
, -X- _ O
generative -X- _ O
models -X- _ O
require -X- _ O
much -X- _ O
more -X- _ O
parameters -X- _ O
to -X- _ O
work -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
limit -X- _ O
of -X- _ O
unidirectional -X- _ O
attention. -X- _ O
Recently -X- _ O
, -X- _ O
PET -X- _ B-MethodName
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
proposes -X- _ O
to -X- _ O
reformulate -X- _ O
input -X- _ O
examples -X- _ O
as -X- _ O
cloze -X- _ O
questions -X- _ O
with -X- _ O
patterns -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
pretraining -X- _ O
corpus -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting. -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
combined -X- _ O
with -X- _ O
gradient-based -X- _ O
finetuning -X- _ O
, -X- _ O
PET -X- _ B-MethodName
can -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting -X- _ O
than -X- _ O
GPT-3 -X- _ B-MethodName
while -X- _ O
requiring -X- _ O
only -X- _ O
0.1 -X- _ O
% -X- _ O
of -X- _ O
its -X- _ O
parameters. -X- _ O
Similarly -X- _ O
, -X- _ O
Athiwaratkun -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Paolini -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
convert -X- _ O
structured -X- _ O
prediction -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
sequence -X- _ O
tagging -X- _ O
and -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
to -X- _ O
sequence -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

Blank -X- _ O
Language -X- _ O
Modeling. -X- _ O
Donahue -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Shen -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
also -X- _ O
study -X- _ O
blanking -X- _ O
infilling -X- _ O
models. -X- _ O
Different -X- _ O
from -X- _ O
their -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
pre-train -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
blank -X- _ O
infilling -X- _ O
objectives -X- _ O
and -X- _ O
evaluate -X- _ O
their -X- _ O
performance -X- _ O
in -X- _ O
downstream -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

Conclusions -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
pretraining -X- _ O
framework -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
generation. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
conditional -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
solvable -X- _ O
by -X- _ O
autoregressive -X- _ O
models. -X- _ O
GLM -X- _ B-MethodName
unifies -X- _ O
the -X- _ O
pretraining -X- _ O
objectives -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
as -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
, -X- _ O
with -X- _ O
mixed -X- _ O
attention -X- _ O
masks -X- _ O
and -X- _ O
the -X- _ O
novel -X- _ O
2D -X- _ O
position -X- _ O
encodings. -X- _ O
Empirically -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
methods -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
can -X- _ O
effectively -X- _ O
share -X- _ O
parameters -X- _ O
for -X- _ O
different -X- _ O
tasks. -X- _ O
The -X- _ O
hyperparameters -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
pre-training -X- _ O
settings -X- _ O
are -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O

B.1 -X- _ O
SuperGLUE -X- _ B-DatasetName
The -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
consists -X- _ O
of -X- _ O
8 -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O
We -X- _ O
formulate -X- _ O
them -X- _ O
as -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
tasks -X- _ I-TaskName
, -X- _ O
following -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
cloze -X- _ O
questions -X- _ O
and -X- _ O
verbalizers -X- _ O
we -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments. -X- _ O
For -X- _ O
3 -X- _ O
tasks -X- _ O
( -X- _ O
ReCoRD -X- _ B-DatasetName
, -X- _ O
COPA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
WSC -X- _ B-DatasetName
) -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
may -X- _ O
consist -X- _ O
of -X- _ O
multiple -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
5 -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
always -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
. -X- _ O

When -X- _ O
finetuning -X- _ O
GLM -X- _ B-MethodName
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
tasks -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
the -X- _ O
input -X- _ O
using -X- _ O
the -X- _ O
cloze -X- _ O
questions -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
blank -X- _ O
with -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token. -X- _ O
Then -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
generating -X- _ O
each -X- _ O
answer -X- _ O
candidate. -X- _ O
For -X- _ O
the -X- _ O
5 -X- _ O
single-token -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
defined -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
logit -X- _ O
of -X- _ O
the -X- _ O
verbalizer -X- _ O
token. -X- _ O
For -X- _ O
the -X- _ O
3 -X- _ O
multi-token -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
log-probabilities -X- _ O
of -X- _ O
the -X- _ O
verbalizer -X- _ O
tokens. -X- _ O
Thanks -X- _ O
to -X- _ O
the -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
mechanism -X- _ O
we -X- _ O
proposed -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
all -X- _ O
the -X- _ O
log-probabilities -X- _ O
in -X- _ O
one -X- _ O
pass. -X- _ O
Then -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
using -X- _ O
the -X- _ O
groundtruth -X- _ O
label -X- _ O
and -X- _ O
update -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
baseline -X- _ O
classifiers -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
standard -X- _ O
practice -X- _ O
to -X- _ O
concatenate -X- _ O
the -X- _ O
input -X- _ O
parts -X- _ O
of -X- _ O
each -X- _ O
task -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
for -X- _ O
textual -X- _ O
entailment -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
passage -X- _ O
, -X- _ O
question -X- _ O
and -X- _ O
answer -X- _ O
for -X- _ O
ReCORD -X- _ B-DatasetName
and -X- _ O
MultiRC -X- _ B-DatasetName
) -X- _ O
and -X- _ O
add -X- _ O
a -X- _ O
classification -X- _ O
layer -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
representation. -X- _ O
We -X- _ O
also -X- _ O
implemented -X- _ O
cloze-style -X- _ O
finetuning -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
pre-trained -X- _ O
models -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
performance -X- _ O
was -X- _ O
usually -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
standard -X- _ O
classifier -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
ablation -X- _ O
study. -X- _ O
Models -X- _ O
with -X- _ O
blank-infilling -X- _ O
objectives -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
our -X- _ O
GLM -X- _ B-MethodName
, -X- _ O
benefits -X- _ O
more -X- _ O
from -X- _ O
converting -X- _ O
the -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
into -X- _ O
cloze -X- _ O
questions. -X- _ O
Thus -X- _ O
for -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
GLM -X- _ B-MethodName
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
after -X- _ O
such -X- _ O
conversion -X- _ O
in -X- _ O
our -X- _ O
main -X- _ O
results -X- _ O
. -X- _ O

B.2 -X- _ O
Sequence-to-Sequence -X- _ O
Fot -X- _ O
the -X- _ O
text -X- _ O
summarization -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
dataset -X- _ O
Gigaword -X- _ B-DatasetName
( -X- _ O
Rush -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
model -X- _ O
fine-tuning -X- _ O
and -X- _ O
evaluation. -X- _ O
We -X- _ O
finetune -X- _ O
GLM -X- _ B-MethodName
LARGE -X- _ I-MethodName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
4 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
AdamW -X- _ O
optimizer -X- _ O
. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
has -X- _ O
a -X- _ O
peak -X- _ O
value -X- _ O
of -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
warmup -X- _ O
over -X- _ O
the -X- _ O
6 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
and -X- _ O
a -X- _ O
linear -X- _ O
decay. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
label -X- _ B-HyperparameterName
smoothing -X- _ I-HyperparameterName
with -X- _ O
rate -X- _ O
0.1 -X- _ B-HyperparameterValue
( -X- _ O
Pereyra -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ B-HyperparameterName
document -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
192 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
summary -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
32. -X- _ B-HyperparameterValue
During -X- _ O
decoding -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
remove -X- _ O
repeated -X- _ O
trigrams. -X- _ O
We -X- _ O
tweak -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
length -X- _ O
penalty -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set. -X- _ O
The -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
Rouge-1 -X- _ B-MetricName
, -X- _ O
Rouge-2 -X- _ B-MetricName
, -X- _ O
and -X- _ O
Rouge-L -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
question -X- _ O
generation -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
dataset -X- _ O
split -X- _ O
of -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
optimizer -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
abstractive -X- _ O
summarization. -X- _ O
The -X- _ O
maximum -X- _ B-HyperparameterName
passage -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
464 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
question -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
48. -X- _ B-HyperparameterValue
During -X- _ O
decoding -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
5 -X- _ B-HyperparameterValue
and -X- _ O
tweak -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
length -X- _ O
penalty -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set. -X- _ O
The -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
BLEU-2 -X- _ B-MetricName
, -X- _ O
BLEU-3 -X- _ B-MetricName
, -X- _ O
BLEU-4 -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Denkowski -X- _ O
and -X- _ O
Lavie -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
Rouge-L -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

Results -X- _ O
of -X- _ O
T5 -X- _ B-DatasetName
Large -X- _ I-DatasetName
on -X- _ O
XSum -X- _ B-DatasetName
are -X- _ O
obtained -X- _ O
by -X- _ O
running -X- _ O
the -X- _ O
summarization -X- _ O
script -X- _ O
provided -X- _ O
by -X- _ O
Huggingface -X- _ O
transformers -X- _ O
6 -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
other -X- _ O
results -X- _ O
of -X- _ O
well -X- _ O
studied -X- _ O
for -X- _ O
language -X- _ O
modeling. -X- _ O
Perplexity -X- _ O
is -X- _ O
the -X- _ O
exponentiation -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
cross -X- _ O
entropy -X- _ O
of -X- _ O
a -X- _ O
corpus. -X- _ O
LAMBDA -X- _ B-DatasetName
is -X- _ O
a -X- _ O
cloze-style -X- _ O
dataset -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
long-range -X- _ O
dependency -X- _ O
modeling. -X- _ O
Each -X- _ O
example -X- _ O
is -X- _ O
a -X- _ O
passage -X- _ O
consisting -X- _ O
of -X- _ O
4-5 -X- _ O
sentences -X- _ O
with -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
missing -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
passage. -X- _ O
Since -X- _ O
we -X- _ O
use -X- _ O
WordPiece -X- _ O
tokenization -X- _ O
, -X- _ O
a -X- _ O
word -X- _ O
can -X- _ O
be -X- _ O
split -X- _ O
into -X- _ O
several -X- _ O
subword -X- _ O
units. -X- _ O
We -X- _ O
use -X- _ O
teacher -X- _ O
forcing -X- _ O
and -X- _ O
consider -X- _ O
the -X- _ O
prediction -X- _ O
correct -X- _ O
only -X- _ O
when -X- _ O
all -X- _ O
the -X- _ O
predicted -X- _ O
tokens -X- _ O
are -X- _ O
correct -X- _ O
. -X- _ O

C -X- _ O
Results -X- _ O
on -X- _ O
Other -X- _ O
NLU -X- _ B-TaskName
Benchmarks -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
another -X- _ O
widely-used -X- _ O
NLU -X- _ B-TaskName
benchmark -X- _ O
, -X- _ O
including -X- _ O
single -X- _ O
sentence -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
sentiment -X- _ O
analysis -X- _ O
( -X- _ O
Socher -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
sentence -X- _ O
pair -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
text -X- _ O
similarity -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dagan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
benchmark -X- _ O
is -X- _ O
usually -X- _ O
considered -X- _ O
as -X- _ O
less -X- _ O
challenging -X- _ O
than -X- _ O
Super-GLUE. -X- _ B-DatasetName
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
extractive -X- _ O
question -X- _ O
answering -X- _ O
benchmark. -X- _ O
We -X- _ O
further -X- _ O
compare -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
two -X- _ O
benchmarks -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Tables -X- _ O
9 -X- _ O
and -X- _ O
10. -X- _ O
On -X- _ O
the -X- _ O
two -X- _ O
benchmarks -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
still -X- _ O
outperform -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
smaller -X- _ O
margin -X- _ O
. -X- _ O

D -X- _ O
Text -X- _ O
Generation -X- _ O
Samples -X- _ O
We -X- _ O
show -X- _ O
texts -X- _ O
generated -X- _ O
by -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
given -X- _ O
unseen -X- _ O
contexts -X- _ O
randomly -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O
We -X- _ O
use -X- _ O
top-k -X- _ O
random -X- _ O
sampling -X- _ O
with -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
40 -X- _ B-HyperparameterValue
for -X- _ O
generation -X- _ O
and -X- _ O
set -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ O
512. -X- _ B-HyperparameterValue
Some -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
are -X- _ O
cut -X- _ O
short. -X- _ O
Simpsons -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
captain -X- _ O
Billy -X- _ O
Higgledypig -X- _ O
, -X- _ O
but -X- _ O
his -X- _ O
character -X- _ O
was -X- _ O
only -X- _ O
a -X- _ O
one-time -X- _ O
recurring -X- _ O
character -X- _ O
in -X- _ O
the -X- _ O
series -X- _ O
' -X- _ O
first -X- _ O
six -X- _ O
seasons. -X- _ O
He -X- _ O
later -X- _ O
appeared -X- _ O
as -X- _ O
a -X- _ O
regular -X- _ O
for -X- _ O
the -X- _ O
show -X- _ O
's -X- _ O
final -X- _ O
six -X- _ O
seasons -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
frequent -X- _ O
guest -X- _ O
in -X- _ O
the -X- _ O
show -X- _ O
since -X- _ O
. -X- _ O

Example -X- _ O
D.3. -X- _ O
Corona -X- _ O
was -X- _ O
a -X- _ O
station -X- _ O
along -X- _ O
the -X- _ O
port -X- _ O
Washington -X- _ O
branch -X- _ O
of -X- _ O
the -X- _ O
long -X- _ O
island -X- _ O
rail -X- _ O
road -X- _ O
in -X- _ O
the -X- _ O
Corona -X- _ O
section -X- _ O
of -X- _ O
queens -X- _ O
, -X- _ O
New -X- _ O
York -X- _ O
City. -X- _ O
It -X- _ O
was -X- _ O
one -X- _ O
of -X- _ O
two -X- _ O
stations -X- _ O
built -X- _ O
by -X- _ O
the -X- _ O
flushing -X- _ O
railroad -X- _ O
in -X- _ O
Corona -X- _ O
, -X- _ O
this -X- _ O
one -X- _ O
having -X- _ O
been -X- _ O
at -X- _ O
Grand -X- _ O
Avenue -X- _ O
( -X- _ O
later -X- _ O
called -X- _ O
National -X- _ O
Avenue -X- _ O
, -X- _ O
now -X- _ O
National -X- _ O
Street -X- _ O
) -X- _ O
and -X- _ O
45th -X- _ O
Avenue. -X- _ O
GLM -X- _ B-MethodName
: -X- _ O
It -X- _ O
had -X- _ O
a -X- _ O
brick -X- _ O
entrance -X- _ O
building -X- _ O
next -X- _ O
to -X- _ O
the -X- _ O
tracks -X- _ O
, -X- _ O
and -X- _ O
one -X- _ O
platform -X- _ O
with -X- _ O
2 -X- _ O
side -X- _ O
platforms. -X- _ O
The -X- _ O
station -X- _ O
burned -X- _ O
down -X- _ O
and -X- _ O
was -X- _ O
rebuilt -X- _ O
in -X- _ O
1908. -X- _ O
The -X- _ O
station -X- _ O
closed -X- _ O
on -X- _ O
september -X- _ O
15 -X- _ O
, -X- _ O
1927 -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
train -X- _ O
service -X- _ O
transferred -X- _ O
from -X- _ O
Grand -X- _ O
Avenue -X- _ O
to -X- _ O
45th -X- _ O
Avenue. -X- _ O
There -X- _ O
were -X- _ O
plans -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
subway -X- _ O
extension -X- _ O
to -X- _ O
Corona -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
was -X- _ O
never -X- _ O
built. -X- _ O
In -X- _ O
the -X- _ O
1980s -X- _ O
, -X- _ O
two -X- _ O
stations -X- _ O
were -X- _ O
constructed -X- _ O
on -X- _ O
the -X- _ O
line -X- _ O
, -X- _ O
Corona -X- _ O
Road -X- _ O
and -X- _ O
Corona -X- _ O
Park. -X- _ O
The -X- _ O
new -X- _ O
Corona -X- _ O
station -X- _ O
opened -X- _ O
in -X- _ O
1988 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
Corona -X- _ O
station -X- _ O
was -X- _ O
demolished -X- _ O
. -X- _ O

GLM -X- _ B-MethodName
: -X- _ O
In -X- _ O
his -X- _ O
four-year -X- _ O
NFL -X- _ O
career -X- _ O
, -X- _ O
he -X- _ O
played -X- _ O
in -X- _ O
33 -X- _ O
games -X- _ O
and -X- _ O
started -X- _ O
14 -X- _ O
, -X- _ O
registering -X- _ O
62 -X- _ O
career -X- _ O
interceptions. -X- _ O
He -X- _ O
completed -X- _ O
his -X- _ O
NFL -X- _ O
career -X- _ O
with -X- _ O
five -X- _ O
interceptions. -X- _ O
Smith -X- _ O
was -X- _ O
born -X- _ O
in -X- _ O
La -X- _ O
Canada -X- _ O
Flintridge -X- _ O
, -X- _ O
Michigan -X- _ O
, -X- _ O
in -X- _ O
1938. -X- _ O
He -X- _ O
attended -X- _ O
Bishop -X- _ O
O -X- _ O
' -X- _ O
Dowd -X- _ O
high -X- _ O
school -X- _ O
in -X- _ O
Flintridge. -X- _ O
Smith -X- _ O
' -X- _ O
s -X- _ O
father -X- _ O
was -X- _ O
a -X- _ O
pharmacist. -X- _ O
He -X- _ O
graduated -X- _ O
from -X- _ O
Michigan -X- _ O
State -X- _ O
University -X- _ O
in -X- _ O
1958 -X- _ O
with -X- _ O
a -X- _ O
degree -X- _ O
in -X- _ O
business -X- _ O
administration. -X- _ O
Smith -X- _ O
played -X- _ O
for -X- _ O
the -X- _ O
Michigan -X- _ O
Wolverines -X- _ O
football -X- _ O
team -X- _ O
from -X- _ O
1959 -X- _ O
to -X- _ O
1963. -X- _ O
In -X- _ O
his -X- _ O
two -X- _ O
years -X- _ O
as -X- _ O
a -X- _ O
reserve -X- _ O
cornerback -X- _ O
, -X- _ O
he -X- _ O
led -X- _ O
the -X- _ O
conference -X- _ O
in -X- _ O
interceptions -X- _ O
with -X- _ O
five. -X- _ O
In -X- _ O
1962 -X- _ O
, -X- _ O
he -X- _ O
set -X- _ O
the -X- _ O
Wolverines -X- _ O
' -X- _ O
all-time -X- _ O
interception -X- _ O
record -X- _ O
with -X- _ O
13 -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
second -X- _ O
overall -X- _ O
in -X- _ O
the -X- _ O
1962 -X- _ O
season -X- _ O
's -X- _ O
Heisman -X- _ O
Trophy -X- _ O
voting. -X- _ O
Smith -X- _ O
also -X- _ O
won -X- _ O
the -X- _ O
Dick -X- _ O
Butkus -X- _ O
award -X- _ O
as -X- _ O
the -X- _ O
nation -X- _ O
's -X- _ O
outstanding -X- _ O
linebacker. -X- _ O
In -X- _ O
1961 -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
Los -X- _ O
Angeles -X- _ O
Times -X- _ O
" -X- _ O
wrote -X- _ O
that -X- _ O
Smith -X- _ O
" -X- _ O
is -X- _ O
an -X- _ O
outstanding -X- _ O
pass -X- _ O
rusher -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
almost -X- _ O
100 -X- _ O
yards -X- _ O
per -X- _ O
punt -X- _ O
return. -X- _ O
" -X- _ O
Smith -X- _ O
was -X- _ O
inducted -X- _ O
into -X- _ O
the -X- _ O
university -X- _ O
of -X- _ O
Michigan -X- _ O
athletic -X- _ O
hall -X- _ O
of -X- _ O
honor -X- _ O
in -X- _ O
1989 -X- _ O
and -X- _ O
the -X- _ O
national -X- _ O
football -X- _ O
foundation -X- _ O
hall -X- _ O
of -X- _ O
fame -X- _ O
in -X- _ O
1991. -X- _ O
He -X- _ O
was -X- _ O
elected -X- _ O
to -X- _ O
the -X- _ O
Michigan -X- _ O
sports -X- _ O
hall -X- _ O
of -X- _ O
fame -X- _ O
in -X- _ O
1995. -X- _ O
Smith -X- _ O
earned -X- _ O
the -X- _ O
honor -X- _ O
because -X- _ O
of -X- _ O
his -X- _ O
accomplishments -X- _ O
prior -X- _ O
to -X- _ O
his -X- _ O
NFL -X- _ O
career. -X- _ O
He -X- _ O
was -X- _ O
one -X- _ O
of -X- _ O
four -X- _ O
Michigan -X- _ O
players -X- _ O
honored -X- _ O
as -X- _ O
first-overall -X- _ O
selections -X- _ O
in -X- _ O
the -X- _ O
1964 -X- _ O
NFL -X- _ O
draft. -X- _ O
The -X- _ O
others -X- _ O
were -X- _ O
Joe -X- _ O
Namath -X- _ O
, -X- _ O
Bill -X- _ O
Nelsen -X- _ O
, -X- _ O
and -X- _ O
Jerry -X- _ O
Kramer. -X- _ O
In -X- _ O
1966 -X- _ O
, -X- _ O
the -X- _ O
NFL -X- _ O
gave -X- _ O
players -X- _ O
$ -X- _ O
300,000 -X- _ O
a -X- _ O
season -X- _ O
to -X- _ O
play -X- _ O
football. -X- _ O
After -X- _ O
his -X- _ O
rookie -X- _ O
season -X- _ O
, -X- _ O
he -X- _ O
was -X- _ O
not -X- _ O
selected -X- _ O
to -X- _ O
play -X- _ O
in -X- _ O
the -X- _ O
1966 -X- _ O
pro -X- _ O
bowl. -X- _ O
On -X- _ O
January -X- _ O
13 -X- _ O
, -X- _ O
1966 -X- _ O
, -X- _ O
the -X- _ O
Rams -X- _ O
traded -X- _ O
smith -X- _ O
to -X- _ O
the -X- _ O
Detroit -X- _ O
Lions -X- _ O
for -X- _ O
Paul -X- _ O
Hornung -X- _ O
, -X- _ O
and -X- _ O
later -X- _ O
that -X- _ O
year -X- _ O
he -X- _ O
was -X- _ O
traded -X- _ O
to -X- _ O
the -X- _ O
Lions -X- _ O
for -X- _ O
Ray -X- _ O
" -X- _ O
the -X- _ O
Lion -X- _ O
" -X- _ O
Jones -X- _ O
in -X- _ O
exchange -X- _ O
for -X- _ O
Linebacker -X- _ O
Jim -X- _ O
" -X- _ O
the -X- _ O
Hawk -X- _ O
" -X- _ O
Johnson. -X- _ O
On -X- _ O
September -X- _ O
10 -X- _ O
, -X- _ O
1968 -X- _ O
, -X- _ O
he -X- _ O
was -X- _ O
traded -X- _ O
back -X- _ O
to -X- _ O
Los -X- _ O
Angeles -X- _ O
for -X- _ O
a -X- _ O
second -X- _ O
round -X- _ O
pick -X- _ O
in -X- _ O
the -X- _ O
1970 -X- _ O
draft. -X- _ O
He -X- _ O
was -X- _ O
also -X- _ O
traded -X- _ O
to -X- _ O
the -X- _ O
St. -X- _ O
Louis -X- _ O
Cardinals -X- _ O
for -X- _ O
a -X- _ O
second -X- _ O
round -X- _ O
pick -X- _ O
in -X- _ O
the -X- _ O
1970 -X- _ O
draft. -X- _ O
On -X- _ O
June -X- _ O
2 -X- _ O
, -X- _ O
1970 -X- _ O
he -X- _ O
was -X- _ O
cut -X- _ O
by -X- _ O
the -X- _ O
Cardinals. -X- _ O
On -X- _ O
November -X- _ O
15 -X- _ O
, -X- _ O
1970 -X- _ O
, -X- _ O
the -X- _ O
Los -X- _ O
Angeles -X- _ O
Rams -X- _ O
acquired -X- _ O
Smith -X- _ O
from -X- _ O
the -X- _ O
Lions -X- _ O
in -X- _ O
exchange -X- _ O
for -X- _ O
Linebacker -X- _ O
Tony -X- _ O
Harris. -X- _ O
The -X- _ O
Rams -X- _ O
waived -X- _ O
Smith -X- _ O
during -X- _ O
the -X- _ O
September -X- _ O
1 -X- _ O
, -X- _ O
1972 -X- _ O
offseason. -X- _ O
Smith -X- _ O
's -X- _ O
number -X- _ O
at -X- _ O
Michigan -X- _ O
State -X- _ O
was -X- _ O
# -X- _ O
7 -X- _ O
in -X- _ O
1969 -X- _ O
. -X- _ O

A.1 -X- _ O
Datasets -X- _ O
To -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
Book-Corpus -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
Wikipedia -X- _ B-DatasetName
used -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
pretraining -X- _ O
datasets -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
which -X- _ O
consist -X- _ O
of -X- _ O
BookCorups -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
16GB -X- _ O
) -X- _ O
, -X- _ O
CC-News -X- _ B-DatasetName
( -X- _ O
the -X- _ O
English -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
Com-monCrawl -X- _ O
News -X- _ O
dataset -X- _ O
3 -X- _ O
76GB -X- _ O
) -X- _ O
, -X- _ O
OpenWebText -X- _ B-DatasetName
( -X- _ O
web -X- _ O
content -X- _ O
extracted -X- _ O
from -X- _ O
URLs -X- _ O
shared -X- _ O
on -X- _ O
Reddit -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
three -X- _ O
upvotes -X- _ O
( -X- _ O
Gokaslan -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
38GB -X- _ O
) -X- _ O
and -X- _ O
Stories -X- _ O
( -X- _ O
subset -X- _ O
of -X- _ O
Common-Crawl -X- _ O
data -X- _ O
filtered -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
story-like -X- _ O
style -X- _ O
of -X- _ O
Winograd -X- _ O
schemas -X- _ O
( -X- _ O
Trinh -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
31GB -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Stories -X- _ O
dataset -X- _ O
is -X- _ O
no -X- _ O
longer -X- _ O
publicly -X- _ O
available -X- _ O
4 -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
Stories -X- _ O
dataset -X- _ O
and -X- _ O
replace -X- _ O
OpenWebText -X- _ B-DatasetName
with -X- _ O
OpenWebText2 -X- _ B-DatasetName
5 -X- _ O
( -X- _ O
66GB -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
CC-News -X- _ O
dataset -X- _ O
is -X- _ O
not -X- _ O
publicly -X- _ O
available -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
CC-News-en -X- _ B-DatasetName
published -X- _ O
by -X- _ O
( -X- _ O
Mackenzie -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
datasets -X- _ O
used -X- _ O
total -X- _ O
158GB -X- _ O
of -X- _ O
uncompressed -X- _ O
texts -X- _ O
, -X- _ O
close -X- _ O
in -X- _ O
size -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
's -X- _ O
160GB -X- _ O
datasets -X- _ O
. -X- _ O

A.2 -X- _ O
Hyperparameters -X- _ O
The -X- _ O
hyperparameters -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
are -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
used -X- _ O
by -X- _ O
BERT. -X- _ B-MethodName
For -X- _ O
trade-off -X- _ O
of -X- _ O
training -X- _ O
speed -X- _ O
and -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
batch -X- _ O
size -X- _ O
256 -X- _ O
and -X- _ O
1,000,000 -X- _ O
training -X- _ O
steps -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
1024 -X- _ O
and -X- _ O
200,000 -X- _ O
training -X- _ O
steps -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
Since -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
is -X- _ O
smaller -X- _ O
, -X- _ O
we -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
steps -X- _ O
to -X- _ O
120,000 -X- _ O
to -X- _ O
speed -X- _ O
up -X- _ O
pre-training. -X- _ O
The -X- _ O
hyperparameters -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Sent -X- _ I-MethodName
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
except -X- _ O
Transformer -X- _ O
architecture -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
410M -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
515M -X- _ I-MethodName
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
The -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
64 -X- _ O
V100 -X- _ O
GPUs -X- _ O
for -X- _ O
200K -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1024 -X- _ B-HyperparameterValue
and -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
takes -X- _ O
about -X- _ O
2.5 -X- _ O
days -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O

To -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
, -X- _ O
we -X- _ O
follow -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
of -X- _ O
RoBERTa. -X- _ B-MethodName
The -X- _ O
main -X- _ O
difference -X- _ O
baselines -X- _ O
on -X- _ O
seq2seq -X- _ B-TaskName
tasks -X- _ O
are -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
papers -X- _ O
. -X- _ O

B.3 -X- _ O
Text -X- _ B-TaskName
Infilling -X- _ I-TaskName
We -X- _ O
follow -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
evaluate -X- _ O
text -X- _ B-TaskName
infilling -X- _ I-TaskName
performance -X- _ O
on -X- _ O
the -X- _ O
Yahoo -X- _ B-DatasetName
Answers -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
100K -X- _ B-HyperparameterValue
/ -X- _ I-HyperparameterValue
10K -X- _ I-HyperparameterValue
/ -X- _ I-HyperparameterValue
10K -X- _ I-HyperparameterValue
documents -X- _ O
for -X- _ O
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
valid -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
respectively. -X- _ O
The -X- _ O
average -X- _ O
document -X- _ O
length -X- _ O
is -X- _ O
78 -X- _ O
words. -X- _ O
To -X- _ O
construct -X- _ O
the -X- _ O
text -X- _ O
infilling -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
mask -X- _ O
a -X- _ O
given -X- _ O
ratio -X- _ O
r -X- _ B-HyperparameterName
∈ -X- _ O
{ -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
• -X- _ I-HyperparameterValue
• -X- _ I-HyperparameterValue
• -X- _ I-HyperparameterValue
50 -X- _ I-HyperparameterValue
% -X- _ I-HyperparameterValue
} -X- _ O
of -X- _ O
each -X- _ O
document -X- _ O
's -X- _ O
tokens -X- _ O
and -X- _ O
the -X- _ O
contiguous -X- _ O
masked -X- _ O
tokens -X- _ O
are -X- _ O
collapsed -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
blank. -X- _ O
We -X- _ O
finetune -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
dynamic -X- _ O
masking -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
blanks -X- _ O
are -X- _ O
randomly -X- _ O
generated -X- _ O
at -X- _ O
training -X- _ O
time. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
sequence-to-sequence -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
AdamW -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
peak -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
1e-5 -X- _ B-HyperparameterValue
and -X- _ O
6 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
warm-up -X- _ B-HyperparameterName
linear -X- _ O
scheduler -X- _ O
. -X- _ O

For -X- _ O
comparison -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
test -X- _ O
set -X- _ O
constructed -X- _ O
by -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
metric -X- _ O
is -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
the -X- _ O
infilled -X- _ O
text -X- _ O
against -X- _ O
the -X- _ O
original -X- _ O
document. -X- _ O
We -X- _ O
compare -X- _ O
with -X- _ O
two -X- _ O
baselines -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
learns -X- _ O
a -X- _ O
left-to-right -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
blank -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BLM -X- _ B-MethodName
proposed -X- _ O
by -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
blank -X- _ O
with -X- _ O
arbitrary -X- _ O
trajectories -X- _ O
. -X- _ O

B.4 -X- _ O
Language -X- _ O
Modeling -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
of -X- _ O
language -X- _ O
modeling -X- _ O
with -X- _ O
perplexity -X- _ B-MetricName
on -X- _ O
BookWiki -X- _ B-DatasetName
and -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
LAMBDA -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Paperno -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

GLM -X- _ B-MethodName
: -X- _ O
He -X- _ O
was -X- _ O
a -X- _ O
voice -X- _ O
actor -X- _ O
for -X- _ O
the -X- _ O
" -X- _ O
X-Men -X- _ O
" -X- _ O
cartoon -X- _ O
series. -X- _ O
He -X- _ O
was -X- _ O
also -X- _ O
a -X- _ O
voice -X- _ O
actor -X- _ O
for -X- _ O
" -X- _ O
the -X- _ O
Simpsons -X- _ O
" -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
" -X- _ O
the -X- _ O
marvelous -X- _ O
misadventures -X- _ O
of -X- _ O
superman. -X- _ O
He -X- _ O
also -X- _ O
has -X- _ O
voiced -X- _ O
characters -X- _ O
in -X- _ O
" -X- _ O
the -X- _ O
legend -X- _ O
of -X- _ O
korra -X- _ O
" -X- _ O
He -X- _ O
has -X- _ O
appeared -X- _ O
on -X- _ O
several -X- _ O
television -X- _ O
series -X- _ O
, -X- _ O
including -X- _ O
" -X- _ O
the -X- _ O
simpsons -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
the -X- _ O
x-files -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
heroes -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
the -X- _ O
simpsons -X- _ O
movie -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
captain -X- _ O
billy -X- _ O
higgledy-pig -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
web -X- _ O
series -X- _ O
" -X- _ O
krusty -X- _ O
mysteries -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
Colonel -X- _ O
Trungus. -X- _ O
He -X- _ O
wrote -X- _ O
for -X- _ O
" -X- _ O
the -X- _ O
Guardian -X- _ O
" -X- _ O
newspaper. -X- _ O
Jonathan -X- _ O
Terry -X- _ O
was -X- _ O
born -X- _ O
in -X- _ O
London. -X- _ O
Terry -X- _ O
grew -X- _ O
up -X- _ O
in -X- _ O
Surrey -X- _ O
, -X- _ O
England -X- _ O
and -X- _ O
attended -X- _ O
the -X- _ O
University -X- _ O
of -X- _ O
Sussex -X- _ O
in -X- _ O
the -X- _ O
United -X- _ O
Kingdom -X- _ O
, -X- _ O
graduating -X- _ O
with -X- _ O
a -X- _ O
degree -X- _ O
in -X- _ O
english -X- _ O
literature. -X- _ O
He -X- _ O
was -X- _ O
a -X- _ O
guest -X- _ O
lecturer -X- _ O
at -X- _ O
King -X- _ O
's -X- _ O
College -X- _ O
London -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
took -X- _ O
two -X- _ O
years -X- _ O
of -X- _ O
acting -X- _ O
courses -X- _ O
at -X- _ O
the -X- _ O
brit -X- _ O
school -X- _ O
of -X- _ O
acting -X- _ O
to -X- _ O
prepare -X- _ O
for -X- _ O
his -X- _ O
future -X- _ O
career -X- _ O
in -X- _ O
the -X- _ O
entertainment -X- _ O
industry. -X- _ O
Terry -X- _ O
first -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
TV -X- _ O
series -X- _ O
" -X- _ O
the -X- _ O

Flow-Adapter -X- _ B-MethodName
Architecture -X- _ O
for -X- _ O
Unsupervised -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
flow-adapter -X- _ B-MethodName
architecture -X- _ O
for -X- _ O
unsupervised -X- _ O
NMT. -X- _ B-TaskName
It -X- _ O
leverages -X- _ O
normalizing -X- _ O
flows -X- _ O
to -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
sentence-level -X- _ O
latent -X- _ O
representations -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
subsequently -X- _ O
used -X- _ O
in -X- _ O
conjunction -X- _ O
with -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
task. -X- _ O
The -X- _ O
primary -X- _ O
novelties -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
capturing -X- _ O
language-specific -X- _ O
sentence -X- _ O
representations -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
using -X- _ O
normalizing -X- _ O
flows -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
transformation -X- _ O
of -X- _ O
these -X- _ O
latent -X- _ O
representations -X- _ O
for -X- _ O
translating -X- _ O
from -X- _ O
one -X- _ O
language -X- _ O
to -X- _ O
another. -X- _ O
This -X- _ O
architecture -X- _ O
allows -X- _ O
for -X- _ O
unsupervised -X- _ O
training -X- _ O
of -X- _ O
each -X- _ O
language -X- _ O
independently. -X- _ O
While -X- _ O
there -X- _ O
is -X- _ O
prior -X- _ O
work -X- _ O
on -X- _ O
latent -X- _ O
variables -X- _ O
for -X- _ O
supervised -X- _ O
MT -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
work -X- _ O
that -X- _ O
uses -X- _ O
latent -X- _ O
variables -X- _ O
and -X- _ O
normalizing -X- _ O
flows -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
MT. -X- _ I-TaskName
We -X- _ O
obtain -X- _ O
competitive -X- _ O
results -X- _ O
on -X- _ O
several -X- _ O
unsupervised -X- _ B-TaskName
MT -X- _ I-TaskName
benchmarks -X- _ O
. -X- _ O

Introduction -X- _ O
Recent -X- _ O
advances -X- _ O
in -X- _ O
deep -X- _ O
learning -X- _ O
have -X- _ O
boosted -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
NMT -X- _ B-TaskName
) -X- _ O
. -X- _ O
Typical -X- _ O
NMT -X- _ B-TaskName
models -X- _ O
leverage -X- _ O
an -X- _ O
encoder-decoder -X- _ O
framework -X- _ O
( -X- _ O
Cho -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
NMT -X- _ B-TaskName
models -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
datahungry -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
significantly -X- _ O
influences -X- _ O
the -X- _ O
performance -X- _ O
( -X- _ O
Zoph -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
large-scale -X- _ O
bilingual -X- _ O
corpora -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
a -X- _ O
relatively -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
languages -X- _ O
( -X- _ O
Al-Onaizan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
bilingual -X- _ O
corpora -X- _ O
, -X- _ O
monolingual -X- _ O
corpora -X- _ O
are -X- _ O
much -X- _ O
easier -X- _ O
to -X- _ O
obtain -X- _ O
. -X- _ O

Unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
, -X- _ O
compared -X- _ O
with -X- _ O
supervised -X- _ O
NMT -X- _ B-TaskName
, -X- _ O
aims -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
without -X- _ O
parallel -X- _ O
data. -X- _ O
Some -X- _ O
early -X- _ O
works -X- _ O
( -X- _ O
Irvine -X- _ O
and -X- _ O
Callison-Burch -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sennrich -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016b -X- _ O
; -X- _ O
Cheng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
used -X- _ O
monolingual -X- _ O
corpora -X- _ O
to -X- _ O
boost -X- _ O
performance -X- _ O
when -X- _ O
parallel -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
abundant. -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
and -X- _ O
Artetxe -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
explored -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
training -X- _ O
a -X- _ O
model -X- _ O
relying -X- _ O
only -X- _ O
on -X- _ O
mono- -X- _ O
lingual -X- _ O
corpora. -X- _ O
They -X- _ O
both -X- _ O
leveraged -X- _ O
a -X- _ O
sharedencoder -X- _ O
architecture -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
generate -X- _ O
universal -X- _ O
representations -X- _ O
, -X- _ O
trained -X- _ O
with -X- _ O
techniques -X- _ O
such -X- _ O
as -X- _ O
initial -X- _ O
word-by-word -X- _ O
translation -X- _ O
through -X- _ O
bilingual -X- _ O
dictionaries -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
; -X- _ O
Artetxe -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
denoising -X- _ O
auto-encoding -X- _ O
( -X- _ O
DAE -X- _ O
) -X- _ O
( -X- _ O
Vincent -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
iterative -X- _ O
back-translation -X- _ O
( -X- _ O
BT -X- _ O
) -X- _ O
( -X- _ O
Hoang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
argued -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
bottleneck -X- _ O
in -X- _ O
such -X- _ O
shared-encoder -X- _ O
models -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
shared -X- _ O
encoder -X- _ O
that -X- _ O
maps -X- _ O
pairs -X- _ O
of -X- _ O
sentences -X- _ O
of -X- _ O
different -X- _ O
languages -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
shared -X- _ O
latent -X- _ O
space. -X- _ O
They -X- _ O
proposed -X- _ O
to -X- _ O
use -X- _ O
two -X- _ O
independent -X- _ O
encoders -X- _ O
sharing -X- _ O
part -X- _ O
of -X- _ O
their -X- _ O
weights -X- _ O
and -X- _ O
achieved -X- _ O
better -X- _ O
results. -X- _ O
But -X- _ O
all -X- _ O
of -X- _ O
those -X- _ O
aforementioned -X- _ O
approaches -X- _ O
trained -X- _ O
the -X- _ O
translation -X- _ O
models -X- _ O
almost -X- _ O
from -X- _ O
scratch -X- _ O
( -X- _ O
with -X- _ O
only -X- _ O
some -X- _ O
prior -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
pre-trained -X- _ O
embeddings -X- _ O
) -X- _ O
and -X- _ O
therefore -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
further -X- _ O
advance -X- _ O
their -X- _ O
performance -X- _ O
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
advance -X- _ O
in -X- _ O
pre-trained -X- _ O
models -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
researchers -X- _ O
have -X- _ O
begun -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
using -X- _ O
pre-trained -X- _ O
models -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
NMT. -X- _ I-TaskName
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
extended -X- _ O
the -X- _ O
pre-training -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
language -X- _ O
to -X- _ O
multiple -X- _ O
languages -X- _ O
, -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
cross-lingual -X- _ O
pre-training. -X- _ O
By -X- _ O
using -X- _ O
pre-trained -X- _ B-MethodName
cross-language -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
XLMs -X- _ B-MethodName
) -X- _ O
to -X- _ O
initialize -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
they -X- _ O
achieved -X- _ O
good -X- _ O
unsupervised -X- _ O
MT -X- _ O
performance -X- _ O
on -X- _ O
multiple -X- _ O
language -X- _ O
pairs. -X- _ O
In -X- _ O
related -X- _ O
work -X- _ O
, -X- _ O
Song -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
proposed -X- _ O
masked -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
pre-training -X- _ O
( -X- _ O
MASS -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
directly -X- _ O
pre-trains -X- _ O
a -X- _ O
whole -X- _ O
encoder-decoder -X- _ O
model. -X- _ O
Üstün -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
language-specific -X- _ O
denoising-adapter -X- _ O
architecture -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
multilingual -X- _ O
modeling -X- _ O
capacity -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
model -X- _ O
mBART -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
used -X- _ O
these -X- _ O
adapters -X- _ O
for -X- _ O
multilingual -X- _ B-TaskName
unsupervised -X- _ I-TaskName
NMT. -X- _ I-TaskName
Although -X- _ O
these -X- _ O
adapters -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
monolingual -X- _ O
data -X- _ O
only -X- _ O
, -X- _ O
the -X- _ O
finetuning -X- _ O
step -X- _ O
relies -X- _ O
on -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O

Current -X- _ O
NMT -X- _ B-TaskName
frameworks -X- _ O
rely -X- _ O
heavily -X- _ O
on -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
capture -X- _ O
alignments. -X- _ O
However -X- _ O
, -X- _ O
attention-based -X- _ O
context -X- _ O
vectors -X- _ O
can -X- _ O
fail -X- _ O
to -X- _ O
extract -X- _ O
sufficiently -X- _ O
accurate -X- _ O
sentence-level -X- _ O
semantics -X- _ O
and -X- _ O
thus -X- _ O
result -X- _ O
in -X- _ O
incorrect -X- _ O
translations -X- _ O
or -X- _ O
translation -X- _ O
ambiguity -X- _ O
( -X- _ O
Tu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
several -X- _ O
variational -X- _ O
frameworks -X- _ O
for -X- _ O
modeling -X- _ O
the -X- _ O
translation -X- _ O
process -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Setiawan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
approaches -X- _ O
incorporate -X- _ O
sentence-level -X- _ O
latent -X- _ O
representations -X- _ O
into -X- _ O
NMT. -X- _ B-TaskName
A -X- _ O
latent -X- _ O
representation -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
fixed-size -X- _ O
continuous -X- _ O
vector -X- _ O
from -X- _ O
an -X- _ O
unknown -X- _ O
distribution -X- _ O
that -X- _ O
captures -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
a -X- _ O
source -X- _ O
sentence. -X- _ O
The -X- _ O
target -X- _ O
sentence -X- _ O
is -X- _ O
then -X- _ O
generated -X- _ O
from -X- _ O
this -X- _ O
latent -X- _ O
representation -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
transformation -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
commonly -X- _ O
found -X- _ O
in -X- _ O
transformer -X- _ O
architectures. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
learns -X- _ O
incorrect -X- _ O
alignments -X- _ O
, -X- _ O
the -X- _ O
latent -X- _ O
representation -X- _ O
plays -X- _ O
a -X- _ O
complementary -X- _ O
role -X- _ O
in -X- _ O
guiding -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O

Prior -X- _ O
work -X- _ O
in -X- _ O
this -X- _ O
vein -X- _ O
has -X- _ O
only -X- _ O
been -X- _ O
conducted -X- _ O
in -X- _ O
supervised -X- _ O
NMT. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
flow-adapter -X- _ B-MethodName
architecture -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
NMT. -X- _ I-TaskName
Similar -X- _ O
to -X- _ O
variational -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
sentence-level -X- _ O
representations. -X- _ O
However -X- _ O
, -X- _ O
unlike -X- _ O
variational -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
model -X- _ O
the -X- _ O
distribution -X- _ O
in -X- _ O
an -X- _ O
implicit -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
normalizing -X- _ O
flows -X- _ O
to -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages. -X- _ O
Secondly -X- _ O
, -X- _ O
different -X- _ O
from -X- _ O
some -X- _ O
previous -X- _ O
unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
models -X- _ O
that -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
share -X- _ O
a -X- _ O
common -X- _ O
semantic -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
the -X- _ O
representations -X- _ O
are -X- _ O
different -X- _ O
because -X- _ O
of -X- _ O
language-specific -X- _ O
characteristics. -X- _ O
Hence -X- _ O
they -X- _ O
are -X- _ O
modeled -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
language. -X- _ O
Subsequently -X- _ O
a -X- _ O
simple -X- _ O
transformation -X- _ O
converts -X- _ O
source -X- _ O
representations -X- _ O
into -X- _ O
target -X- _ O
representations. -X- _ O
This -X- _ O
makes -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
better -X- _ O
capture -X- _ O
sentence -X- _ O
semantics -X- _ O
in -X- _ O
a -X- _ O
language-specific -X- _ O
manner. -X- _ O
Lastly -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
minimizing -X- _ O
KL -X- _ O
loss -X- _ O
, -X- _ O
the -X- _ O
flows -X- _ O
are -X- _ O
directly -X- _ O
trained -X- _ O
by -X- _ O
maximum -X- _ O
likelihood -X- _ O
estimation -X- _ O
( -X- _ O
MLE -X- _ O
) -X- _ O
of -X- _ O
sentence-level -X- _ O
latent -X- _ O
representations. -X- _ O
This -X- _ O
gives -X- _ O
the -X- _ O
latent -X- _ O
representations -X- _ O
more -X- _ O
flexibility -X- _ O
. -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
flow-adapter -X- _ B-MethodName
architecture. -X- _ I-MethodName
It -X- _ O
uses -X- _ O
normalizing -X- _ O
flows -X- _ O
to -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
sentence-level -X- _ O
representations -X- _ O
and -X- _ O
performs -X- _ O
a -X- _ O
latent -X- _ O
representation -X- _ O
transformation -X- _ O
from -X- _ O
source -X- _ O
to -X- _ O
target. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
work -X- _ O
that -X- _ O
uses -X- _ O
latent -X- _ O
variables -X- _ O
and -X- _ O
normalizing -X- _ O
flows -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
Experiments -X- _ O
show -X- _ O
the -X- _ O
validity -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
flow-adapter -X- _ O
architecture. -X- _ O
It -X- _ O
performs -X- _ O
very -X- _ O
well -X- _ O
in -X- _ O
unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
on -X- _ O
several -X- _ O
language -X- _ O
pairs -X- _ O
on -X- _ O
the -X- _ O
Multi30K -X- _ B-DatasetName
dataset. -X- _ O
When -X- _ O
additionally -X- _ O
using -X- _ O
pre-trained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
results -X- _ O
competitive -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
on -X- _ O
WMT -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
en-fr -X- _ B-DatasetName
( -X- _ O
WMT'14 -X- _ B-DatasetName
) -X- _ O
and -X- _ O
en-ro -X- _ B-DatasetName
( -X- _ O
WMT'16 -X- _ B-DatasetName
) -X- _ O
. -X- _ O

Normalizing -X- _ O
Flows -X- _ O
Normalizing -X- _ O
flows -X- _ O
( -X- _ O
NFs -X- _ O
) -X- _ O
are -X- _ O
a -X- _ O
special -X- _ O
type -X- _ O
of -X- _ O
deep -X- _ O
generative -X- _ O
model. -X- _ O
Different -X- _ O
from -X- _ O
generative -X- _ O
adversarial -X- _ O
networks -X- _ O
( -X- _ O
GAN -X- _ O
) -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
variational -X- _ O
auto-encoding -X- _ O
( -X- _ O
VAE -X- _ O
) -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
NFs -X- _ O
allow -X- _ O
for -X- _ O
not -X- _ O
only -X- _ O
sampling -X- _ O
but -X- _ O
also -X- _ O
exact -X- _ O
density -X- _ O
estimation. -X- _ O
Due -X- _ O
to -X- _ O
such -X- _ O
desirable -X- _ O
properties -X- _ O
, -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
fields -X- _ O
such -X- _ O
as -X- _ O
image -X- _ O
( -X- _ O
Ho -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kingma -X- _ O
and -X- _ O
Dhariwal -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
audio -X- _ O
( -X- _ O
Esling -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
van -X- _ O
den -X- _ O
Oord -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
video -X- _ O
generation -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
significant -X- _ O
achievements -X- _ O
in -X- _ O
modeling -X- _ O
continuous -X- _ O
data -X- _ O
, -X- _ O
NFs -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
modeling -X- _ O
discrete -X- _ O
data -X- _ O
, -X- _ O
either -X- _ O
by -X- _ O
directly -X- _ O
modeling -X- _ O
the -X- _ O
data -X- _ O
in -X- _ O
discrete -X- _ O
space -X- _ O
( -X- _ O
Tran -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Hesselink -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
by -X- _ O
transforming -X- _ O
the -X- _ O
discrete -X- _ O
data -X- _ O
into -X- _ O
continuous -X- _ O
space -X- _ O
( -X- _ O
Ziegler -X- _ O
and -X- _ O
Rush -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Tang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

NFs -X- _ O
transform -X- _ O
between -X- _ O
two -X- _ O
distributions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
change-of-variables -X- _ O
formula -X- _ O
( -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
( -X- _ O
Dinh -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2015 -X- _ O
( -X- _ O
Dinh -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
, -X- _ O
2017 -X- _ O

where -X- _ O
z -X- _ O
∼ -X- _ O
p -X- _ O
z -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
x -X- _ O
∼ -X- _ O
p -X- _ O
x -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
denote -X- _ O
two -X- _ O
vectors -X- _ O
from -X- _ O
a -X- _ O
simple -X- _ O
latent -X- _ O
distribution -X- _ O
p -X- _ O
z -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
complex -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
p -X- _ O
x -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
θ -X- _ O
is -X- _ O
an -X- _ O
invertible -X- _ O
and -X- _ O
differentiable -X- _ O
function -X- _ O
( -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
parameters -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
f -X- _ O
θ -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
x -X- _ O
and -X- _ O
det -X- _ O
∂f -X- _ O
θ -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
∂z -X- _ O
denotes -X- _ O
the -X- _ O
determinant -X- _ O
of -X- _ O
the -X- _ O
Jacobian -X- _ O
matrix -X- _ O
of -X- _ O
f -X- _ O
θ -X- _ O
. -X- _ O
The -X- _ O
idea -X- _ O
of -X- _ O
NFs -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
an -X- _ O
f -X- _ O
θ -X- _ O
such -X- _ O
that -X- _ O
f -X- _ O
θ -X- _ O
and -X- _ O
f -X- _ O
−1 -X- _ O
θ -X- _ O
transform -X- _ O
between -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
p -X- _ O
z -X- _ O
( -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
observed -X- _ O
space -X- _ O
p -X- _ O
x -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O

Constructing -X- _ O
a -X- _ O
single -X- _ O
arbitrarily -X- _ O
complex -X- _ O
invertible -X- _ O
and -X- _ O
differentiable -X- _ O
function -X- _ O
is -X- _ O
usually -X- _ O
cumbersome. -X- _ O
Therefore -X- _ O
, -X- _ O
a -X- _ O
generally -X- _ O
adopted -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
stack -X- _ O
multiple -X- _ O
transformations -X- _ O
f -X- _ O
i -X- _ O
together -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O

, -X- _ O
whose -X- _ O
Jacobian -X- _ O
matrix -X- _ O
is -X- _ O
efficient -X- _ O
to -X- _ O
compute. -X- _ O
Here -X- _ O
K -X- _ B-HyperparameterName
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
sequential -X- _ O
flows -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
3 -X- _ B-HyperparameterValue
in -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Normalizing -X- _ O
flows -X- _ O
are -X- _ O
usually -X- _ O
optimized -X- _ O
by -X- _ O
MLE -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
θ -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
log -X- _ O
p -X- _ O
( -X- _ O
D|θ -X- _ O
) -X- _ O
= -X- _ O
N -X- _ O
n=1 -X- _ O
log -X- _ O
p -X- _ O
x -X- _ O
( -X- _ O
x -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
|θ -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
N -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
data -X- _ O
size. -X- _ O
By -X- _ O
applying -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
the -X- _ O
change-of-variable -X- _ O
formula -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
log -X- _ O
p -X- _ O
x -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
log -X- _ O
p -X- _ O
z -X- _ O
( -X- _ O
f -X- _ O
−1 -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
log -X- _ O
det -X- _ O

Latent-variable -X- _ O
( -X- _ O
variational -X- _ O
) -X- _ O
NMT -X- _ B-TaskName
Compared -X- _ O
with -X- _ O
standard -X- _ O
encoder-decoder -X- _ O
based -X- _ O
NMT -X- _ B-TaskName
models -X- _ O
, -X- _ O
latent-variable -X- _ O
( -X- _ O
variational -X- _ O
) -X- _ O
approaches -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ma -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Calixto -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Setiawan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
additionally -X- _ O
leverage -X- _ O
latent -X- _ O
random -X- _ O
variables -X- _ O
. -X- _ O

Let -X- _ O
x -X- _ O
be -X- _ O
a -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
y -X- _ O
be -X- _ O
its -X- _ O
translation -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
variational -X- _ O
NMT -X- _ B-TaskName
framework -X- _ O
introduces -X- _ O
a -X- _ O
continuous -X- _ O
random -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
modeling -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
p -X- _ O
( -X- _ O
y|z -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
z -X- _ O
, -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
reformulated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
z -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
global -X- _ O
semantic -X- _ O
signal -X- _ O
that -X- _ O
is -X- _ O
helpful -X- _ O
to -X- _ O
counteract -X- _ O
incorrect -X- _ O
alignments -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
learned -X- _ O
and -X- _ O
uses -X- _ O
through -X- _ O
attention. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
integration -X- _ O
of -X- _ O
z -X- _ O
poses -X- _ O
challenges -X- _ O
for -X- _ O
inference. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
variational -X- _ O
NMT -X- _ B-TaskName
adopts -X- _ O
techniques -X- _ O
from -X- _ O
VAE -X- _ B-TaskName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Rezende -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
neural -X- _ O
approximation -X- _ O
and -X- _ O
the -X- _ O
reparameterization -X- _ O
trick -X- _ O
. -X- _ O

Neural -X- _ O
approximation -X- _ O
leverages -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
posterior -X- _ O
distribution -X- _ O
p -X- _ O
( -X- _ O
z|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
with -X- _ O
q -X- _ O
ϕ -X- _ O
( -X- _ O
z|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
ϕ -X- _ O
denotes -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
neural -X- _ O
network. -X- _ O
In -X- _ O
most -X- _ O
works -X- _ O
, -X- _ O
q -X- _ O
ϕ -X- _ O
( -X- _ O
z|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
designed -X- _ O
as -X- _ O
a -X- _ O
diagonal -X- _ O
Gaussian -X- _ O
N -X- _ O
( -X- _ O
µ -X- _ O
, -X- _ O
diag -X- _ O
( -X- _ O
σ -X- _ O
2 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
mean -X- _ O
µ -X- _ O
and -X- _ O
the -X- _ O
variance -X- _ O
σ -X- _ O
2 -X- _ O
are -X- _ O
parameterized -X- _ O
with -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

Reparameterization -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
latent -X- _ O
random -X- _ O
variable -X- _ O
z -X- _ O
is -X- _ O
parameterized -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
µ -X- _ O
and -X- _ O
the -X- _ O
variance -X- _ O
σ -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
parameters -X- _ O
µ -X- _ O
and -X- _ O
σ -X- _ O
2 -X- _ O
can -X- _ O
be -X- _ O
computed. -X- _ O
The -X- _ O
reparameterization -X- _ O
of -X- _ O
z -X- _ O
is -X- _ O
often -X- _ O
carried -X- _ O
out -X- _ O
in -X- _ O
a -X- _ O
location-scale -X- _ O
manner -X- _ O
: -X- _ O
z -X- _ O
= -X- _ O
µ -X- _ O
+ -X- _ O
σ -X- _ O
⊙ -X- _ O
ϵ -X- _ O
where -X- _ O
ϵ -X- _ O
∼ -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
) -X- _ O
With -X- _ O
these -X- _ O
two -X- _ O
techniques -X- _ O
, -X- _ O
the -X- _ O
learning -X- _ O
objective -X- _ O
of -X- _ O
variational -X- _ O
NMT -X- _ B-TaskName
is -X- _ O
the -X- _ O
evidence -X- _ O
lower-bound -X- _ O
or -X- _ O
ELBO -X- _ O
of -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
: -X- _ O

where -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
z|x -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
prior -X- _ O
distribution -X- _ O
modeled -X- _ O
by -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
and -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
y|z -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
is -X- _ O
modeled -X- _ O
by -X- _ O
the -X- _ O
decoder -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
source -X- _ O
sentence -X- _ O
x -X- _ O
and -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
z. -X- _ O
The -X- _ O
KL -X- _ O
term -X- _ O
minimizes -X- _ O
the -X- _ O
discrepancy -X- _ O
between -X- _ O
the -X- _ O
prior -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
z|x -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
posterior -X- _ O
q -X- _ O
θ -X- _ O
( -X- _ O
z|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
inference -X- _ O
step -X- _ O
, -X- _ O
z -X- _ O
can -X- _ O
therefore -X- _ O
be -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
prior -X- _ O
, -X- _ O
which -X- _ O
only -X- _ O
requires -X- _ O
x -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
posterior -X- _ O
that -X- _ O
requires -X- _ O
both -X- _ O
x -X- _ O
and -X- _ O
y. -X- _ O
Although -X- _ O
this -X- _ O
variational -X- _ O
framework -X- _ O
leverages -X- _ O
latent -X- _ O
variables -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
helpful -X- _ O
for -X- _ O
translation -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
has -X- _ O
some -X- _ O
flaws -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
training -X- _ O
a -X- _ O
variational -X- _ O
NMT -X- _ B-TaskName
framework -X- _ O
requires -X- _ O
parallel -X- _ O
corpora -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
posterior -X- _ O
q -X- _ O
ϕ -X- _ O
( -X- _ O
z|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
and -X- _ O
such -X- _ O
parallel -X- _ O
corpora -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
MT -X- _ I-TaskName
; -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
distribution -X- _ O
family -X- _ O
of -X- _ O
the -X- _ O
latent -X- _ O
variables -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
z|x -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
pre-defined -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
Gaussian -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
restricts -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
complex -X- _ O
posterior -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
as -X- _ O
variational -X- _ O
NMT -X- _ B-TaskName
leverages -X- _ O
z -X- _ O
sampled -X- _ O
from -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
z|x -X- _ O
) -X- _ O
for -X- _ O
inference -X- _ O
, -X- _ O
an -X- _ O
underlying -X- _ O
assumption -X- _ O
is -X- _ O
that -X- _ O
z -X- _ O
should -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
whether -X- _ O
only -X- _ O
x -X- _ O
is -X- _ O
considered -X- _ O
or -X- _ O
both -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
are -X- _ O
considered. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
this -X- _ O
framework -X- _ O
assumes -X- _ O
z -X- _ O
is -X- _ O
language-agnostic -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
true -X- _ O
since -X- _ O
language-specific -X- _ O
characteristics -X- _ O
can -X- _ O
influence -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
z -X- _ O
. -X- _ O

Flow-Adapter -X- _ B-MethodName
Based -X- _ O
Framework -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
reap -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
introducing -X- _ O
latent -X- _ O
variables -X- _ O
into -X- _ O
unsupervised -X- _ O
MT -X- _ B-TaskName
while -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
avoiding -X- _ O
the -X- _ O
flaws -X- _ O
of -X- _ O
variational -X- _ O
NMT -X- _ B-TaskName
we -X- _ O
just -X- _ O
discussed. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
flow-adapter -X- _ O
based -X- _ O
framework -X- _ O
that -X- _ O
uses -X- _ O
two -X- _ O
NFs -X- _ O
to -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
latent -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
take -X- _ O
account -X- _ O
of -X- _ O
multilinguality -X- _ O
in -X- _ O
unsupervised -X- _ B-TaskName
MT -X- _ I-TaskName
and -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
language-specific -X- _ O
sentence-level -X- _ O
representations. -X- _ O
During -X- _ O
the -X- _ O
translation -X- _ O
process -X- _ O
, -X- _ O
a -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
is -X- _ O
performed -X- _ O
to -X- _ O
transform -X- _ O
the -X- _ O
source-language -X- _ O
representation -X- _ O
into -X- _ O
the -X- _ O
targetlanguage -X- _ O
representation -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
decoder -X- _ O
can -X- _ O
leverage -X- _ O
them -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
better -X- _ O
target-language -X- _ O
sentence. -X- _ O
We -X- _ O
will -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
sentence-level -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
flow-adapter -X- _ O
based -X- _ O
framework -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
MT -X- _ I-TaskName
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O

Modeling -X- _ O
Representation -X- _ O
by -X- _ O
NFs -X- _ O
& -X- _ O
Latent -X- _ O
Code -X- _ O
Transformation -X- _ O
As -X- _ O
previously -X- _ O
mentioned -X- _ O
, -X- _ O
variational -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Setiawan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
x -X- _ O
and -X- _ O
target -X- _ O
sentence -X- _ O
y -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
generated -X- _ O
latent -X- _ O
variable -X- _ O
z -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
regardless -X- _ O
of -X- _ O
whether -X- _ O
we -X- _ O
only -X- _ O
consider -X- _ O
x -X- _ O
or -X- _ O
consider -X- _ O
both -X- _ O
x -X- _ O
and -X- _ O
y. -X- _ O
Unsupervised -X- _ B-TaskName
NMT -X- _ I-TaskName
methods -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
similarly -X- _ O
assume -X- _ O
that -X- _ O
a -X- _ O
shared -X- _ O
encoder -X- _ O
maps -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
into -X- _ O
a -X- _ O
shared -X- _ O
latent -X- _ O
space -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
diverge -X- _ O
from -X- _ O
this -X- _ O
assumption -X- _ O
and -X- _ O
follow -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
in -X- _ O
adopting -X- _ O
the -X- _ O
desideratum -X- _ O
that -X- _ O
the -X- _ O
unique -X- _ O
and -X- _ O
internal -X- _ O
characteristics -X- _ O
of -X- _ O
each -X- _ O
language -X- _ O
be -X- _ O
respected. -X- _ O
One -X- _ O
could -X- _ O
think -X- _ O
that -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
should -X- _ O
theoretically -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
; -X- _ O
but -X- _ O
in -X- _ O
reality -X- _ O
, -X- _ O
because -X- _ O
of -X- _ O
language-specific -X- _ O
characteristics -X- _ O
, -X- _ O
the -X- _ O
latent -X- _ O
representations -X- _ O
z -X- _ O
obtained -X- _ O
by -X- _ O
an -X- _ O
encoder -X- _ O
can -X- _ O
be -X- _ O
different -X- _ O
for -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences. -X- _ O
Differ-ences -X- _ O
in -X- _ O
vocabulary -X- _ O
, -X- _ O
pragmatics -X- _ O
and -X- _ O
other -X- _ O
linguistic -X- _ O
properties -X- _ O
all -X- _ O
influence -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
the -X- _ O
latent -X- _ O
representations. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
latent -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
perspective -X- _ O
as -X- _ O
follows. -X- _ O
We -X- _ O
can -X- _ O
view -X- _ O
z -X- _ O
x -X- _ O
and -X- _ O
z -X- _ O
y -X- _ O
as -X- _ O
expressions -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
representations -X- _ O
in -X- _ O
two -X- _ O
distinct -X- _ O
languages -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
semantics -X- _ O
ϵ -X- _ O
where -X- _ O
ϵ -X- _ O
is -X- _ O
truly -X- _ O
language-agnostic. -X- _ O
z -X- _ O
x -X- _ O
and -X- _ O
z -X- _ O
y -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
applying -X- _ O
parameter-free -X- _ O
techniques -X- _ O
such -X- _ O
as -X- _ O
pooling -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
fed -X- _ O
with -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
3.2 -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

Modeling -X- _ O
by -X- _ O
NFs. -X- _ O
For -X- _ O
our -X- _ O
unsupervised -X- _ O
scenario -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
representations -X- _ O
of -X- _ O
both -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
-i.e. -X- _ O
, -X- _ O
p -X- _ O
zx -X- _ O
( -X- _ O
z -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
p -X- _ O
zy -X- _ O
( -X- _ O
z -X- _ O
y -X- _ O
) -X- _ O
-using -X- _ O
NFs -X- _ O
with -X- _ O
K -X- _ B-HyperparameterName
sequential -X- _ O
flows -X- _ O
: -X- _ O

Our -X- _ O
transformation -X- _ O
to -X- _ O
the -X- _ O
sentence-level -X- _ O
representations -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
. -X- _ O
They -X- _ O
argued -X- _ O
that -X- _ O
BERT -X- _ O
induces -X- _ O
a -X- _ O
non-smooth -X- _ O
anisotropic -X- _ O
semantic -X- _ O
space -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
harm -X- _ O
its -X- _ O
accurate -X- _ O
representation -X- _ O
of -X- _ O
semantic -X- _ O
similarity. -X- _ O
Therefore -X- _ O
, -X- _ O
they -X- _ O
also -X- _ O
used -X- _ O
NFs -X- _ O
to -X- _ O
transform -X- _ O
the -X- _ O
anisotropic -X- _ O
BERT -X- _ O
sentence-level -X- _ O
distribution -X- _ O
to -X- _ O
a -X- _ O
standard -X- _ O
Gaussian -X- _ O
distribution -X- _ O
that -X- _ O
is -X- _ O
smooth -X- _ O
and -X- _ O
isotropic -X- _ O
and -X- _ O
reported -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
some -X- _ O
sentence-level -X- _ O
similarity -X- _ O
tasks. -X- _ O
By -X- _ O
using -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
sentence-level -X- _ O
representation -X- _ O
, -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
sentences -X- _ O
from -X- _ O
different -X- _ O
languages -X- _ O
can -X- _ O
therefore -X- _ O
be -X- _ O
aligned -X- _ O
in -X- _ O
a -X- _ O
simple -X- _ O
common -X- _ O
space -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
way -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
show -X- _ O
is -X- _ O
effective -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O

For -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
NFs -X- _ O
for -X- _ O
transforming -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentencelevel -X- _ O
representations -X- _ O
to -X- _ O
the -X- _ O
base -X- _ O
distribution -X- _ O
as -X- _ O
mappings -X- _ O
G -X- _ O
( -X- _ O
zx→ϵ -X- _ O
) -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
zy→ϵ -X- _ O
) -X- _ O
. -X- _ O
Because -X- _ O
of -X- _ O
the -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
ϵ→zy -X- _ O
) -X- _ O
= -X- _ O
G -X- _ O
−1 -X- _ O
( -X- _ O
zy→ϵ -X- _ O
) -X- _ O
. -X- _ O
Latent -X- _ O
Code -X- _ O
Transformation. -X- _ O
Inspired -X- _ O
by -X- _ O
AlignFlow -X- _ O
( -X- _ O
Grover -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
cross-domain -X- _ O
transformation -X- _ O
between -X- _ O
z -X- _ O
x -X- _ O
and -X- _ O
z -X- _ O
y -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
formulate -X- _ O
a -X- _ O
language-specific -X- _ O
latent -X- _ O
code -X- _ O
for -X- _ O
the -X- _ O
decoder. -X- _ O
We -X- _ O
formalize -X- _ O
the -X- _ O
cross-language -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

The -X- _ O
target-to-source -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
is -X- _ O
then -X- _ O
the -X- _ O
composition -X- _ O
of -X- _ O
G -X- _ O
( -X- _ O
ϵ→zx -X- _ O
) -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
zy→ϵ -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
G -X- _ O
( -X- _ O
ϵ→zy -X- _ O
) -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
ϵ→zx -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
inverse -X- _ O
mappings -X- _ O
of -X- _ O
G -X- _ O
( -X- _ O
zy→ϵ -X- _ O
) -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
zy→ϵ -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
easily -X- _ O
obtain -X- _ O
them -X- _ O
with -X- _ O
normalizing -X- _ O
flows -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
realNVP -X- _ O
( -X- _ O
Dinh -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Glow -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Dhariwal -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
G -X- _ O
( -X- _ O
zx→zy -X- _ O
) -X- _ O
and -X- _ O
G -X- _ O
( -X- _ O
zy→zx -X- _ O
) -X- _ O
are -X- _ O
both -X- _ O
invertible -X- _ O
since -X- _ O
they -X- _ O
are -X- _ O
compositions -X- _ O
of -X- _ O
two -X- _ O
invertible -X- _ O
mappings. -X- _ O
Moreover -X- _ O
, -X- _ O
G -X- _ O
( -X- _ O
zx→zy -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
inverse -X- _ O
of -X- _ O
G -X- _ O
( -X- _ O
zy→zx -X- _ O
) -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A.1 -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

Flow-Adapter -X- _ B-MethodName
Based -X- _ O
Unsupervised -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
The -X- _ O
general -X- _ O
architecture -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O
The -X- _ O
transformer -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
both -X- _ O
encoder -X- _ O
and -X- _ O
decoder. -X- _ O
We -X- _ O
use -X- _ O
source -X- _ O
encoder -X- _ O
/ -X- _ O
decoder -X- _ O
to -X- _ O
denote -X- _ O
the -X- _ O
encoder -X- _ O
/ -X- _ O
decoder -X- _ O
for -X- _ O
encoding -X- _ O
/ -X- _ O
generating -X- _ O
the -X- _ O
source-language -X- _ O
sentence. -X- _ O
Similarly -X- _ O
, -X- _ O
target -X- _ O
encoder -X- _ O
/ -X- _ O
decoder -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
/ -X- _ O
decoder -X- _ O
encoding -X- _ O
/ -X- _ O
generating -X- _ O
the -X- _ O
targetlanguage -X- _ O
sentence. -X- _ O
The -X- _ O
decoders -X- _ O
work -X- _ O
in -X- _ O
an -X- _ O
autoregressive -X- _ O
way. -X- _ O
Source -X- _ O
flow -X- _ O
and -X- _ O
target -X- _ O
flow -X- _ O
are -X- _ O
NFs -X- _ O
for -X- _ O
modeling -X- _ O
the -X- _ O
sentence-level -X- _ O
latent -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
as -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
. -X- _ O

Encoding. -X- _ O
The -X- _ O
source -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
encoder -X- _ O
work -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
; -X- _ O
for -X- _ O
brevity -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
describe -X- _ O
the -X- _ O
procedure -X- _ O
of -X- _ O
encoding -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
and -X- _ O
how -X- _ O
z -X- _ O
x -X- _ O
is -X- _ O
generated. -X- _ O
The -X- _ O
source -X- _ O
encoder -X- _ O
takes -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
x -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
0 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
S -X- _ O
} -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
generates -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
{ -X- _ O
h -X- _ O
0 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
h -X- _ O
S -X- _ O
} -X- _ O
. -X- _ O
These -X- _ O
hidden -X- _ O
representations -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
encoder-decoder -X- _ O
attentional -X- _ O
inputs. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
sentence-level -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
by -X- _ O
applying -X- _ O
max-pooling -X- _ O
and -X- _ O
mean-pooling -X- _ O
to -X- _ O
the -X- _ O
token-level -X- _ O
representations. -X- _ O
After -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
up -X- _ O
the -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
CLS -X- _ O
representation -X- _ O
h -X- _ O
0 -X- _ O
, -X- _ O
which -X- _ O
usually -X- _ O
encodes -X- _ O
some -X- _ O
global -X- _ O
information. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
projection -X- _ O
matrix -X- _ O
W -X- _ O
to -X- _ O
project -X- _ O
the -X- _ O
resulting -X- _ O
vector -X- _ O
to -X- _ O
a -X- _ O
latent -X- _ O
space. -X- _ O
The -X- _ O
output -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
z -X- _ O
x -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
sentence-level -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A.2 -X- _ O
for -X- _ O
equation -X- _ O
and -X- _ O
illustration -X- _ O
) -X- _ O
. -X- _ O

Cross-lingual -X- _ O
Translation. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
decoder -X- _ O
can -X- _ O
better -X- _ O
leverage -X- _ O
language-specific -X- _ O
latent -X- _ O
representations -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
z -X- _ O
x -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
decoder -X- _ O
and -X- _ O
z -X- _ O
y -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
decoder -X- _ O
) -X- _ O
than -X- _ O
indiscriminately -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
representational -X- _ O
space -X- _ O
for -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
z -X- _ O
x -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
decoder. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
for -X- _ O
cross-language -X- _ O
translation -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O
If -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
performing -X- _ O
the -X- _ O
translation -X- _ O
in -X- _ O
the -X- _ O
source-to-target -X- _ O
direction -X- _ O
, -X- _ O
the -X- _ O
source -X- _ O
flow -X- _ O
first -X- _ O
transforms -X- _ O
the -X- _ O
source -X- _ O
latent -X- _ O
representation -X- _ O
z -X- _ O
x -X- _ O
into -X- _ O
ϵ -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
in -X- _ O
the -X- _ O
semantic -X- _ O
base -X- _ O
space. -X- _ O
Then -X- _ O
the -X- _ O
target -X- _ O
flow -X- _ O
transforms -X- _ O
ϵ -X- _ O
back -X- _ O
into -X- _ O
z -X- _ O
y -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
latent -X- _ O
representation -X- _ O
space. -X- _ O
Then -X- _ O
z -X- _ O
y -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
decoder -X- _ O
for -X- _ O
generating -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
. -X- _ O

Denoising -X- _ O
Auto-Encoding -X- _ O
( -X- _ O
DAE -X- _ O
) -X- _ O
and -X- _ O
Back -X- _ O
Translation -X- _ O
( -X- _ O
BT -X- _ O
) -X- _ O
Processes. -X- _ O
The -X- _ O
DAE -X- _ O
reconstructs -X- _ O
a -X- _ O
sentence -X- _ O
from -X- _ O
its -X- _ O
noised -X- _ O
version. -X- _ O
For -X- _ O
inducing -X- _ O
noise -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
strategy -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
by -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
( -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
, -X- _ O
please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.3 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
DAEs -X- _ O
separately -X- _ O
for -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
hence -X- _ O
we -X- _ O
do -X- _ O
n't -X- _ O
need -X- _ O
a -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
there. -X- _ O
For -X- _ O
BT -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
such -X- _ O
a -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
is -X- _ O
performed -X- _ O
twice -X- _ O
; -X- _ O
taking -X- _ O
BT -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
: -X- _ O
first -X- _ O
in -X- _ O
the -X- _ O
source-to-target -X- _ O
direction -X- _ O
, -X- _ O
then -X- _ O
in -X- _ O
the -X- _ O
target-to-source -X- _ O
direction -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

is -X- _ O
the -X- _ O
sigmoid -X- _ O
function -X- _ O
, -X- _ O
⊙ -X- _ O
denotes -X- _ O
Hadamard -X- _ O
product -X- _ O
between -X- _ O
two -X- _ O
vectors -X- _ O
, -X- _ O
and -X- _ O
o -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
logit -X- _ O
vector -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
prediction -X- _ O
at -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
position. -X- _ O
The -X- _ O
values -X- _ O
in -X- _ O
g -X- _ O
i -X- _ O
control -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
z -X- _ O
to -X- _ O
o -X- _ O
i -X- _ O
. -X- _ O
In -X- _ O
case -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
latent -X- _ O
representation -X- _ O
does -X- _ O
not -X- _ O
match -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
output -X- _ O
, -X- _ O
a -X- _ O
linear -X- _ O
projection -X- _ O
maps -X- _ O
z -X- _ O
to -X- _ O
the -X- _ O
desired -X- _ O
dimension -X- _ O
. -X- _ O

Training. -X- _ O
Our -X- _ O
flow-adapter -X- _ B-MethodName
framework -X- _ O
has -X- _ O
three -X- _ O
learning -X- _ O
objectives -X- _ O
: -X- _ O
DAE -X- _ O
, -X- _ O
BT -X- _ O
and -X- _ O
MLE -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
representations. -X- _ O
The -X- _ O
description -X- _ O
of -X- _ O
DAE -X- _ O
and -X- _ O
BT -X- _ O
is -X- _ O
omitted -X- _ O
here -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
well -X- _ O
known -X- _ O
from -X- _ O
related -X- _ O
work -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Artetxe -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
single -X- _ O
training -X- _ O
iteration -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
DAE -X- _ O
step -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
BT -X- _ O
step -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O
MLE -X- _ O
computation -X- _ O
is -X- _ O
integrated -X- _ O
into -X- _ O
the -X- _ O
DAE -X- _ O
step -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
representations. -X- _ O
Our -X- _ O
MLE -X- _ O
learning -X- _ O
objective -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
monolingual -X- _ O
dataset -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
follows -X- _ O
( -X- _ O
similar -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
, -X- _ O
omitted -X- _ O
) -X- _ O
: -X- _ O

Experiments -X- _ O
4.1 -X- _ O
Datasets -X- _ O
Multi30K -X- _ B-DatasetName
task1 -X- _ O
dataset -X- _ O
( -X- _ O
Elliott -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
( -X- _ O
Elliott -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
1 -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
multi-modal -X- _ O
dataset -X- _ O
that -X- _ O
has -X- _ O
30,000 -X- _ O
images -X- _ O
annotated -X- _ O
with -X- _ O
captions -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
German -X- _ O
and -X- _ O
French. -X- _ O
Similar -X- _ O
to -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
caption -X- _ O
of -X- _ O
each -X- _ O
image. -X- _ O
The -X- _ O
officially -X- _ O
provided -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
are -X- _ O
used. -X- _ O
We -X- _ O
use -X- _ O
this -X- _ O
dataset -X- _ O
as -X- _ O
a -X- _ O
small-scale -X- _ O
test -X- _ O
for -X- _ O
validating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
methods. -X- _ O
WMT -X- _ B-DatasetName
datasets. -X- _ O
2 -X- _ O
Our -X- _ O
experiments -X- _ O
are -X- _ O
run -X- _ O
with -X- _ O
the -X- _ O
settings -X- _ O
that -X- _ O
were -X- _ O
used -X- _ O
for -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
XLM -X- _ B-TaskName
uses -X- _ O
the -X- _ O
monolingual -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
WMT -X- _ B-DatasetName
News -X- _ I-DatasetName
Crawl -X- _ I-DatasetName
datasets -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
newstest2014 -X- _ B-DatasetName
en-fr -X- _ I-DatasetName
, -X- _ O
newstest2016 -X- _ B-DatasetName
en-de -X- _ I-DatasetName
and -X- _ O
newstest2016 -X- _ B-DatasetName
en-ro -X- _ I-DatasetName
. -X- _ O

Setups -X- _ O
Preprocessing. -X- _ O
We -X- _ O
tokenize -X- _ O
the -X- _ O
sentences -X- _ O
with -X- _ O
the -X- _ O
Moses -X- _ O
script -X- _ O
( -X- _ O
Koehn -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
Multi30K -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
process -X- _ O
it -X- _ O
similar -X- _ O
to -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
sentences -X- _ O
are -X- _ O
randomly -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
parts. -X- _ O
The -X- _ O
sourcelanguage -X- _ O
monolingual -X- _ O
dataset -X- _ O
is -X- _ O
built -X- _ O
from -X- _ O
the -X- _ O
source-language -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
part -X- _ O
and -X- _ O
the -X- _ O
target-language -X- _ O
dataset -X- _ O
from -X- _ O
the -X- _ O
second -X- _ O
part. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
there -X- _ O
will -X- _ O
be -X- _ O
no -X- _ O
exact -X- _ O
translations -X- _ O
of -X- _ O
any -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
datasets. -X- _ O
For -X- _ O
the -X- _ O
WMT -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
preprocessing -X- _ O
methods -X- _ O
from -X- _ O
( -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
English-Romanian -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
diacritics -X- _ O
as -X- _ O
done -X- _ O
by -X- _ O
Sennrich -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2016a -X- _ O
) -X- _ O
to -X- _ O
avoid -X- _ O
their -X- _ O
inconsistent -X- _ O
usage -X- _ O
in -X- _ O
the -X- _ O
Romanian -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O

Metric -X- _ O
& -X- _ O
Performance. -X- _ O
We -X- _ O
use -X- _ O
BLEU -X- _ B-MetricName
as -X- _ O
metric -X- _ O
( -X- _ O
Papineni -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
for -X- _ O
all -X- _ O
our -X- _ O
experiments. -X- _ O
Although -X- _ O
Artetxe -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
1 -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
of -X- _ O
our -X- _ O
flow-adapter -X- _ B-HyperparameterName
model -X- _ O
for -X- _ O
multilingual -X- _ O
translation -X- _ O
on -X- _ O
Multi30K. -X- _ B-DatasetName
Baseline -X- _ O
: -X- _ O
model -X- _ O
without -X- _ O
our -X- _ O
proposed -X- _ O
flow-adapter -X- _ B-HyperparameterName
architecture. -X- _ O
3-scf -X- _ O
or -X- _ O
3-glow -X- _ O
models -X- _ O
: -X- _ O
baseline -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
flow-adapter -X- _ O
architecture -X- _ O
constructed -X- _ O
by -X- _ O
two -X- _ O
realNVP -X- _ O
NF -X- _ O
models -X- _ O
or -X- _ O
Glow -X- _ O
NF -X- _ O
models -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
3 -X- _ O
sequential -X- _ O
flows -X- _ O
, -X- _ O
for -X- _ O
performing -X- _ O
the -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
in -X- _ O
that -X- _ O
translation -X- _ O
direction. -X- _ O
unsupervised -X- _ O
validation -X- _ O
criteria -X- _ O
for -X- _ O
systematic -X- _ O
tuning -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
( -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Song -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
provided -X- _ O
parallel -X- _ O
validation -X- _ O
sets -X- _ O
for -X- _ O
tuning -X- _ O
hyperparameters. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
that -X- _ O
achieve -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
sets -X- _ O
. -X- _ O

Pre-trained -X- _ O
Embeddings -X- _ O
& -X- _ O
Models. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
pre-trained -X- _ O
MUSE -X- _ B-MethodName
4 -X- _ I-MethodName
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
multilingual -X- _ O
unsupervised -X- _ B-TaskName
MT -X- _ I-TaskName
experiment -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
leverage -X- _ O
pre-trained -X- _ O
cross-lingual -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
of -X- _ O
shared -X- _ O
& -X- _ O
separate -X- _ O
decoder -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
XLM -X- _ B-TaskName
models -X- _ O
from -X- _ O
HuggingFace -X- _ O
5 -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
initialize -X- _ O
the -X- _ O
encoder. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
incorporate -X- _ O
our -X- _ O
flow-adapter -X- _ O
architecture -X- _ O
directly -X- _ O
into -X- _ O
the -X- _ O
codebase -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
of -X- _ O
XLM -X- _ B-TaskName
6 -X- _ I-TaskName
for -X- _ O
the -X- _ O
WMT -X- _ B-DatasetName
dataset -X- _ O
experiment -X- _ O
( -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
are -X- _ O
both -X- _ O
initialized -X- _ O
with -X- _ O
pre-trained -X- _ O
models. -X- _ O
Details -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O
. -X- _ O

Results -X- _ O
of -X- _ O
Multilingual -X- _ O
Unsupervised -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
on -X- _ O
Multi30K -X- _ B-DatasetName
As -X- _ O
Multi30K -X- _ B-DatasetName
provides -X- _ O
parallel -X- _ O
test -X- _ O
data -X- _ O
for -X- _ O
English -X- _ O
, -X- _ O
French -X- _ O
and -X- _ O
German -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
conduct -X- _ O
experiments -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
multilingual -X- _ O
translation -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
flow-adapter -X- _ O
models. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O
The -X- _ O
baseline -X- _ O
model -X- _ O
( -X- _ O
without -X- _ O
flow-adapter -X- _ O
architecture -X- _ O
) -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
only -X- _ O
DAE -X- _ O
loss -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
flow-adapter -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
3-scf -X- _ O
and -X- _ O
3-glow -X- _ O
) -X- _ O
are -X- _ O
additionally -X- _ O
trained -X- _ O
with -X- _ O
MLE -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
NFs. -X- _ O
3-scf -X- _ O
( -X- _ O
resp. -X- _ O
3-glow -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
with -X- _ O
two -X- _ O
realNVP -X- _ O
NF -X- _ O
models -X- _ O
( -X- _ O
Dinh -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
( -X- _ O
resp. -X- _ O
Glow -X- _ O
NF -X- _ O
models -X- _ O
( -X- _ O
Kingma -X- _ O
andDhariwal -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
3 -X- _ O
sequential -X- _ O
flows. -X- _ O
Each -X- _ O
NF -X- _ O
model -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
sentence-level -X- _ O
represen-tations -X- _ O
of -X- _ O
one -X- _ O
specific -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
two -X- _ O
NF -X- _ O
models -X- _ O
then -X- _ O
construct -X- _ O
a -X- _ O
flow-adapter -X- _ B-MethodName
for -X- _ O
that -X- _ O
translation -X- _ O
direction -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
flow-adapter -X- _ B-MethodName
based -X- _ O
models -X- _ O
additionally -X- _ O
perform -X- _ O
the -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
language-specific -X- _ O
representation -X- _ O
while -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
perform -X- _ O
such -X- _ O
a -X- _ O
transformation. -X- _ O
For -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pre-trained -X- _ O
crosslingual -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
MUSE -X- _ B-MethodName
embeddings -X- _ O
) -X- _ O
and -X- _ O
randomly -X- _ O
initialize -X- _ O
a -X- _ O
shared -X- _ O
encoder -X- _ O
and -X- _ O
a -X- _ O
shared -X- _ O
decoder -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
languages. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
the -X- _ O
iterative -X- _ O
back-translation. -X- _ O
For -X- _ O
further -X- _ O
research -X- _ O
where -X- _ O
there -X- _ O
are -X- _ O
far -X- _ O
more -X- _ O
languages -X- _ O
accommodated -X- _ O
, -X- _ O
random -X- _ O
online -X- _ O
back-translation -X- _ O
( -X- _ O
ROBT -X- _ O
) -X- _ O
proposed -X- _ O
by -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
could -X- _ O
be -X- _ O
considered -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
improvements -X- _ O
over -X- _ O
all -X- _ O
six -X- _ O
translation -X- _ O
directions -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
flow-adapter -X- _ O
architecture. -X- _ O
Notably -X- _ O
, -X- _ O
our -X- _ O
3-scf -X- _ O
and -X- _ O
3-glow -X- _ O
models -X- _ O
achieve -X- _ O
19.83 -X- _ B-MetricValue
and -X- _ O
20.14 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
scores -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
on -X- _ O
deen -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
0.52 -X- _ B-MetricValue
and -X- _ O
0.83 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
model. -X- _ O
Similar -X- _ O
improvements -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
seen -X- _ O
on -X- _ O
other -X- _ O
translation -X- _ O
directions. -X- _ O
Our -X- _ O
3-scf -X- _ O
model -X- _ O
has -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
that -X- _ O
are -X- _ O
0.46 -X- _ B-MetricValue
to -X- _ O
0.88 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
baselines -X- _ O
while -X- _ O
our -X- _ O
3-glow -X- _ O
model -X- _ O
has -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
that -X- _ O
are -X- _ O
0.04 -X- _ B-MetricValue
to -X- _ O
0.83 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
baselines. -X- _ O
The -X- _ O
overall -X- _ O
improvements -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
flow-adapter -X- _ B-MethodName
can -X- _ O
generate -X- _ O
more -X- _ O
suitable -X- _ O
sentence-level -X- _ O
representations -X- _ O
by -X- _ O
performing -X- _ O
the -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
helpful -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
semantics -X- _ O
and -X- _ O
generate -X- _ O
more -X- _ O
suitable -X- _ O
translations -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
translation -X- _ O
performance -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
pair -X- _ O
and -X- _ O
the -X- _ O
translation -X- _ O
direction -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
and -X- _ O
flow-adapter -X- _ O
models. -X- _ O
Our -X- _ O
models -X- _ O
obtain -X- _ O
very -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
en-fr -X- _ B-DatasetName
, -X- _ I-DatasetName
with -X- _ O
performances -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
en-fr -X- _ B-DatasetName
or -X- _ O
fr-en -X- _ B-DatasetName
directions -X- _ O
better -X- _ O
by -X- _ O
16 -X- _ B-DatasetName
BLEU -X- _ B-DatasetName
points. -X- _ O
For -X- _ O
other -X- _ O
language -X- _ O
pairs -X- _ O
( -X- _ O
including -X- _ O
enfr -X- _ B-DatasetName
) -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
always -X- _ O
one -X- _ O
direction -X- _ O
showing -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
the -X- _ O
other. -X- _ O
Specifically -X- _ O
, -X- _ O
de-en -X- _ B-DatasetName
achieves -X- _ O
more -X- _ O
than -X- _ O
19 -X- _ B-DatasetName
BLEU -X- _ B-DatasetName
points -X- _ O
compared -X- _ O
with -X- _ O
12 -X- _ B-DatasetName
points -X- _ O
for -X- _ O
en-de -X- _ B-DatasetName
, -X- _ O
and -X- _ O
de-fr -X- _ B-DatasetName
achieves -X- _ O
more -X- _ O
than -X- _ O
11 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
compared -X- _ O
with -X- _ O
8.5 -X- _ B-MetricValue
for -X- _ O
fr-de -X- _ B-DatasetName
. -X- _ O

Results -X- _ O
of -X- _ O
Shared-Decoder -X- _ O
& -X- _ O
Separate-Decoder -X- _ O
Models -X- _ O
on -X- _ O
Multi30K -X- _ B-DatasetName
We -X- _ O
present -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
flow-adapter -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
shared-decoder -X- _ O
and -X- _ O
separatedecoder -X- _ O
settings -X- _ O
on -X- _ O
Multi30K. -X- _ B-DatasetName
For -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
the -X- _ O
encoder -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre-trained -X- _ O
XLM -X- _ B-HyperparameterName
model -X- _ O
and -X- _ O
fixed -X- _ O
; -X- _ O
the -X- _ O
decoder -X- _ O
parameters -X- _ O
are -X- _ O
ran- -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
of -X- _ O
the -X- _ O
flow-adapter -X- _ B-MethodName
models -X- _ O
and -X- _ O
unsupervised -X- _ O
SOTA -X- _ O
model -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
UNMT -X- _ B-MethodName
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
on -X- _ O
Multi30K. -X- _ B-DatasetName
Baseline -X- _ O
models -X- _ O
use -X- _ O
pre-trained -X- _ O
XLMs -X- _ B-TaskName
from -X- _ O
HuggingFace -X- _ O
as -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
randomly -X- _ O
initialized -X- _ O
decoder -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
without -X- _ O
the -X- _ O
flow-adapter. -X- _ O
( -X- _ O
separate -X- _ O
decoders -X- _ O
) -X- _ O
: -X- _ O
two -X- _ O
independent -X- _ O
and -X- _ O
randomly -X- _ O
initialized -X- _ O
decoders -X- _ O
are -X- _ O
used -X- _ O
, -X- _ O
each -X- _ O
for -X- _ O
decoding -X- _ O
a -X- _ O
specific -X- _ O
language. -X- _ O
( -X- _ O
shared -X- _ O
decoder -X- _ O
) -X- _ O
: -X- _ O
a -X- _ O
single -X- _ O
shared -X- _ O
decoder -X- _ O
for -X- _ O
decoding -X- _ O
both -X- _ O
languages -X- _ O
is -X- _ O
used. -X- _ O
3-scf -X- _ O
and -X- _ O
3-glow -X- _ O
( -X- _ O
as -X- _ O
defined -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
Section -X- _ O
4.3 -X- _ O
) -X- _ O
denote -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
flow-adapter -X- _ O
architecture. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
UNMT -X- _ B-MethodName
from -X- _ O
their -X- _ O
original -X- _ O
paper. -X- _ O
domly -X- _ O
initialized -X- _ O
and -X- _ O
then -X- _ O
trained. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
previous -X- _ O
SOTA -X- _ O
model -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
UNMT -X- _ B-MethodName
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
7 -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
the -X- _ O
shareddecoder -X- _ O
baseline -X- _ O
model -X- _ O
obtains -X- _ O
very -X- _ O
low -X- _ O
BLEU -X- _ B-MetricName
scores. -X- _ O
By -X- _ O
checking -X- _ O
the -X- _ O
translation -X- _ O
generated -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
model -X- _ O
only -X- _ O
copies -X- _ O
the -X- _ O
input -X- _ O
as -X- _ O
translation. -X- _ O
This -X- _ O
phenomenon -X- _ O
shows -X- _ O
that -X- _ O
this -X- _ O
baseline -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
perform -X- _ O
the -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
, -X- _ O
can -X- _ O
not -X- _ O
model -X- _ O
two -X- _ O
languages -X- _ O
simultaneously -X- _ O
well -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
can -X- _ O
not -X- _ O
generate -X- _ O
translations -X- _ O
in -X- _ O
the -X- _ O
desired -X- _ O
language -X- _ O
domains. -X- _ O
However -X- _ O
, -X- _ O
by -X- _ O
incorporating -X- _ O
the -X- _ O
flow-adapter -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
will -X- _ O
no -X- _ O
longer -X- _ O
have -X- _ O
this -X- _ O
limitation. -X- _ O
Both -X- _ O
shared-decoder -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
3-scf -X- _ O
and -X- _ O
3-glow -X- _ O
, -X- _ O
achieve -X- _ O
very -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
translation -X- _ O
pairs. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
3-scf -X- _ O
model -X- _ O
obtains -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
of -X- _ O
25.80 -X- _ B-MetricValue
, -X- _ O
28.92 -X- _ B-MetricValue
, -X- _ O
39.26 -X- _ B-MetricValue
and -X- _ O
36.84 -X- _ B-MetricValue
on -X- _ O
en-de -X- _ B-DatasetName
, -X- _ O
de-en -X- _ B-DatasetName
, -X- _ O
en-fr -X- _ B-DatasetName
and -X- _ O
fr-en -X- _ B-DatasetName
, -X- _ O
which -X- _ O
are -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O

Compared -X- _ O
with -X- _ O
the -X- _ O
shared-decoder -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
separate-decoder -X- _ O
setting -X- _ O
do -X- _ O
not -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
copying -X- _ O
problem -X- _ O
, -X- _ O
because -X- _ O
different -X- _ O
decoders -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
specifically -X- _ O
model -X- _ O
and -X- _ O
generate -X- _ O
sentences -X- _ O
in -X- _ O
distinct -X- _ O
language -X- _ O
domains. -X- _ O
The -X- _ O
downside -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
is -X- _ O
that -X- _ O
using -X- _ O
multiple -X- _ O
decoders -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
can -X- _ O
substantially -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters. -X- _ O
Within -X- _ O
the -X- _ O
separatedecoder -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
flow-adapter -X- _ O
models -X- _ O
generally -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
, -X- _ O
with -X- _ O
about -X- _ O
1 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
increase -X- _ O
on -X- _ O
en-de -X- _ B-DatasetName
and -X- _ O
de-en -X- _ B-DatasetName
directions -X- _ O
and -X- _ O
relatively -X- _ O
smaller -X- _ O
improvements -X- _ O
on -X- _ O
en-fr -X- _ B-DatasetName
and -X- _ O
fr-en. -X- _ B-DatasetName
Those -X- _ O
improvements -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
flow-adapter -X- _ O
architectures -X- _ O
as -X- _ O
language-specific -X- _ O
latent -X- _ O
representations -X- _ O
are -X- _ O
used -X- _ O
, -X- _ O
thus -X- _ O
advancing -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
separate-decoder -X- _ O
mod-els -X- _ O
generally -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
shareddecoder -X- _ O
models. -X- _ O
The -X- _ O
separate-decoder -X- _ O
baseline -X- _ O
is -X- _ O
much -X- _ O
better -X- _ O
than -X- _ O
its -X- _ O
counterpart -X- _ O
as -X- _ O
it -X- _ O
avoids -X- _ O
the -X- _ O
copying -X- _ O
problem. -X- _ O
For -X- _ O
the -X- _ O
3-scf -X- _ O
flow-adapter -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
separate-decoder -X- _ O
model -X- _ O
outperforms -X- _ O
the -X- _ O
shared-decoder -X- _ O
model -X- _ O
by -X- _ O
2.44 -X- _ B-MetricValue
, -X- _ O
1.71 -X- _ B-MetricValue
, -X- _ O
0.38 -X- _ B-MetricValue
on -X- _ O
en-de -X- _ B-DatasetName
, -X- _ O
de-en -X- _ B-DatasetName
and -X- _ O
en-fr. -X- _ B-DatasetName
However -X- _ O
, -X- _ O
on -X- _ O
fr-en -X- _ B-DatasetName
, -X- _ O
the -X- _ O
shared-decoder -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
BLEU -X- _ O
socre -X- _ O
that -X- _ O
is -X- _ O
by -X- _ O
0.39 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
better. -X- _ O
A -X- _ O
similar -X- _ O
phenomenon -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
seen -X- _ O
for -X- _ O
the -X- _ O
3-glow -X- _ O
model. -X- _ O
We -X- _ O
conjecture -X- _ O
this -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
languages. -X- _ O
As -X- _ O
English -X- _ O
and -X- _ O
French -X- _ O
share -X- _ O
common -X- _ O
vocabulary -X- _ O
, -X- _ O
some -X- _ O
common -X- _ O
features -X- _ O
can -X- _ O
therefore -X- _ O
be -X- _ O
captured -X- _ O
by -X- _ O
a -X- _ O
shared -X- _ O
decoder -X- _ O
, -X- _ O
thus -X- _ O
improving -X- _ O
its -X- _ O
generalization -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
UNMT -X- _ B-TaskName
, -X- _ O
our -X- _ O
models -X- _ O
show -X- _ O
superiority -X- _ O
, -X- _ O
improving -X- _ O
performance -X- _ O
by -X- _ O
more -X- _ O
than -X- _ O
4 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
in -X- _ O
each -X- _ O
direction. -X- _ O
We -X- _ O
attribute -X- _ O
the -X- _ O
improvements -X- _ O
to -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
model -X- _ O
and -X- _ O
incorporation -X- _ O
of -X- _ O
languagespecific -X- _ O
sentence-level -X- _ O
representations -X- _ O
obtained -X- _ O
by -X- _ O
our -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
WMT -X- _ B-DatasetName
datasets -X- _ O
We -X- _ O
further -X- _ O
integrate -X- _ O
our -X- _ O
flow-adapter -X- _ O
architecture -X- _ O
into -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
of -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
WMT -X- _ B-DatasetName
datasets. -X- _ O
To -X- _ O
fully -X- _ O
leverage -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
initialize -X- _ O
both -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
with -X- _ O
XLM -X- _ B-TaskName
models -X- _ O
and -X- _ O
set -X- _ O
them -X- _ O
trainable. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
experiment -X- _ O
in -X- _ O
Section -X- _ O
4.4 -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
shared -X- _ O
decoder -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
also -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre-trained -X- _ O
model -X- _ O
and -X- _ O
has -X- _ O
far -X- _ O
more -X- _ O
parameters -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
randomly -X- _ O
initialized -X- _ O
transformer -X- _ O
decoder -X- _ O
we -X- _ O
use -X- _ O
in -X- _ O
Section -X- _ O
4.4. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
flow-adapter -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
5-scf -X- _ O
and -X- _ O
5-Models -X- _ O
en-de -X- _ B-DatasetName
de-en -X- _ B-DatasetName
en-ro -X- _ B-DatasetName
ro-en -X- _ B-DatasetName
en-fr -X- _ B-DatasetName
fr-en -X- _ B-DatasetName
XLM -X- _ B-TaskName
( -X- _ O
EMD -X- _ B-TaskName
+ -X- _ I-TaskName
EMD -X- _ I-TaskName
) -X- _ O
( -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
21 -X- _ O
glow -X- _ O
8 -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
SOTA -X- _ O
models -X- _ O
, -X- _ O
namely -X- _ O
XLM -X- _ B-TaskName
, -X- _ O
MASS -X- _ B-TaskName
and -X- _ O
CSP. -X- _ B-TaskName
9 -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3. -X- _ O
Noticeably -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
our -X- _ O
flow-adapter -X- _ B-MethodName
models -X- _ O
achieve -X- _ O
remarkable -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
language -X- _ O
pairs. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
EMD -X- _ B-TaskName
+ -X- _ I-TaskName
EMD -X- _ I-TaskName
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
the -X- _ O
pre-trained -X- _ O
cross-lingual -X- _ O
embeddings -X- _ O
instead -X- _ O
of -X- _ O
pre-trained -X- _ O
models -X- _ O
, -X- _ O
both -X- _ O
5-scf -X- _ O
and -X- _ O
5-glow -X- _ O
achieve -X- _ O
overall -X- _ O
better -X- _ O
performance. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
3-scf -X- _ O
achieves -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
higher -X- _ O
by -X- _ O
5. -X- _ B-MetricValue
20 -X- _ I-MetricValue
, -X- _ O
5.33 -X- _ B-MetricValue
, -X- _ O
6.61 -X- _ B-MetricValue
, -X- _ O
5.09 -X- _ B-MetricValue
, -X- _ O
6.37 -X- _ B-MetricValue
and -X- _ O
4.32 -X- _ B-MetricValue
on -X- _ O
en-de -X- _ B-DatasetName
, -X- _ O
de-en -X- _ B-DatasetName
, -X- _ O
en-ro -X- _ B-DatasetName
, -X- _ O
ro-en -X- _ B-DatasetName
, -X- _ O
en-fr -X- _ B-DatasetName
and -X- _ O
fr-en -X- _ B-DatasetName
, -X- _ O
respectively. -X- _ O
While -X- _ O
not -X- _ O
being -X- _ O
as -X- _ O
good -X- _ O
as -X- _ O
5-scf -X- _ O
, -X- _ O
5-glow -X- _ O
still -X- _ O
shows -X- _ O
superiority -X- _ O
over -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
EMD -X- _ B-TaskName
+ -X- _ I-TaskName
EMD -X- _ I-TaskName
) -X- _ O
. -X- _ O
These -X- _ O
improvements -X- _ O
can -X- _ O
be -X- _ O
contributed -X- _ O
to -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
pre-trained -X- _ O
models -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
the -X- _ O
flow-adapter. -X- _ O
We -X- _ O
further -X- _ O
compare -X- _ O
our -X- _ O
flow-adapter -X- _ O
based -X- _ O
models -X- _ O
with -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
MLM -X- _ B-TaskName
+ -X- _ I-TaskName
MLM -X- _ I-TaskName
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
initialized -X- _ O
with -X- _ O
pre-trained -X- _ O
models. -X- _ O
We -X- _ O
find -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
x-en -X- _ O
directions -X- _ O
is -X- _ O
consistently -X- _ O
lower -X- _ O
than -X- _ O
en-x -X- _ O
directions -X- _ O
for -X- _ O
our -X- _ O
models -X- _ O
except -X- _ O
for -X- _ O
ende. -X- _ O
This -X- _ O
pattern -X- _ O
is -X- _ O
not -X- _ O
limited -X- _ O
to -X- _ O
our -X- _ O
architecture -X- _ O
but -X- _ O
is -X- _ O
consistently -X- _ O
present -X- _ O
in -X- _ O
prior -X- _ O
work. -X- _ O
We -X- _ O
, -X- _ O
again -X- _ O
, -X- _ O
speculate -X- _ O
this -X- _ O
is -X- _ O
relating -X- _ O
to -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
languages -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
similarity -X- _ O
between -X- _ O
languages. -X- _ O
We -X- _ O
leave -X- _ O
this -X- _ O
finding -X- _ O
for -X- _ O
future -X- _ O
investigation. -X- _ O
Our -X- _ O
flow-adapter -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
though -X- _ O
achieving -X- _ O
similar -X- _ O
or -X- _ O
relatively -X- _ O
worse -X- _ O
BLEU -X- _ O
scores -X- _ O
on -X- _ O
de-en -X- _ O
and -X- _ O
ro-en -X- _ O
compared -X- _ O
with -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
MLM -X- _ B-TaskName
+ -X- _ I-TaskName
MLM -X- _ I-TaskName
) -X- _ O
, -X- _ O
obtain -X- _ O
higher -X- _ O
scores -X- _ O
on -X- _ O
other -X- _ O
directions -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
en-de -X- _ O
and -X- _ O
en-ro -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
might -X- _ O
be -X- _ O
more -X- _ O
helpful -X- _ O
on -X- _ O
specific -X- _ O
translation -X- _ O
directions -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
flow-adapter -X- _ O
generates -X- _ O
language-specific -X- _ O
rep- -X- _ O
8 -X- _ O
Preliminary -X- _ O
experiments -X- _ O
showed -X- _ O
that -X- _ O
using -X- _ O
5 -X- _ O
flows -X- _ O
provides -X- _ O
slightly -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
3 -X- _ O
flows -X- _ O
for -X- _ O
WMT -X- _ B-DatasetName
as -X- _ O
WMT -X- _ B-DatasetName
has -X- _ O
many -X- _ O
more -X- _ O
sentences -X- _ O
than -X- _ O
Multi30K -X- _ B-DatasetName
and -X- _ O
therefore -X- _ O
more -X- _ O
powerful -X- _ O
generative -X- _ O
models -X- _ O
( -X- _ O
by -X- _ O
adding -X- _ O
more -X- _ O
intermediate -X- _ O
flows -X- _ O
) -X- _ O
are -X- _ O
needed -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
sentence-level -X- _ O
representations. -X- _ O
9 -X- _ O
We -X- _ O
follow -X- _ O
prior -X- _ O
convention -X- _ O
and -X- _ O
compare -X- _ O
directly -X- _ O
with -X- _ O
MASS -X- _ B-DatasetName
and -X- _ O
CSP -X- _ B-DatasetName
even -X- _ O
though -X- _ O
dataset -X- _ O
processing -X- _ O
for -X- _ O
MASS -X- _ B-DatasetName
and -X- _ O
CSP -X- _ B-DatasetName
( -X- _ O
e.g. -X- _ O
, -X- _ O
filtering -X- _ O
, -X- _ O
sampling -X- _ O
) -X- _ O
are -X- _ O
not -X- _ O
strictly -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
for -X- _ O
XLM. -X- _ B-DatasetName
But -X- _ O
the -X- _ O
difference -X- _ O
is -X- _ O
small -X- _ O
and -X- _ O
results -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
much -X- _ O
different -X- _ O
as -X- _ O
mentions. -X- _ O
resentations. -X- _ O
Lastly -X- _ O
, -X- _ O
5-scf -X- _ O
achieves -X- _ O
scores -X- _ O
by -X- _ O
2.37 -X- _ B-MetricValue
and -X- _ O
0.42 -X- _ B-MetricValue
better -X- _ O
than -X- _ O
XLM -X- _ B-TaskName
( -X- _ O
MLM -X- _ B-TaskName
+ -X- _ I-TaskName
MLM -X- _ I-TaskName
) -X- _ O
on -X- _ O
en-fr -X- _ B-DatasetName
and -X- _ O
fr-en. -X- _ B-DatasetName
As -X- _ O
in -X- _ O
the -X- _ O
other -X- _ O
experiments -X- _ O
, -X- _ O
the -X- _ O
improvement -X- _ O
due -X- _ O
to -X- _ O
flow -X- _ O
adapters -X- _ O
seems -X- _ O
to -X- _ O
be -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
languages -X- _ O
involved -X- _ O
in -X- _ O
that -X- _ O
language -X- _ O
pair -X- _ O
and -X- _ O
the -X- _ O
translation -X- _ O
directions. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
investigate -X- _ O
this -X- _ O
phenomenon -X- _ O
in -X- _ O
future -X- _ O
research -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
out -X- _ O
models -X- _ O
are -X- _ O
competitve -X- _ O
with -X- _ O
MASS -X- _ B-TaskName
and -X- _ O
CSP -X- _ B-TaskName
, -X- _ O
with -X- _ O
only -X- _ O
small -X- _ O
differences -X- _ O
in -X- _ O
BLEU. -X- _ B-MetricName
In -X- _ O
general -X- _ O
, -X- _ O
the -X- _ O
experiments -X- _ O
shows -X- _ O
the -X- _ O
validity -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
flow-adapter -X- _ B-MethodName
architecture -X- _ O
integrated -X- _ O
into -X- _ O
pre-trained -X- _ O
models -X- _ O
. -X- _ O

Conclusion -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
flow-adapter -X- _ B-MethodName
architecture -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
NMT. -X- _ I-TaskName
The -X- _ O
flow-adapter -X- _ B-MethodName
employs -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
NFs -X- _ O
to -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
distributions -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
representations. -X- _ O
A -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
is -X- _ O
performed -X- _ O
in -X- _ O
translation -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
better -X- _ O
capture -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
certain -X- _ O
language -X- _ O
domains. -X- _ O
Through -X- _ O
extensive -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
flow-adapter -X- _ O
can -X- _ O
improve -X- _ O
multilingual -X- _ O
translation -X- _ O
ability. -X- _ O
Moreover -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
alleviate -X- _ O
the -X- _ O
copying -X- _ O
problem. -X- _ O
By -X- _ O
integrating -X- _ O
the -X- _ O
flow-adapter -X- _ O
into -X- _ O
pretrained -X- _ O
XLM -X- _ B-TaskName
models -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
results -X- _ O
competitive -X- _ O
to -X- _ O
state-of-the-art -X- _ O
models -X- _ O
on -X- _ O
WMT -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
pre-training -X- _ O
the -X- _ O
flow-adapter -X- _ B-MethodName
simultaneously -X- _ O
when -X- _ O
pre-training -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
flows -X- _ O
can -X- _ O
learn -X- _ O
more -X- _ O
information. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
extend -X- _ O
normalizing -X- _ O
flows -X- _ O
to -X- _ O
language -X- _ O
generation. -X- _ O
By -X- _ O
using -X- _ O
different -X- _ O
flows -X- _ O
for -X- _ O
different -X- _ O
languages -X- _ O
, -X- _ O
multilingual -X- _ O
language -X- _ O
generation -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
semantics -X- _ O
can -X- _ O
be -X- _ O
performed -X- _ O
. -X- _ O

A.1 -X- _ O
Proof -X- _ O
of -X- _ O
the -X- _ O
Invertibility -X- _ O
The -X- _ O
following -X- _ O
proof -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
proof -X- _ O
by -X- _ O
Grover -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
shows -X- _ O
the -X- _ O
source-to-target -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
is -X- _ O
the -X- _ O
inverse -X- _ O
of -X- _ O
the -X- _ O
target-tosource -X- _ O
latent -X- _ O
code -X- _ O
transformation -X- _ O
, -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
: -X- _ O

A.2 -X- _ O
Generation -X- _ O
of -X- _ O
Sentence-level -X- _ O
Representation -X- _ O
The -X- _ O
following -X- _ O
formula -X- _ O
shows -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
how -X- _ O
the -X- _ O
sentence-level -X- _ O
representation -X- _ O
is -X- _ O
generated -X- _ O
: -X- _ O

where -X- _ O
the -X- _ O
pooling -X- _ O
operation -X- _ O
generates -X- _ O
a -X- _ O
vector -X- _ O
that -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
dimension -X- _ O
as -X- _ O
h -X- _ O
0 -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
three -X- _ O
vectors -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
and -X- _ O
therefore -X- _ O
are -X- _ O
additive. -X- _ O
An -X- _ O
illustration -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

A.3.1 -X- _ O
Multi30K -X- _ B-DatasetName
Experiment -X- _ O
For -X- _ O
the -X- _ O
multilingual -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
cross-lingual -X- _ O
MUSE -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
embeddings -X- _ O
were -X- _ O
learned -X- _ O
using -X- _ O
fastText -X- _ B-TaskName
10 -X- _ O
( -X- _ O
Bojanowski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
on -X- _ O
Wikipedia -X- _ O
data -X- _ O
and -X- _ O
then -X- _ O
aligned -X- _ O
in -X- _ O
a -X- _ O
common -X- _ O
space -X- _ O
by -X- _ O
the -X- _ O
method -X- _ O
proposed -X- _ O
by -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
over -X- _ O
10 -X- _ O
runs -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets. -X- _ O
Denosing -X- _ O
auto-encoding -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
baseline -X- _ O
model. -X- _ O
The -X- _ O
flow-adapter -X- _ O
based -X- _ O
( -X- _ O
3-scf -X- _ O
and -X- _ O
3-glow -X- _ O
) -X- _ O
models -X- _ O
are -X- _ O
additionally -X- _ O
trained -X- _ O
with -X- _ O
MLE -X- _ O
loss. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
denoising -X- _ O
auto-encoding -X- _ O
hyperparameter -X- _ O
settings -X- _ O
used -X- _ O
by -X- _ O
Lample -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
word -X- _ O
drop -X- _ O
and -X- _ O
word -X- _ O
shuffling -X- _ O
are -X- _ O
used. -X- _ O
For -X- _ O
word -X- _ O
drop -X- _ O
, -X- _ O
every -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
( -X- _ O
except -X- _ O
< -X- _ O
bos -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
eos -X- _ O
> -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
dropped -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ O
p -X- _ B-HyperparameterName
wd -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
we -X- _ O
set -X- _ O
0.1 -X- _ B-HyperparameterValue
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

For -X- _ O
word -X- _ O
shuffling -X- _ O
, -X- _ O
a -X- _ O
random -X- _ O
permutation -X- _ O
σ -X- _ B-HyperparameterName
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
satisfy -X- _ O
the -X- _ O
condition -X- _ O
: -X- _ O
∀i -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
|σ -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
− -X- _ O
i| -X- _ O
≤ -X- _ O
k -X- _ O
, -X- _ O
where -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
index -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
sequence -X- _ O
, -X- _ O
n -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
and -X- _ O
k -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
hyperparameter -X- _ O
that -X- _ O
controls -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
the -X- _ O
permutation -X- _ O
which -X- _ O
we -X- _ O
set -X- _ O
3 -X- _ O
in -X- _ O
our -X- _ O
experiments. -X- _ O
The -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
pre-trained -X- _ O
embedding -X- _ O
is -X- _ O
300. -X- _ B-HyperparameterValue
The -X- _ O
randomly -X- _ O
initialized -X- _ O
shared -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
use -X- _ O
transformer -X- _ O
architecture -X- _ O
with -X- _ O
512 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
, -X- _ O
4 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
and -X- _ O
3 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
by -X- _ O
default. -X- _ O
We -X- _ O
use -X- _ O
separate -X- _ O
embedding -X- _ O
layers -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
and -X- _ O
tie -X- _ O
their -X- _ O
weights -X- _ O
with -X- _ O
the -X- _ O
output -X- _ O
layers -X- _ O
for -X- _ O
each -X- _ O
language. -X- _ O
The -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ B-HyperparameterName
latent -X- _ I-HyperparameterName
representation -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
100. -X- _ B-HyperparameterValue
And -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
MLE -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
flows -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
0.01. -X- _ B-HyperparameterValue
We -X- _ O
use -X- _ O
dropout -X- _ B-HyperparameterName
( -X- _ O
Srivastava -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
probability -X- _ O
of -X- _ O
0.2 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
transformers -X- _ O
and -X- _ O
0 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
flows. -X- _ O
The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
32. -X- _ B-HyperparameterValue
The -X- _ O
whole -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
end-to-end -X- _ O
manner -X- _ O
with -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
an -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.0001. -X- _ B-HyperparameterValue
For -X- _ O
the -X- _ O
shared-decoder -X- _ O
& -X- _ O
separate-decoder -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
xlm-mlm-enfr-1024 -X- _ O
, -X- _ O
xlm-mlm-ende-1024 -X- _ O
, -X- _ O
xlm-mlmenro-1024 -X- _ O
from -X- _ O
HuggingFace -X- _ O
11 -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
The -X- _ O
illustration -X- _ O
of -X- _ O
generation -X- _ O
of -X- _ O
the -X- _ O
sentence-level -X- _ O
representations. -X- _ O
CLS -X- _ O
embedding -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
vector -X- _ O
output -X- _ O
by -X- _ O
the -X- _ O
transformer -X- _ O
encoder -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
h -X- _ O
0 -X- _ O
. -X- _ O

to -X- _ O
initialize -X- _ O
a -X- _ O
shared -X- _ O
encoder -X- _ O
and -X- _ O
randomly -X- _ O
initialize -X- _ O
the -X- _ O
decoder -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
.using -X- _ O
pre-trained -X- _ O
models. -X- _ O
Denosing -X- _ O
auto-encoding -X- _ O
and -X- _ O
iterative -X- _ O
back-translation -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
baseline -X- _ O
model. -X- _ O
The -X- _ O
flowadapter -X- _ O
based -X- _ O
( -X- _ O
3-scf -X- _ O
and -X- _ O
3-glow -X- _ O
) -X- _ O
models -X- _ O
are -X- _ O
additionally -X- _ O
trained -X- _ O
with -X- _ O
MLE -X- _ O
loss. -X- _ O
The -X- _ O
same -X- _ O
denoising -X- _ O
auto-encoding -X- _ O
hyperparameters -X- _ O
as -X- _ O
above -X- _ O
are -X- _ O
used. -X- _ O
For -X- _ O
iterative -X- _ O
back-translation -X- _ O
, -X- _ O
greedy -X- _ O
decoding -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
synthetic -X- _ O
parallel -X- _ O
sentences -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
reconstructions. -X- _ O
A -X- _ O
single -X- _ O
embedding -X- _ O
layer -X- _ O
( -X- _ O
from -X- _ O
the -X- _ O
pre-trained -X- _ O
model -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
and -X- _ O
its -X- _ O
weight -X- _ O
is -X- _ O
tied -X- _ O
with -X- _ O
the -X- _ O
output -X- _ O
layer. -X- _ O
The -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
are -X- _ O
fixed -X- _ O
except -X- _ O
for -X- _ O
its -X- _ O
embedding -X- _ O
layer -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
decoder -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
size -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
sentence-level -X- _ O
latent -X- _ O
representation -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
256. -X- _ B-HyperparameterValue
The -X- _ O
pre-trained -X- _ O
encoder -X- _ O
uses -X- _ O
1024 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
GELU -X- _ B-HyperparameterValue
activations -X- _ B-HyperparameterName
( -X- _ O
Hendrycks -X- _ O
and -X- _ O
Gimpel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
4096 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
, -X- _ O
8 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
and -X- _ O
6 -X- _ O
layers. -X- _ B-HyperparameterName
The -X- _ O
randomly -X- _ O
initialized -X- _ O
decoder -X- _ O
has -X- _ O
512 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
, -X- _ O
8 -X- _ B-HyperparameterValue
heads -X- _ B-HyperparameterName
and -X- _ O
3 -X- _ B-HyperparameterValue
layers. -X- _ B-HyperparameterName
The -X- _ O
models -X- _ O
are -X- _ O
firstly -X- _ O
trained -X- _ O
with -X- _ O
DAE -X- _ O
loss -X- _ O
( -X- _ O
and -X- _ O
MLE -X- _ O
loss -X- _ O
for -X- _ O
flow-adapter -X- _ O
models -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
then -X- _ O
trained -X- _ O
with -X- _ O
all -X- _ O
losses -X- _ O
( -X- _ O
including -X- _ O
the -X- _ O
iterative -X- _ O
back-translation -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
rest -X- _ O
epochs. -X- _ O
The -X- _ O
rest -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
above -X- _ O
. -X- _ O

A.3.2 -X- _ O
WMT -X- _ B-DatasetName
Experiment -X- _ O
We -X- _ O
insert -X- _ O
our -X- _ O
implementation -X- _ O
of -X- _ O
flow-adapter -X- _ O
architecture -X- _ O
into -X- _ O
the -X- _ O
codebase -X- _ O
of -X- _ O
XLM -X- _ B-TaskName
12 -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
pretrained -X- _ O
model -X- _ O
of -X- _ O
en-fr -X- _ B-DatasetName
, -X- _ O
en-de -X- _ B-DatasetName
and -X- _ O
en-ro -X- _ B-DatasetName
from -X- _ O
them. -X- _ O
We -X- _ O
also -X- _ O
follow -X- _ O
their -X- _ O
recommended -X- _ O
unsupervised -X- _ O
training -X- _ O
settings. -X- _ O
For -X- _ O
the -X- _ O
flow-related -X- _ O
hyperparameters -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
256 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
sentence-level -X- _ O
latent -X- _ O
representation. -X- _ O
The -X- _ O
weight -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
MLE -X- _ O
loss -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O

WeCheck -X- _ B-MethodName
: -X- _ O
Strong -X- _ B-MethodName
Factual -X- _ I-MethodName
Consistency -X- _ I-MethodName
Checker -X- _ I-MethodName
via -X- _ I-MethodName
Weakly -X- _ I-MethodName
Supervised -X- _ I-MethodName
Learning -X- _ I-MethodName

A -X- _ O
crucial -X- _ O
issue -X- _ O
of -X- _ O
current -X- _ O
text -X- _ O
generation -X- _ O
models -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
often -X- _ O
uncontrollably -X- _ O
generate -X- _ O
text -X- _ O
that -X- _ O
is -X- _ O
factually -X- _ O
inconsistent -X- _ O
with -X- _ O
inputs. -X- _ O
Due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
annotated -X- _ O
data -X- _ O
, -X- _ O
existing -X- _ O
factual -X- _ O
consistency -X- _ O
metrics -X- _ O
usually -X- _ O
train -X- _ O
evaluation -X- _ O
models -X- _ O
on -X- _ O
synthetic -X- _ O
texts -X- _ O
or -X- _ O
directly -X- _ O
transfer -X- _ O
from -X- _ O
other -X- _ O
related -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
and -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
. -X- _ O
Bias -X- _ O
in -X- _ O
synthetic -X- _ O
text -X- _ O
or -X- _ O
upstream -X- _ O
tasks -X- _ O
makes -X- _ O
them -X- _ O
perform -X- _ O
poorly -X- _ O
on -X- _ O
text -X- _ O
actually -X- _ O
generated -X- _ O
by -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
general -X- _ O
evaluation -X- _ O
for -X- _ O
various -X- _ O
tasks. -X- _ O
To -X- _ O
alleviate -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
weakly -X- _ O
supervised -X- _ O
framework -X- _ O
named -X- _ O
WeCheck -X- _ B-MethodName
that -X- _ O
is -X- _ O
directly -X- _ O
trained -X- _ O
on -X- _ O
actual -X- _ O
generated -X- _ O
samples -X- _ O
from -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
weakly -X- _ O
annotated -X- _ O
labels. -X- _ O
WeCheck -X- _ B-MethodName
first -X- _ O
utilizes -X- _ O
a -X- _ O
generative -X- _ O
model -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
factual -X- _ O
labels -X- _ O
of -X- _ O
generated -X- _ O
samples -X- _ O
by -X- _ O
aggregating -X- _ O
weak -X- _ O
labels -X- _ O
from -X- _ O
multiple -X- _ O
resources. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
simple -X- _ O
noise-aware -X- _ O
classification -X- _ O
model -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
metric -X- _ O
using -X- _ O
the -X- _ O
inferred -X- _ O
weakly -X- _ O
supervised -X- _ O
information. -X- _ O
Comprehensive -X- _ O
experiments -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
demonstrate -X- _ O
the -X- _ O
strong -X- _ O
performance -X- _ O
of -X- _ O
WeCheck -X- _ B-MethodName
, -X- _ O
achieving -X- _ O
an -X- _ O
average -X- _ B-MetricName
absolute -X- _ I-MetricName
improvement -X- _ I-MetricName
of -X- _ O
3.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
TRUE -X- _ B-TaskName
benchmark -X- _ O
over -X- _ O
11B -X- _ O
state-of-the-art -X- _ O
methods -X- _ O
using -X- _ O
only -X- _ O
435M -X- _ O
parameters. -X- _ O
Furthermore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
up -X- _ O
to -X- _ O
30× -X- _ O
faster -X- _ O
than -X- _ O
previous -X- _ O
evaluation -X- _ O
methods -X- _ O
, -X- _ O
greatly -X- _ O
improving -X- _ O
the -X- _ O
accuracy -X- _ O
and -X- _ O
efficiency -X- _ O
of -X- _ O
factual -X- _ O
consistency -X- _ O
evaluation. -X- _ O
1 -X- _ O
* -X- _ O
Work -X- _ O
is -X- _ O
done -X- _ O
during -X- _ O
an -X- _ O
internship -X- _ O
at -X- _ O
Baidu -X- _ O
Inc -X- _ O
. -X- _ O

Introduction -X- _ O
The -X- _ O
research -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
has -X- _ O
achieved -X- _ O
significant -X- _ O
progress -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
still -X- _ O
suffers -X- _ O
the -X- _ O
main -X- _ O
issue -X- _ O
of -X- _ O
generating -X- _ O
output -X- _ O
which -X- _ O
is -X- _ O
factually -X- _ O
inconsistent -X- _ O
with -X- _ O
the -X- _ O
given -X- _ O
inputs -X- _ O
( -X- _ O
Maynez -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
various -X- _ O
metrics -X- _ O
have -X- _ O
been -X- _ O
designed -X- _ O
to -X- _ O
check -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
generated -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
given -X- _ O
inputs -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Scialom -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
know -X- _ O
, -X- _ O
how -X- _ O
to -X- _ O
construct -X- _ O
such -X- _ O
a -X- _ O
metric -X- _ O
has -X- _ O
attracted -X- _ O
increasing -X- _ O
attention -X- _ O
in -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
fields -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022b -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
text -X- _ O
summarization -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
dialogue -X- _ O
generation -X- _ O
( -X- _ O
Welleck -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
text -X- _ O
simplification -X- _ O
( -X- _ O
Devaraj -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

Existing -X- _ O
factual -X- _ O
metrics -X- _ O
can -X- _ O
be -X- _ O
classified -X- _ O
into -X- _ O
two -X- _ O
types -X- _ O
: -X- _ O
one -X- _ O
based -X- _ O
on -X- _ O
synthetic -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
based -X- _ O
on -X- _ O
task -X- _ O
transfer. -X- _ O
Synthetic-data -X- _ O
based -X- _ O
metrics -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Mishra -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
apply -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
to -X- _ O
construct -X- _ O
factual -X- _ O
and -X- _ O
non-factual -X- _ O
texts -X- _ O
as -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
samples -X- _ O
, -X- _ O
respectively. -X- _ O
Metrics -X- _ O
trained -X- _ O
from -X- _ O
these -X- _ O
synthetic -X- _ O
samples -X- _ O
often -X- _ O
perform -X- _ O
poorly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
significant -X- _ O
mismatch -X- _ O
between -X- _ O
features -X- _ O
of -X- _ O
actual -X- _ O
generated -X- _ O
and -X- _ O
synthetic -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
distribution -X- _ O
of -X- _ O
factual -X- _ O
errors -X- _ O
) -X- _ O
( -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Task-transfer -X- _ O
based -X- _ O
metrics -X- _ O
utilize -X- _ O
the -X- _ O
reasoning -X- _ O
ability -X- _ O
of -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
relevant -X- _ O
upstream -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
( -X- _ O
Falke -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Laban -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Fabbri -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
directly -X- _ O
apply -X- _ O
them -X- _ O
to -X- _ O
evaluate -X- _ O
factual -X- _ O
consistency -X- _ O
without -X- _ O
any -X- _ O
adaption -X- _ O
. -X- _ O

As -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
previous -X- _ O
metrics -X- _ O
are -X- _ O
learned -X- _ O
indirectly -X- _ O
from -X- _ O
other -X- _ O
related -X- _ O
resources -X- _ O
but -X- _ O
without -X- _ O
seeing -X- _ O
the -X- _ O
actual -X- _ O
generated -X- _ O
text. -X- _ O
In -X- _ O
such -X- _ O
cases -X- _ O
, -X- _ O
they -X- _ O
may -X- _ O
overfit -X- _ O
to -X- _ O
their -X- _ O
upstream -X- _ O
tasks -X- _ O
and -X- _ O
fail -X- _ O
to -X- _ O
generalize -X- _ O
to -X- _ O
actual -X- _ O
generated -X- _ O
samples -X- _ O
that -X- _ O
have -X- _ O
significantly -X- _ O
different -X- _ O
data -X- _ O
features. -X- _ O
Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
the -X- _ O
probability -X- _ O
density -X- _ O
of -X- _ O
three -X- _ O
metrics -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
horizontal -X- _ O
axis -X- _ O
is -X- _ O
metric -X- _ O
scores -X- _ O
and -X- _ O
the -X- _ O
vertical -X- _ O
axis -X- _ O
is -X- _ O
the -X- _ O
score -X- _ O
density. -X- _ O
Though -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
comparable -X- _ O
in -X- _ O
performance -X- _ O
, -X- _ O
they -X- _ O
vary -X- _ O
significantly -X- _ O
in -X- _ O
probability -X- _ O
distributions -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
XSUM -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
where -X- _ O
sample -X- _ O
features -X- _ O
are -X- _ O
greatly -X- _ O
different -X- _ O
from -X- _ O
upstream -X- _ O
tasks -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
2 -X- _ O
, -X- _ O
NLI-warmup -X- _ B-MethodName
is -X- _ O
extremely -X- _ O
confident -X- _ O
in -X- _ O
predicting -X- _ O
both -X- _ O
very -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
scores -X- _ O
while -X- _ O
SUMMAC -X- _ B-MethodName
and -X- _ O
QAFact -X- _ B-MethodName
are -X- _ O
only -X- _ O
confident -X- _ O
in -X- _ O
predicting -X- _ O
low -X- _ O
scores -X- _ O
3 -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
during -X- _ O
testing -X- _ O
, -X- _ O
ensembling -X- _ O
different -X- _ O
metric -X- _ O
scores -X- _ O
by -X- _ O
simply -X- _ O
averaging -X- _ O
will -X- _ O
further -X- _ O
improve -X- _ O
their -X- _ O
performance -X- _ O
( -X- _ O
Honovich -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
also -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
learned -X- _ O
from -X- _ O
different -X- _ O
resources -X- _ O
are -X- _ O
also -X- _ O
complementary -X- _ O
. -X- _ O

To -X- _ O
bridge -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
and -X- _ O
mitigate -X- _ O
the -X- _ O
scarcity -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
WeCheck -X- _ B-MethodName
, -X- _ O
a -X- _ O
factual -X- _ O
consistency -X- _ O
Checking -X- _ O
framework -X- _ O
based -X- _ O
on -X- _ O
Weakly -X- _ O
supervised -X- _ O
learning. -X- _ O
Specifically -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
learning -X- _ O
paradigm -X- _ O
that -X- _ O
provides -X- _ O
weak -X- _ O
supervision -X- _ O
via -X- _ O
modeling -X- _ O
multiple -X- _ O
label -X- _ O
sources -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
ground -X- _ O
truth. -X- _ O
Different -X- _ O
from -X- _ O
previous -X- _ O
metrics -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
directly -X- _ O
utilizes -X- _ O
the -X- _ O
abundant -X- _ O
actual -X- _ O
generated -X- _ O
samples -X- _ O
bootstrapped -X- _ O
from -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
target -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
e.g. -X- _ O
BART -X- _ O
on -X- _ O
text -X- _ O
summarization. -X- _ O
Then -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
follows -X- _ O
a -X- _ O
two-step -X- _ O
pipeline -X- _ O
consisting -X- _ O
of -X- _ O
weak -X- _ O
annotation -X- _ O
and -X- _ O
noiseaware -X- _ O
fine-tuning -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
target -X- _ O
metric -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
weak -X- _ O
annotation -X- _ O
step -X- _ O
, -X- _ O
by -X- _ O
aggregating -X- _ O
multiple -X- _ O
weak -X- _ O
supervision -X- _ O
resources -X- _ O
, -X- _ O
we -X- _ O
infer -X- _ O
the -X- _ O
unknown -X- _ O
ground -X- _ O
truth -X- _ O
label -X- _ O
of -X- _ O
a -X- _ O
sample. -X- _ O
To -X- _ O
reach -X- _ O
this -X- _ O
goal -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
provide -X- _ O
each -X- _ O
sample -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
calculated -X- _ O
from -X- _ O
various -X- _ O
other -X- _ O
metrics. -X- _ O
These -X- _ O
metrics -X- _ O
are -X- _ O
learned -X- _ O
from -X- _ O
various -X- _ O
resources -X- _ O
or -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
QA-based -X- _ B-TaskName
metrics -X- _ O
and -X- _ O
NLI-based -X- _ B-TaskName
metrics. -X- _ O
After -X- _ O
unifying -X- _ O
and -X- _ O
filtering -X- _ O
these -X- _ O
signals -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
generative -X- _ O
labeling -X- _ O
model -X- _ O
that -X- _ O
models -X- _ O
agreements -X- _ O
and -X- _ O
disagreements -X- _ O
between -X- _ O
them -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
their -X- _ O
latent -X- _ O
ground -X- _ O
truth -X- _ O
label. -X- _ O
The -X- _ O
inferred -X- _ O
ground -X- _ O
truth -X- _ O
likelihood -X- _ O
is -X- _ O
then -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
probabilistic -X- _ O
label -X- _ O
to -X- _ O
provide -X- _ O
weak -X- _ O
supervision. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
noise-aware -X- _ O
fine-tuning -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
target -X- _ O
metric -X- _ O
model. -X- _ O
It -X- _ O
is -X- _ O
noted -X- _ O
here -X- _ O
, -X- _ O
the -X- _ O
weak -X- _ O
annotation -X- _ O
also -X- _ O
brings -X- _ O
noises -X- _ O
to -X- _ O
the -X- _ O
supervision -X- _ O
signal -X- _ O
and -X- _ O
brings -X- _ O
new -X- _ O
challenges -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
optimization -X- _ O
process. -X- _ O
As -X- _ O
a -X- _ O
solution -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
warmup -X- _ O
our -X- _ O
target -X- _ O
metric -X- _ O
model -X- _ O
with -X- _ O
NLI -X- _ B-TaskName
data -X- _ O
for -X- _ O
a -X- _ O
better -X- _ O
initialization -X- _ O
before -X- _ O
weakly -X- _ O
supervised -X- _ O
training. -X- _ O
Then -X- _ O
, -X- _ O
after -X- _ O
filtering -X- _ O
out -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
noisy -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
our -X- _ O
target -X- _ O
metric -X- _ O
model -X- _ O
with -X- _ O
weak -X- _ O
annotations. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
could -X- _ O
learn -X- _ O
how -X- _ O
to -X- _ O
utilize -X- _ O
multiple -X- _ O
resources -X- _ O
for -X- _ O
weak -X- _ O
annotation -X- _ O
while -X- _ O
recognizing -X- _ O
and -X- _ O
filtering -X- _ O
the -X- _ O
potential -X- _ O
noises -X- _ O
accompanied -X- _ O
by -X- _ O
weak -X- _ O
supervision -X- _ O
. -X- _ O

Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
WeCheck -X- _ B-MethodName
not -X- _ O
only -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
but -X- _ O
also -X- _ O
is -X- _ O
computationally -X- _ O
efficient. -X- _ O
On -X- _ O
the -X- _ O
TRUE -X- _ O
benchmark -X- _ O
( -X- _ O
Honovich -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
current -X- _ O
most -X- _ O
comprehensive -X- _ O
benchmark -X- _ O
for -X- _ O
factual -X- _ O
consistency -X- _ O
evaluation -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
obtains -X- _ O
an -X- _ O
average -X- _ B-MetricName
ROC -X- _ I-MetricName
AUC -X- _ I-MetricName
of -X- _ O
84.8 -X- _ B-MetricValue
, -X- _ O
3.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ O
improvement -X- _ O
over -X- _ O
previous -X- _ O
11B -X- _ O
pre-trained -X- _ O
task -X- _ O
transferred -X- _ O
metrics -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
size -X- _ O
of -X- _ O
435M -X- _ O
parameters. -X- _ O
Moreover -X- _ O
, -X- _ O
it -X- _ O
's -X- _ O
much -X- _ O
more -X- _ O
stable -X- _ O
for -X- _ O
various -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
with -X- _ O
much -X- _ O
lower -X- _ O
variance -X- _ O
on -X- _ O
different -X- _ O
tasks. -X- _ O
Thus -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
a -X- _ O
simple -X- _ O
but -X- _ O
more -X- _ O
effective -X- _ O
and -X- _ O
efficient -X- _ O
metric -X- _ O
for -X- _ O
factual -X- _ O
consistency -X- _ O
evaluation -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
factual -X- _ O
consistency -X- _ O
evaluation -X- _ O
metric -X- _ O
based -X- _ O
on -X- _ O
weakly -X- _ O
supervised -X- _ O
learning -X- _ O
, -X- _ O
namely -X- _ O
WeCheck -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
directly -X- _ O
trained -X- _ O
on -X- _ O
actual -X- _ O
generated -X- _ O
samples -X- _ O
from -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
weakly -X- _ O
annotated -X- _ O
labels -X- _ O
. -X- _ O

• -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
both -X- _ O
effective -X- _ O
and -X- _ O
efficient -X- _ O
achieving -X- _ O
3.3 -X- _ O
% -X- _ O
absolute -X- _ O
improvement -X- _ O
and -X- _ O
up -X- _ O
to -X- _ O
30 -X- _ O
times -X- _ O
faster -X- _ O
comparing -X- _ O
with -X- _ O
previous -X- _ O
state-ofart -X- _ O
metrics -X- _ O
. -X- _ O

• -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
metric -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
more -X- _ O
stable -X- _ O
on -X- _ O
various -X- _ O
generation -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
than -X- _ O
previous -X- _ O
methods -X- _ O
. -X- _ O

WeCheck -X- _ B-MethodName
Framework -X- _ O
Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
two-step -X- _ O
pipeline -X- _ O
of -X- _ O
WeCheck -X- _ B-MethodName
framework. -X- _ O
In -X- _ O
the -X- _ O
upper -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
during -X- _ O
the -X- _ O
weak -X- _ O
annotation -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
calculate -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
for -X- _ O
each -X- _ O
< -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
s -X- _ O
h -X- _ O
a -X- _ O
1 -X- _ O
_ -X- _ O
b -X- _ O
a -X- _ O
s -X- _ O
e -X- _ O
6 -X- _ O
4 -X- _ O
= -X- _ O
" -X- _ O
p -X- _ O
c -X- _ O
m -X- _ O
T -X- _ O
Y -X- _ O
4 -X- _ O
n -X- _ O
3 -X- _ O
q -X- _ O
a -X- _ O
J -X- _ O
V -X- _ O
+ -X- _ O
S -X- _ O
I -X- _ O
l -X- _ O
z -X- _ O
W -X- _ O
R -X- _ O
D -X- _ O
o -X- _ O
c -X- _ O
H -X- _ O
p -X- _ O
i -X- _ O
s -X- _ O
0 -X- _ O
= -X- _ O
" -X- _ O
> -X- _ O
A -X- _ O

Noise-aware -X- _ O
fine-tuning -X- _ O
first -X- _ O
warmup -X- _ O
target -X- _ O
metric -X- _ O
model -X- _ O
with -X- _ O
NLI -X- _ B-TaskName
data -X- _ O
and -X- _ O
training -X- _ O
it -X- _ O
with -X- _ O
filtered -X- _ O
probabilistic -X- _ O
labels. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
our -X- _ O
problem -X- _ O
definition -X- _ O
and -X- _ O
detailed -X- _ O
method -X- _ O
. -X- _ O

Problem -X- _ O
Definition -X- _ O
Factual -X- _ O
Consistency -X- _ O
Evaluation -X- _ O
Given -X- _ O
a -X- _ O
textual -X- _ O
sequence -X- _ O
as -X- _ O
a -X- _ O
premise -X- _ O
, -X- _ O
and -X- _ O
another -X- _ O
textual -X- _ O
sequence -X- _ O
as -X- _ O
a -X- _ O
hypothesis -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
generated -X- _ O
summary -X- _ O
or -X- _ O
dialogue -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
a -X- _ O
factual -X- _ O
consistency -X- _ O
metric -X- _ O
f -X- _ O
θ -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
hypothesis -X- _ O
is -X- _ O
factual -X- _ O
consistent -X- _ O
given -X- _ O
the -X- _ O
premise. -X- _ O
For -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
previous -X- _ O
textual -X- _ O
entailment -X- _ O
based -X- _ O
framework -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
takes -X- _ O
x -X- _ O
, -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
hypothesis -X- _ O
and -X- _ O
premise -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
format -X- _ O
and -X- _ O
unifies -X- _ O
the -X- _ O
evaluation -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
problem -X- _ O
: -X- _ O
f -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
∈ -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
predicted -X- _ O
logit -X- _ O
indicates -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
x -X- _ O
being -X- _ O
factually -X- _ O
consistent. -X- _ O
Another -X- _ O
advantage -X- _ O
of -X- _ O
using -X- _ O
the -X- _ O
entailment-based -X- _ O
framework -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
time -X- _ O
complexity -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
methods -X- _ O
( -X- _ O
Laban -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Taking -X- _ O
f -X- _ O
θ -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
metric -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
to -X- _ O
train -X- _ O
f -X- _ O
θ -X- _ O
into -X- _ O
an -X- _ O
efficient -X- _ O
factual -X- _ O
consistency -X- _ O
metric -X- _ O
. -X- _ O

Weakly -X- _ O
Supervised -X- _ O
Training -X- _ O
In -X- _ O
our -X- _ O
weakly -X- _ O
supervised -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
bootstrap -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
sam-ples -X- _ O
from -X- _ O
the -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
e.g. -X- _ O
text -X- _ O
summarization -X- _ O
, -X- _ O
and -X- _ O
dialogue -X- _ O
generation. -X- _ O
Using -X- _ O
various -X- _ O
factual -X- _ O
metrics -X- _ O
trained -X- _ O
from -X- _ O
multiple -X- _ O
resources -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
each -X- _ O
sample -X- _ O
x -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
weak -X- _ O
signals -X- _ O
λ -X- _ O
= -X- _ O
( -X- _ O
λ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
λ -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
λ -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
logit -X- _ O
separately -X- _ O
calculated -X- _ O
by -X- _ O
a -X- _ O
metric. -X- _ O
We -X- _ O
treat -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
label -X- _ O
y -X- _ O
of -X- _ O
x -X- _ O
as -X- _ O
a -X- _ O
hidden -X- _ O
variable -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
estimated -X- _ O
by -X- _ O
aggregating -X- _ O
λ. -X- _ O
To -X- _ O
reach -X- _ O
this -X- _ O
goal -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
labeling -X- _ O
model -X- _ O
p -X- _ O
ϕ -X- _ O
to -X- _ O
model -X- _ O
agreements -X- _ O
and -X- _ O
disagreements -X- _ O
relations -X- _ O
between -X- _ O
weak -X- _ O
signals -X- _ O
in -X- _ O
λ -X- _ O
and -X- _ O
estimate -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
truth -X- _ O
label -X- _ O
, -X- _ O
p -X- _ O
ϕ -X- _ O
( -X- _ O
y|λ -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
p -X- _ O
ϕ -X- _ O
( -X- _ O
y|λ -X- _ O
) -X- _ O
to -X- _ O
supervise -X- _ O
the -X- _ O
metric -X- _ O
model -X- _ O
f -X- _ O
θ -X- _ O
. -X- _ O

Weak -X- _ O
Annotation -X- _ O
To -X- _ O
provide -X- _ O
weak -X- _ O
supervision -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
data -X- _ O
programming -X- _ O
, -X- _ O
a -X- _ O
weakly -X- _ O
supervised -X- _ O
learning -X- _ O
paradigm -X- _ O
based -X- _ O
on -X- _ O
modeling -X- _ O
multiple -X- _ O
label -X- _ O
sources. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
data -X- _ O
programming -X- _ O
, -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
are -X- _ O
often -X- _ O
produced -X- _ O
by -X- _ O
various -X- _ O
checking -X- _ O
clauses -X- _ O
, -X- _ O
e.g. -X- _ O
whether -X- _ O
word -X- _ O
" -X- _ O
causes -X- _ O
" -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
? -X- _ O
and -X- _ O
produce -X- _ O
a -X- _ O
discrete -X- _ O
weak -X- _ O
signal -X- _ O
λ -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
, -X- _ O
−1 -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
0 -X- _ O
/ -X- _ O
1 -X- _ O
stands -X- _ O
for -X- _ O
a -X- _ O
vote -X- _ O
for -X- _ O
positive -X- _ O
/ -X- _ O
negative -X- _ O
label -X- _ O
and -X- _ O
−1 -X- _ O
stands -X- _ O
for -X- _ O
a -X- _ O
abstain -X- _ O
vote. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
scenario -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
metric -X- _ O
frameworks -X- _ O
, -X- _ O
outputs -X- _ O
of -X- _ O
different -X- _ O
metrics -X- _ O
often -X- _ O
do -X- _ O
not -X- _ O
share -X- _ O
a -X- _ O
unified -X- _ O
output -X- _ O
format -X- _ O
and -X- _ O
are -X- _ O
usually -X- _ O
continuous. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
QA-based -X- _ B-TaskName
metrics -X- _ O
often -X- _ O
produce -X- _ O
continuous -X- _ O
logits -X- _ O
in -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
NLI-based -X- _ B-TaskName
metrics -X- _ O
often -X- _ O
produce -X- _ O
discrete -X- _ O
labels -X- _ O
of -X- _ O
entailment -X- _ O
or -X- _ O
contradiction. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
before -X- _ O
training -X- _ O
the -X- _ O
labeling -X- _ O
model -X- _ O
is -X- _ O
to -X- _ O
unify -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
by -X- _ O
a -X- _ O
mapping -X- _ O
function -X- _ O
, -X- _ O
m -X- _ O
( -X- _ O
λ -X- _ O
i -X- _ O
) -X- _ O
→ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
, -X- _ O
−1 -X- _ O
} -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
transformed -X- _ O
λ -X- _ O
by -X- _ O
a -X- _ O
data -X- _ O
programming -X- _ O
based -X- _ O
labeling -X- _ O
model -X- _ O
. -X- _ O

Weak -X- _ O
Signal -X- _ O
Unification -X- _ O
We -X- _ O
first -X- _ O
unify -X- _ O
all -X- _ O
the -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
from -X- _ O
different -X- _ O
metrics -X- _ O
into -X- _ O
the -X- _ O
same -X- _ O
format -X- _ O
, -X- _ O
a -X- _ O
logit -X- _ O
λ -X- _ O
i -X- _ O
∈ -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
metric -X- _ O
with -X- _ O
single -X- _ O
logit -X- _ O
output -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
use -X- _ O
its -X- _ O
output -X- _ O
as -X- _ O
λ -X- _ O
i -X- _ O
. -X- _ O
For -X- _ O
multi-label -X- _ O
classification -X- _ O
output -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
predicting -X- _ O
entailment. -X- _ O
Notice -X- _ O
that -X- _ O
all -X- _ O
the -X- _ O
signals -X- _ O
predicted -X- _ O
by -X- _ O
imperfect -X- _ O
metrics -X- _ O
will -X- _ O
introduce -X- _ O
a -X- _ O
portion -X- _ O
of -X- _ O
noises. -X- _ O
For -X- _ O
a -X- _ O
more -X- _ O
reliable -X- _ O
signal -X- _ O
, -X- _ O
the -X- _ O
core -X- _ O
idea -X- _ O
for -X- _ O
designing -X- _ O
a -X- _ O
mapping -X- _ O
function -X- _ O
m -X- _ O
is -X- _ O
to -X- _ O
map -X- _ O
signals -X- _ O
that -X- _ O
the -X- _ O
metric -X- _ O
has -X- _ O
high -X- _ O
confidence -X- _ O
into -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
and -X- _ O
abstain -X- _ O
low-confidence -X- _ O
signals -X- _ O
by -X- _ O
mapping -X- _ O
them -X- _ O
to -X- _ O
−1 -X- _ O
. -X- _ O

Generally -X- _ O
, -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
setting -X- _ O
thresholds -X- _ O
on -X- _ O
signals. -X- _ O
But -X- _ O
another -X- _ O
important -X- _ O
issue -X- _ O
to -X- _ O
be -X- _ O
noticed -X- _ O
is -X- _ O
that -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
signal -X- _ O
distributions -X- _ O
vary -X- _ O
significantly -X- _ O
across -X- _ O
metrics -X- _ O
and -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
threshold -X- _ O
selection -X- _ O
difficult. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
instead -X- _ O
dynamically -X- _ O
determine -X- _ O
thresholds -X- _ O
by -X- _ O
setting -X- _ O
constant -X- _ O
probability -X- _ O
mass -X- _ O
that -X- _ O
contains -X- _ O
the -X- _ O
highest -X- _ O
confidence. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
to -X- _ O
map -X- _ O
the -X- _ O
lowest -X- _ O
p -X- _ B-HyperparameterName
− -X- _ I-HyperparameterName
percent -X- _ O
and -X- _ O
the -X- _ O
highest -X- _ O
p -X- _ B-HyperparameterName
+ -X- _ I-HyperparameterName
percent -X- _ O
of -X- _ O
signal -X- _ O
scores -X- _ O
into -X- _ O
label -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
, -X- _ O
separately -X- _ O
, -X- _ O
and -X- _ O
map -X- _ O
the -X- _ O
rest -X- _ O
interval -X- _ O
of -X- _ O
low-confident -X- _ O
scores -X- _ O
into -X- _ O
-1. -X- _ O
Given -X- _ O
the -X- _ O
inverse -X- _ O
cumulative -X- _ O
distribution -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
i-th -X- _ O
signal -X- _ O
F -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
calculate -X- _ O
its -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
threshold -X- _ O
γ -X- _ O
+ -X- _ O
i -X- _ O
and -X- _ O
γ -X- _ O
− -X- _ O
i -X- _ O
by -X- _ O
: -X- _ O

For -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
share -X- _ O
p -X- _ B-HyperparameterName
− -X- _ I-HyperparameterName
and -X- _ O
p -X- _ B-HyperparameterName
+ -X- _ I-HyperparameterName
across -X- _ O
different -X- _ O
resources -X- _ O
and -X- _ O
datasets. -X- _ O
By -X- _ O
applying -X- _ O
the -X- _ O
mapping -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
unify -X- _ O
each -X- _ O
λ -X- _ O
i -X- _ O
into -X- _ O
a -X- _ O
discrete -X- _ O
label -X- _ O
in -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
, -X- _ O
−1 -X- _ O
} -X- _ O
. -X- _ O

where -X- _ O
α -X- _ B-HyperparameterName
i -X- _ I-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
i -X- _ I-HyperparameterName
are -X- _ O
learnable -X- _ O
hyper-parameters. -X- _ O
Given -X- _ O
all -X- _ O
samples -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
labeling -X- _ O
model -X- _ O
by -X- _ O
optimizing -X- _ O
: -X- _ O

2.3 -X- _ O
Noise -X- _ O
Aware -X- _ O
Fine-tuning -X- _ O
NLI -X- _ O
Warmup -X- _ O
After -X- _ O
we -X- _ O
get -X- _ O
the -X- _ O
labeling -X- _ O
model -X- _ O
p -X- _ O
ϕ -X- _ O
, -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
metric -X- _ O
model -X- _ O
f -X- _ O
θ -X- _ O
with -X- _ O
the -X- _ O
weak -X- _ O
supervision -X- _ O
inferred -X- _ O
by -X- _ O
it. -X- _ O
But -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
direct -X- _ O
training -X- _ O
with -X- _ O
weak -X- _ O
supervision -X- _ O
will -X- _ O
cause -X- _ O
the -X- _ O
model -X- _ O
easily -X- _ O
converges -X- _ O
to -X- _ O
the -X- _ O
local -X- _ O
minima. -X- _ O
This -X- _ O
may -X- _ O
because -X- _ O
reasoning -X- _ O
over -X- _ O
a -X- _ O
long -X- _ O
range -X- _ O
of -X- _ O
context -X- _ O
is -X- _ O
challenging -X- _ O
and -X- _ O
weak -X- _ O
supervisions -X- _ O
are -X- _ O
also -X- _ O
potential -X- _ O
to -X- _ O
be -X- _ O
noisy. -X- _ O
These -X- _ O
problems -X- _ O
cause -X- _ O
great -X- _ O
difficulties -X- _ O
in -X- _ O
optimization. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
curriculum -X- _ O
learning -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
warmup -X- _ O
our -X- _ O
metric -X- _ O
model -X- _ O
on -X- _ O
NLI -X- _ B-TaskName
, -X- _ O
an -X- _ O
easier -X- _ O
and -X- _ O
closely -X- _ O
related -X- _ O
task. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
mixture -X- _ O
of -X- _ O
four -X- _ O
NLI -X- _ B-TaskName
datasets -X- _ O
, -X- _ O
MultiNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Fever-NLI -X- _ B-DatasetName
( -X- _ O
Thorne -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
LingNLI -X- _ B-DatasetName
( -X- _ O
Parrish -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Adversarial-NLI -X- _ B-DatasetName
( -X- _ O
Nie -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
warmed-up -X- _ O
checkpoint -X- _ O
, -X- _ O
our -X- _ O
metric -X- _ O
model -X- _ O
achieves -X- _ O
much -X- _ O
better -X- _ O
results -X- _ O
under -X- _ O
weak -X- _ O
supervision -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
later -X- _ O
show -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Experimental -X- _ O
Settings -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
of -X- _ O
WeCheck -X- _ B-MethodName
including -X- _ O
the -X- _ O
evaluation -X- _ O
benchmark -X- _ O
, -X- _ O
baseline -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
implementation -X- _ O
details -X- _ O
. -X- _ O

TRUE -X- _ B-MetricName
Benchmark -X- _ O
Recent -X- _ O
works -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
metric -X- _ O
should -X- _ O
be -X- _ O
evaluated -X- _ O
comprehensively -X- _ O
across -X- _ O
multiple -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
to -X- _ O
reduce -X- _ O
variance. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
WeCheck -X- _ B-MethodName
on -X- _ O
TRUE -X- _ B-MetricName
( -X- _ O
Honovich -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
benchmark -X- _ O
consisting -X- _ O
of -X- _ O
11 -X- _ O
datasets -X- _ O
of -X- _ O
4 -X- _ O
tasks -X- _ O
including -X- _ O
text -X- _ O
summarization -X- _ O
, -X- _ O
dialogue -X- _ O
generation -X- _ O
, -X- _ O
paraphrasing -X- _ O
, -X- _ O
and -X- _ O
fact -X- _ O
checking -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
sample -X- _ O
in -X- _ O
datasets -X- _ O
is -X- _ O
annotated -X- _ O
with -X- _ O
a -X- _ O
binary -X- _ O
label -X- _ O
manually. -X- _ O
We -X- _ O
only -X- _ O
test -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
three -X- _ O
tasks -X- _ O
as -X- _ O
fact -X- _ O
checking -X- _ O
is -X- _ O
beyond -X- _ O
our -X- _ O
scope. -X- _ O
Following -X- _ O
TRUE -X- _ B-MetricName
, -X- _ O
we -X- _ O
normalize -X- _ O
each -X- _ O
metric -X- _ O
score -X- _ O
into -X- _ O
a -X- _ O
logit -X- _ O
and -X- _ O
report -X- _ O
their -X- _ O
Characteristic -X- _ B-MetricName
Area -X- _ I-MetricName
Under -X- _ I-MetricName
the -X- _ I-MetricName
Curve -X- _ I-MetricName
( -X- _ O
ROC -X- _ B-MetricName
AUC -X- _ I-MetricName
) -X- _ O
w.r.t -X- _ O
binary -X- _ O
logits. -X- _ O
Evaluation -X- _ O
with -X- _ O
ROC -X- _ B-MetricName
AUC -X- _ I-MetricName
does -X- _ O
not -X- _ O
require -X- _ O
metrics -X- _ O
to -X- _ O
set -X- _ O
specific -X- _ O
decision -X- _ O
thresholds. -X- _ O
Details -X- _ O
of -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
of -X- _ O
TRUE -X- _ B-MetricName
are -X- _ O
introduce -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Baseline -X- _ O
We -X- _ O
evaluate -X- _ O
WeCheck -X- _ B-MethodName
by -X- _ O
comparing -X- _ O
with -X- _ O
recently -X- _ O
proposed -X- _ O
metrics. -X- _ O
We -X- _ O
categorize -X- _ O
these -X- _ O
baselines -X- _ O
by -X- _ O
types -X- _ O
of -X- _ O
their -X- _ O
methods. -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
BERT-based -X- _ B-MetricName
metric -X- _ O
with -X- _ O
synthetic -X- _ O
training -X- _ O
samples -X- _ O
constructed -X- _ O
from -X- _ O
rule-based -X- _ O
data -X- _ O
augmentation. -X- _ O
SUMMAC -X- _ B-MethodName
( -X- _ O
SCZS -X- _ B-MethodName
) -X- _ O
( -X- _ O
Laban -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
aggregates -X- _ O
sentence-level -X- _ O
entailment -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
final -X- _ O
factual -X- _ O
consistency -X- _ O
score. -X- _ O
We -X- _ O
only -X- _ O
report -X- _ O
the -X- _ O
zero-shot -X- _ O
version -X- _ O
SCZS -X- _ B-MethodName
instead -X- _ O
of -X- _ O
the -X- _ O
supervised -X- _ O
version -X- _ O
SCCONV -X- _ B-MethodName
because -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
on -X- _ O
the -X- _ O
TRUE -X- _ B-MetricName
benchmark. -X- _ O
ANLI -X- _ O
( -X- _ O
Honovich -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
directly -X- _ O
apply -X- _ O
a -X- _ O
large -X- _ O
11B -X- _ O
T5 -X- _ O
trained -X- _ O
on -X- _ O
Adversarial-NLI -X- _ B-DatasetName
( -X- _ O
Nie -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
dataset -X- _ O
for -X- _ O
fact -X- _ O
checking -X- _ O
and -X- _ O
achieve -X- _ O
SOTA -X- _ O
performance -X- _ O
on -X- _ O
TRUE -X- _ B-MetricName
. -X- _ O

NLI-based -X- _ O
Metrics -X- _ O
FactCC -X- _ O
QA-QG -X- _ O
based -X- _ O
Metrics -X- _ O
QuestEval -X- _ B-MetricName
( -X- _ O
Scialom -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
QA-QG -X- _ B-MetricName
based -X- _ O
metric -X- _ O
that -X- _ O
jointly -X- _ O
measures -X- _ O
factual -X- _ O
consistency -X- _ O
and -X- _ O
semantic -X- _ O
relevance -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
generated -X- _ O
questions -X- _ O
are -X- _ O
weighted -X- _ O
by -X- _ O
a -X- _ O
trained -X- _ O
model. -X- _ O
QAFactEval -X- _ B-MetricName
( -X- _ O
QAFact -X- _ B-MetricName
) -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
metric -X- _ O
designed -X- _ O
by -X- _ O
carefully -X- _ O
optimizing -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
QG-QA -X- _ B-MetricName
framework. -X- _ O
Q -X- _ O
2 -X- _ O
, -X- _ O
from -X- _ O
the -X- _ O
version -X- _ O
of -X- _ O
Honovich -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
replace -X- _ O
all -X- _ O
the -X- _ O
component -X- _ O
of -X- _ O
QA-QG -X- _ B-MetricName
framework -X- _ O
into -X- _ O
T5 -X- _ O
11B -X- _ O
large -X- _ O
models -X- _ O
. -X- _ O

Other -X- _ O
Types -X- _ O
BERTScore -X- _ B-MetricName
( -X- _ O
BERTS -X- _ O
) -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
measure -X- _ O
the -X- _ O
similarity -X- _ O
of -X- _ O
a -X- _ O
generated -X- _ O
text -X- _ O
and -X- _ O
its -X- _ O
reference -X- _ O
by -X- _ O
aggregating -X- _ O
tokenlevel -X- _ O
similarities -X- _ O
of -X- _ O
their -X- _ O
contextual -X- _ O
representations. -X- _ O
BARTScore -X- _ B-MetricName
( -X- _ O
BARTS -X- _ O
) -X- _ O
( -X- _ O
Yuan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
text -X- _ O
by -X- _ O
its -X- _ O
modeling -X- _ O
perplexity -X- _ O
of -X- _ O
a -X- _ O
fine-tuned -X- _ O
BART -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O
All -X- _ O
the -X- _ O
baseline -X- _ O
metrics -X- _ O
are -X- _ O
tested -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
open-sourced -X- _ O
codes. -X- _ O
The -X- _ O
metric -X- _ O
model -X- _ O
of -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
powerful -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
DeBERTaV3 -X- _ B-MethodName
( -X- _ O
He -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
description -X- _ O
in -X- _ O
§ -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
warm -X- _ O
up -X- _ O
DeBERTaV3 -X- _ B-MethodName
on -X- _ O
NLI -X- _ B-TaskName
datasets -X- _ O
and -X- _ O
apply -X- _ O
it -X- _ O
for -X- _ O
weak -X- _ O
supervised -X- _ O
training. -X- _ O
As -X- _ O
regards -X- _ O
to -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
text -X- _ O
summarization -X- _ O
examples -X- _ O
from -X- _ O
BART -X- _ B-MethodName
fine-tuned -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
and -X- _ O
XSum -X- _ B-DatasetName
datasets. -X- _ O
We -X- _ O
sample -X- _ O
dialogue -X- _ O
generation -X- _ O
examples -X- _ O
from -X- _ O
Mem-Net -X- _ B-DatasetName
and -X- _ O
dodecaDialogue -X- _ B-DatasetName
( -X- _ O
Shuster -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
WoW -X- _ B-DatasetName
dataset -X- _ O
following -X- _ O
Honovich -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
paraphrase -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
use -X- _ O
samples -X- _ O
in -X- _ O
PAWS -X- _ B-DatasetName
since -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
regard -X- _ O
as -X- _ O
a -X- _ O
consistency -X- _ O
checking -X- _ O
dataset -X- _ O
itself. -X- _ O
For -X- _ O
weak -X- _ O
signals -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
QAFact -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
SUMMAC -X- _ O
( -X- _ O
Laban -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NLI -X- _ O
warmed -X- _ O
up -X- _ O
DeBERTaV3 -X- _ B-MethodName
( -X- _ O
NLI-warmup -X- _ B-TaskName
) -X- _ O
as -X- _ O
to -X- _ O
provide -X- _ O
weak -X- _ O
signals -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
as -X- _ O
default. -X- _ O
For -X- _ O
weak -X- _ O
signal -X- _ O
unification -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
p -X- _ O
+ -X- _ O
and -X- _ O
p -X- _ O
− -X- _ O
in -X- _ O
mapping -X- _ O
function -X- _ O
m -X- _ O
to -X- _ O
0.75 -X- _ O
and -X- _ O
0.25 -X- _ O
based -X- _ O
on -X- _ O
validation. -X- _ O
For -X- _ O
labeling -X- _ O
model -X- _ O
p -X- _ O
ϕ -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
Snorkel -X- _ O
for -X- _ O
efficiency -X- _ O
and -X- _ O
train -X- _ O
it -X- _ O
on -X- _ O
CPUs -X- _ O
with -X- _ O
Adam -X- _ O
optimizer. -X- _ O
For -X- _ O
noise-aware -X- _ O
fine-tuning -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
warmed -X- _ O
up -X- _ O
checkpoint -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e -X- _ B-HyperparameterValue
−6 -X- _ I-HyperparameterValue
, -X- _ O
warmup -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
of -X- _ O
500 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
total -X- _ O
training -X- _ O
steps -X- _ B-HyperparameterName
of -X- _ O
3 -X- _ B-MetricName
epoch. -X- _ O
We -X- _ O
train -X- _ O
on -X- _ O
4 -X- _ O
NVIDIA -X- _ O
Tesla -X- _ O
V100 -X- _ O
GPUs -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
takes -X- _ O
around -X- _ O
only -X- _ O
5000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
to -X- _ O
reach -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O

Results -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
TRUE -X- _ B-MetricName
are -X- _ O
reported -X- _ O
in -X- _ O
and -X- _ O
closely -X- _ O
related -X- _ O
task -X- _ O
, -X- _ O
provides -X- _ O
a -X- _ O
much -X- _ O
better -X- _ O
initialization -X- _ O
for -X- _ O
training -X- _ O
with -X- _ O
weak -X- _ O
supervision. -X- _ O
For -X- _ O
noise-aware -X- _ O
finetuning -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
how -X- _ O
filtering -X- _ O
potential -X- _ O
noisy -X- _ O
samples -X- _ O
( -X- _ O
Eq. -X- _ O
7 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
probabilistic -X- _ O
label -X- _ O
( -X- _ O
Eq. -X- _ O
6 -X- _ O
) -X- _ O
affect -X- _ O
the -X- _ O
overall -X- _ O
performance. -X- _ O
After -X- _ O
removing -X- _ O
noise -X- _ O
filtering -X- _ O
( -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
Noise -X- _ O
Filter -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
around -X- _ O
1-2 -X- _ O
points -X- _ O
in -X- _ O
each -X- _ O
task -X- _ O
and -X- _ O
dataset -X- _ O
in -X- _ O
average. -X- _ O
By -X- _ O
replacing -X- _ O
the -X- _ O
probabilistic -X- _ O
labels -X- _ O
into -X- _ O
hard -X- _ O
labels -X- _ O
( -X- _ O
w -X- _ O
/ -X- _ O
Hard -X- _ O
Label -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
around -X- _ O
0.1-0.2 -X- _ O
drops -X- _ O
in -X- _ O
performance. -X- _ O
This -X- _ O
implies -X- _ O
how -X- _ O
to -X- _ O
filter -X- _ O
potential -X- _ O
noisy -X- _ O
samples -X- _ O
is -X- _ O
crucial -X- _ O
in -X- _ O
noise -X- _ O
aware -X- _ O
fine-tuning -X- _ O
, -X- _ O
and -X- _ O
probabilistic -X- _ O
labels -X- _ O
also -X- _ O
slightly -X- _ O
help -X- _ O
. -X- _ O

Effects -X- _ O
of -X- _ O
Task -X- _ O
We -X- _ O
also -X- _ O
analyse -X- _ O
how -X- _ O
each -X- _ O
bootstrapped -X- _ O
task -X- _ O
affect -X- _ O
WeCheck. -X- _ B-MethodName
In -X- _ O
1 -X- _ O
) -X- _ O
is -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
others. -X- _ O
Among -X- _ O
the -X- _ O
rest -X- _ O
two -X- _ O
methods -X- _ O
with -X- _ O
comparable -X- _ O
performance -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
2.9 -X- _ O
times -X- _ O
faster -X- _ O
than -X- _ O
SCZS -X- _ B-MethodName
and -X- _ O
30 -X- _ O
times -X- _ O
faster -X- _ O
than -X- _ O
QAFact -X- _ B-MethodName
. -X- _ O

Abstractiveness -X- _ O
As -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
abstractive -X- _ O
hypotheses -X- _ O
are -X- _ O
challenging -X- _ O
for -X- _ O
current -X- _ O
metrics -X- _ O
, -X- _ O
e.g. -X- _ O
XSUM -X- _ B-DatasetName
summaries -X- _ O
from -X- _ O
MNBM. -X- _ B-DatasetName
We -X- _ O
give -X- _ O
an -X- _ O
in-depth -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
hypothesis -X- _ O
abstractiveness -X- _ O
on -X- _ O
the -X- _ O
metrics -X- _ O
performance -X- _ O
. -X- _ O

Following -X- _ O
See -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
unique -X- _ O
unigrams -X- _ O
in -X- _ O
a -X- _ O
hypothesis -X- _ O
w.r.t -X- _ O
its -X- _ O
premise -X- _ O
to -X- _ O
measure -X- _ O
abstractivenss. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
spilt -X- _ O
all -X- _ O
the -X- _ O
examples -X- _ O
in -X- _ O
TRUE -X- _ O
into -X- _ O
10 -X- _ O
bins -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
abstractiveness. -X- _ O
For -X- _ O
each -X- _ O
bin -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
ROC -X- _ B-DatasetName
AUC -X- _ I-DatasetName
of -X- _ O
WeCheck -X- _ B-MethodName
and -X- _ O
the -X- _ O
other -X- _ O
three -X- _ O
representative -X- _ O
baselines -X- _ O
: -X- _ O
QAFact -X- _ B-MethodName
, -X- _ O
Summac -X- _ B-MethodName
, -X- _ O
and -X- _ O
NLI-warmup. -X- _ B-MethodName
From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
significant -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
performance -X- _ O
for -X- _ O
all -X- _ O
baselines -X- _ O
as -X- _ O
the -X- _ O
hypothesis -X- _ O
becomes -X- _ O
more -X- _ O
abstractive -X- _ O
, -X- _ O
while -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
keeps -X- _ O
its -X- _ O
performance -X- _ O
( -X- _ O
around -X- _ O
0.85 -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
baseline -X- _ O
metrics -X- _ O
in -X- _ O
every -X- _ O
bin -X- _ O
of -X- _ O
ab- -X- _ O
stractiveness. -X- _ O
This -X- _ O
further -X- _ O
verifies -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
directly -X- _ O
training -X- _ O
with -X- _ O
real -X- _ O
task -X- _ O
data -X- _ O
. -X- _ O

Labeling -X- _ O
Model -X- _ O
We -X- _ O
compare -X- _ O
how -X- _ O
different -X- _ O
data -X- _ O
programming -X- _ O
based -X- _ O
labeling -X- _ O
models -X- _ O
affect -X- _ O
the -X- _ O
final -X- _ O
metric -X- _ O
performance -X- _ O
. -X- _ O

In -X- _ O
WeCheck -X- _ O
, -X- _ O
labeling -X- _ O
model -X- _ O
p -X- _ O
ϕ -X- _ O
learns -X- _ O
to -X- _ O
aggregate -X- _ O
multi-resource -X- _ O
labels -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
hidden -X- _ O
true -X- _ O
label. -X- _ O
Comparing -X- _ O
concretely -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
Snorkel -X- _ O
. -X- _ O
Because -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
is -X- _ O
small -X- _ O
and -X- _ O
their -X- _ O
relationships -X- _ O
are -X- _ O
relatively -X- _ O
simple -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
trained -X- _ O
from -X- _ O
different -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
prefer -X- _ O
this -X- _ O
method -X- _ O
over -X- _ O
other -X- _ O
recent -X- _ O
more -X- _ O
advanced -X- _ O
ones -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
labeling -X- _ O
model -X- _ O
by -X- _ O
replacing -X- _ O
it -X- _ O
with -X- _ O
other -X- _ O
methods. -X- _ O
In -X- _ O
these -X- _ O
baselines -X- _ O
, -X- _ O
simpler -X- _ O
methods -X- _ O
include -X- _ O
: -X- _ O
Average -X- _ O
Signals -X- _ O
, -X- _ O
which -X- _ O
simply -X- _ O
averages -X- _ O
all -X- _ O
the -X- _ O
weak -X- _ O
signals -X- _ O
as -X- _ O
the -X- _ O
probabilistic -X- _ O
label -X- _ O
p -X- _ O
( -X- _ O
y -X- _ O
+ -X- _ O
) -X- _ O
; -X- _ O
Major -X- _ O
Vote -X- _ O
, -X- _ O
which -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
frequently -X- _ O
appeared -X- _ O
label -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
weak -X- _ O
signal -X- _ O
set -X- _ O
as -X- _ O
the -X- _ O
true -X- _ O
label. -X- _ O
More -X- _ O
advanced -X- _ O
methods -X- _ O
include -X- _ O
: -X- _ O
Flying -X- _ O
Squid -X- _ O
( -X- _ O
Fu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
applies -X- _ O
an -X- _ O
Ising -X- _ O
model -X- _ O
( -X- _ O
Parsons -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
as -X- _ O
the -X- _ O
labeling -X- _ O
method -X- _ O
and -X- _ O
trains -X- _ O
it -X- _ O
end-to-end -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
tasks -X- _ O
model -X- _ O
; -X- _ O
DWS -X- _ O
( -X- _ O
Parker -X- _ O
and -X- _ O
Yu -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
treats -X- _ O
the -X- _ O
true -X- _ O
label -X- _ O
of -X- _ O
a -X- _ O
sample -X- _ O
as -X- _ O
the -X- _ O
hidden -X- _ O
variable -X- _ O
and -X- _ O
applies -X- _ O
Estimation-Maximization -X- _ O
( -X- _ O
EM -X- _ O
) -X- _ O
for -X- _ O
inference -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
our -X- _ O
default -X- _ O
labeling -X- _ O
model -X- _ O
outperforms -X- _ O
all -X- _ O
others. -X- _ O
Furthermore -X- _ O
, -X- _ O
more -X- _ O
complex -X- _ O
methods -X- _ O
( -X- _ O
Flying -X- _ O
Squid -X- _ O
, -X- _ O
Weasel -X- _ O
, -X- _ O
and -X- _ O
EM -X- _ O
) -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
simpler -X- _ O
methods -X- _ O
( -X- _ O
Ours -X- _ O
, -X- _ O
Average -X- _ O
Signal -X- _ O
, -X- _ O
and -X- _ O
Major -X- _ O
Vote -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
further -X- _ O
verifies -X- _ O
that -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
weak -X- _ O
signals -X- _ O
are -X- _ O
simple -X- _ O
, -X- _ O
and -X- _ O
complex -X- _ O
modeling -X- _ O
will -X- _ O
not -X- _ O
bring -X- _ O
further -X- _ O
improvements. -X- _ O
From -X- _ O
another -X- _ O
perspective -X- _ O
, -X- _ O
overly -X- _ O
simplistic -X- _ O
approaches -X- _ O
without -X- _ O
any -X- _ O
statistical -X- _ O
modeling -X- _ O
( -X- _ O
Average -X- _ O
Signal -X- _ O
and -X- _ O
Major -X- _ O
Vote -X- _ O
) -X- _ O
also -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
our -X- _ O
methods -X- _ O
. -X- _ O

Related -X- _ O
Work -X- _ O
Factual -X- _ O
Consistency -X- _ O
Evaluation -X- _ O
Recently -X- _ O
, -X- _ O
automatically -X- _ O
checking -X- _ O
factual -X- _ O
consistency -X- _ O
has -X- _ O
become -X- _ O
an -X- _ O
increasingly -X- _ O
popular -X- _ O
topic -X- _ O
. -X- _ O
Reasoning -X- _ O
over -X- _ O
a -X- _ O
long -X- _ O
range -X- _ O
of -X- _ O
context -X- _ O
for -X- _ O
factual -X- _ O
evaluation -X- _ O
is -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
that -X- _ O
even -X- _ O
human -X- _ O
annotators -X- _ O
may -X- _ O
frequently -X- _ O
disagree -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
collect -X- _ O
a -X- _ O
large-scale -X- _ O
high-quality -X- _ O
dataset -X- _ O
for -X- _ O
training -X- _ O
a -X- _ O
fully -X- _ O
supervised -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
previous -X- _ O
works -X- _ O
search -X- _ O
for -X- _ O
indirect -X- _ O
methods. -X- _ O
One -X- _ O
branch -X- _ O
of -X- _ O
them -X- _ O
leverage -X- _ O
the -X- _ O
reasoning -X- _ O
ability -X- _ O
of -X- _ O
NLI. -X- _ B-TaskName
Based -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
NLI -X- _ B-TaskName
datasets -X- _ O
, -X- _ O
e.g. -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
ANLI -X- _ B-DatasetName
( -X- _ O
Nie -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
some -X- _ O
works -X- _ O
aggregate -X- _ O
sentence-level -X- _ O
entailment -X- _ O
score -X- _ O
for -X- _ O
checking -X- _ O
( -X- _ O
Falke -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Laban -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
others -X- _ O
adopt -X- _ O
document-level -X- _ O
NLI -X- _ B-MetricName
which -X- _ O
directly -X- _ O
reasoning -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
context -X- _ O
( -X- _ O
Maynez -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gehrmann -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
branch -X- _ O
of -X- _ O
methods -X- _ O
apply -X- _ O
QA-QG -X- _ B-MetricName
based -X- _ O
pipeline -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
fine-grained -X- _ O
checking. -X- _ O
QAGS -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
FEQA -X- _ O
( -X- _ O
Durmus -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
earliest -X- _ O
attempt -X- _ O
on -X- _ O
this -X- _ O
method -X- _ O
, -X- _ O
and -X- _ O
QuestEval -X- _ O
( -X- _ O
Scialom -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
QAFactEval -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
further -X- _ O
improve -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
methods -X- _ O
by -X- _ O
applying -X- _ O
NLI -X- _ B-TaskName
for -X- _ O
answer -X- _ O
matching. -X- _ O
Data -X- _ O
Programming -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
mainly -X- _ O
focus -X- _ O
on -X- _ O
data -X- _ O
programming -X- _ O
( -X- _ O
Ratner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
( -X- _ O
DP -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
weak -X- _ O
supervision -X- _ O
paradigm -X- _ O
proposed -X- _ O
to -X- _ O
infer -X- _ O
correct -X- _ O
labels -X- _ O
based -X- _ O
on -X- _ O
noisy -X- _ O
labels -X- _ O
from -X- _ O
labeling -X- _ O
functions -X- _ O
( -X- _ O
LFs -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
rule-based -X- _ O
decision-making -X- _ O
processes -X- _ O
that -X- _ O
generate -X- _ O
discrete -X- _ O
labels. -X- _ O
Following -X- _ O
the -X- _ O
DP -X- _ O
paradigm -X- _ O
, -X- _ O
Snorkel -X- _ O
is -X- _ O
proposed -X- _ O
to -X- _ O
for -X- _ O
rapid -X- _ O
training -X- _ O
, -X- _ O
more -X- _ O
recent -X- _ O
works -X- _ O
study -X- _ O
how -X- _ O
to -X- _ O
adapt -X- _ O
label -X- _ O
model -X- _ O
in -X- _ O
DP -X- _ O
( -X- _ O
Ratner -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Awasthi -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
modeling -X- _ O
more -X- _ O
complex -X- _ O
structure -X- _ O
between -X- _ O
LFs -X- _ O
( -X- _ O
Fu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
DP -X- _ O
is -X- _ O
also -X- _ O
applied -X- _ O
to -X- _ O
several -X- _ O
NLP -X- _ O
tasks. -X- _ O
DWS -X- _ O
( -X- _ O
Parker -X- _ O
and -X- _ O
Yu -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
combine -X- _ O
DP -X- _ O
and -X- _ O
CRF -X- _ O
for -X- _ O
weakly -X- _ O
supervised -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
, -X- _ O
Min -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
apply -X- _ O
DP -X- _ O
for -X- _ O
QA. -X- _ B-TaskName
Different -X- _ O
from -X- _ O
all -X- _ O
previous -X- _ O
tasks -X- _ O
, -X- _ O
our -X- _ O
weak -X- _ O
supervision -X- _ O
signals -X- _ O
are -X- _ O
logits -X- _ O
from -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
discrete -X- _ O
labels -X- _ O
generated -X- _ O
from -X- _ O
rules -X- _ O
. -X- _ O

Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
weakly -X- _ O
supervised -X- _ O
framework -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
, -X- _ O
which -X- _ O
aggregates -X- _ O
weakly -X- _ O
supervised -X- _ O
signals -X- _ O
from -X- _ O
multiple -X- _ O
resources -X- _ O
and -X- _ O
trains -X- _ O
a -X- _ O
target -X- _ O
metric -X- _ O
model -X- _ O
in -X- _ O
a -X- _ O
noise-aware -X- _ O
manner. -X- _ O
Different -X- _ O
from -X- _ O
previous -X- _ O
metrics -X- _ O
that -X- _ O
trains -X- _ O
from -X- _ O
synthetic -X- _ O
data -X- _ O
or -X- _ O
transferred -X- _ O
from -X- _ O
other -X- _ O
tasks -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
directly -X- _ O
trains -X- _ O
with -X- _ O
the -X- _ O
real -X- _ O
generated -X- _ O
text. -X- _ O
WeCheck -X- _ B-MethodName
first -X- _ O
annotates -X- _ O
each -X- _ O
sample -X- _ O
with -X- _ O
a -X- _ O
probabilistic -X- _ O
label -X- _ O
via -X- _ O
a -X- _ O
labeling -X- _ O
function -X- _ O
that -X- _ O
aggregates -X- _ O
multiple -X- _ O
resources. -X- _ O
Then -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
noise-aware -X- _ O
finetuning -X- _ O
stage -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
applies -X- _ O
probabilistic -X- _ O
labels -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
target -X- _ O
metric -X- _ O
model. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
not -X- _ O
only -X- _ O
surpass -X- _ O
previous -X- _ O
methods -X- _ O
in -X- _ O
performance -X- _ O
but -X- _ O
also -X- _ O
time -X- _ O
efficient. -X- _ O
Moreover -X- _ O
, -X- _ O
WeCheck -X- _ B-MethodName
is -X- _ O
potential -X- _ O
to -X- _ O
be -X- _ O
compatible -X- _ O
with -X- _ O
future -X- _ O
more -X- _ O
stronger -X- _ O
metrics -X- _ O
, -X- _ O
bring -X- _ O
further -X- _ O
improvements -X- _ O
to -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
. -X- _ O

Limitations -X- _ O
Hyper-parameters -X- _ O
Selection -X- _ O
Some -X- _ O
hyperparameters -X- _ O
still -X- _ O
acquire -X- _ O
careful -X- _ O
selection -X- _ O
for -X- _ O
WeCheck -X- _ B-MethodName
, -X- _ O
e.g. -X- _ O
p -X- _ B-HyperparameterName
+ -X- _ I-HyperparameterName
, -X- _ O
p -X- _ B-HyperparameterName
− -X- _ I-HyperparameterName
. -X- _ O
Also -X- _ O
, -X- _ O
using -X- _ O
different -X- _ O
set -X- _ O
of -X- _ O
hyper-parameters -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
will -X- _ O
further -X- _ O
boost -X- _ O
performance. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
several -X- _ O
time -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
parameters -X- _ O
based -X- _ O
on -X- _ O
validation -X- _ O
. -X- _ O

End-to-End -X- _ O
Training -X- _ O
WeCheck -X- _ B-MethodName
applies -X- _ O
the -X- _ O
weak -X- _ O
annotation -X- _ O
and -X- _ O
noise-aware -X- _ O
fine-tuning -X- _ O
twostep -X- _ O
pipeline -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
noises -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
will -X- _ O
greatly -X- _ O
affect -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
second -X- _ O
step. -X- _ O
By -X- _ O
modifying -X- _ O
the -X- _ O
overall -X- _ O
framework -X- _ O
into -X- _ O
end-toend -X- _ O
training -X- _ O
will -X- _ O
solve -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O

Why -X- _ O
Are -X- _ O
n't -X- _ O
We -X- _ O
NER -X- _ B-TaskName
Yet -X- _ O
? -X- _ O
Artifacts -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
Errors -X- _ O
in -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
in -X- _ O
Spontaneous -X- _ O
Speech -X- _ O
Transcripts -X- _ O

Transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
human -X- _ O
speech -X- _ O
present -X- _ O
a -X- _ O
significant -X- _ O
obstacle -X- _ O
for -X- _ O
traditional -X- _ O
NER -X- _ B-TaskName
models. -X- _ O
The -X- _ O
lack -X- _ O
of -X- _ O
grammatical -X- _ O
structure -X- _ O
of -X- _ O
spoken -X- _ O
utterances -X- _ O
and -X- _ O
word -X- _ O
errors -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
make -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
challenging. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
in -X- _ O
detail -X- _ O
the -X- _ O
complex -X- _ O
relationship -X- _ O
between -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
which -X- _ O
limit -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
NER -X- _ B-TaskName
models -X- _ O
to -X- _ O
recover -X- _ O
entity -X- _ O
mentions -X- _ O
from -X- _ O
spontaneous -X- _ O
speech -X- _ O
transcripts. -X- _ O
Using -X- _ O
publicly -X- _ O
available -X- _ O
benchmark -X- _ O
datasets -X- _ O
( -X- _ O
SWNE -X- _ B-DatasetName
, -X- _ O
Earnings-21 -X- _ B-DatasetName
, -X- _ O
OntoNotes -X- _ B-DatasetName
) -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
full -X- _ O
taxonomy -X- _ O
of -X- _ O
ASR-NER -X- _ B-TaskName
errors -X- _ O
and -X- _ O
measure -X- _ O
their -X- _ O
true -X- _ O
impact -X- _ O
on -X- _ O
entity -X- _ B-TaskName
recognition. -X- _ I-TaskName
We -X- _ O
find -X- _ O
that -X- _ O
NER -X- _ B-TaskName
models -X- _ O
fail -X- _ O
to -X- _ O
recognize -X- _ O
entity -X- _ O
spans -X- _ O
even -X- _ O
if -X- _ O
no -X- _ O
word -X- _ O
errors -X- _ O
are -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
ASR. -X- _ B-TaskName
We -X- _ O
also -X- _ O
show -X- _ O
why -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
is -X- _ O
inadequate -X- _ O
to -X- _ O
evaluate -X- _ O
NER -X- _ B-TaskName
models -X- _ O
on -X- _ O
conversational -X- _ O
transcripts -X- _ O
1 -X- _ O
. -X- _ O

Introduction -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
NLP -X- _ O
models -X- _ O
tends -X- _ O
to -X- _ O
deteriorate -X- _ O
significantly -X- _ O
when -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
raw -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
Automatic -X- _ B-TaskName
Speech -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
ASR -X- _ B-TaskName
) -X- _ O
system. -X- _ O
We -X- _ O
coin -X- _ O
the -X- _ O
term -X- _ O
ASR-NLP -X- _ B-TaskName
gap -X- _ O
to -X- _ O
describe -X- _ O
this -X- _ O
phenomenon. -X- _ O
Despite -X- _ O
unprecedented -X- _ O
advances -X- _ O
in -X- _ O
modern -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
transcript -X- _ O
of -X- _ O
a -X- _ O
spontaneous -X- _ O
human-human -X- _ O
conversation -X- _ O
remains -X- _ O
an -X- _ O
insurmountable -X- _ O
challenge -X- _ O
for -X- _ O
most -X- _ O
models. -X- _ O
This -X- _ O
is -X- _ O
particularly -X- _ O
true -X- _ O
for -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
struggle -X- _ O
to -X- _ O
retrieve -X- _ O
even -X- _ O
the -X- _ O
most -X- _ O
basic -X- _ O
entity -X- _ O
mentions -X- _ O
from -X- _ O
spontaneous -X- _ O
speech. -X- _ O
1 -X- _ O
All -X- _ O
code -X- _ O
necessary -X- _ O
to -X- _ O
reproduce -X- _ O
our -X- _ O
results -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
niedakh -X- _ O
/ -X- _ O
asr-ner-eval-repository -X- _ O
Three -X- _ O
primary -X- _ O
factors -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
the -X- _ O
ASR-NLP -X- _ B-TaskName
gap. -X- _ O
Firstly -X- _ O
, -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
spontaneous -X- _ O
human -X- _ O
conversations -X- _ O
is -X- _ O
diametrically -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
prescriptive -X- _ O
written -X- _ O
language -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
language -X- _ O
models. -X- _ O
These -X- _ O
models -X- _ O
can -X- _ O
use -X- _ O
the -X- _ O
grammatical -X- _ O
structure -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
corpora -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
part-of-speech -X- _ O
sequences -X- _ O
, -X- _ O
dependency -X- _ O
trees -X- _ O
, -X- _ O
and -X- _ O
dialog -X- _ O
acts. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
spontaneous -X- _ O
conversations -X- _ O
lack -X- _ O
sentence -X- _ O
structure. -X- _ O
They -X- _ O
contain -X- _ O
repetitions -X- _ O
, -X- _ O
back-channeling -X- _ O
, -X- _ O
phatic -X- _ O
expressions -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
artifacts -X- _ O
of -X- _ O
turn-taking. -X- _ O
The -X- _ O
second -X- _ O
challenge -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
containing -X- _ O
neither -X- _ O
punctuation -X- _ O
nor -X- _ O
sentence -X- _ O
segmentation. -X- _ O
These -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
restored -X- _ O
by -X- _ O
an -X- _ O
auxiliary -X- _ O
downstream -X- _ O
model. -X- _ O
Thus -X- _ O
, -X- _ O
NLP -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
prescriptive -X- _ O
written -X- _ O
text -X- _ O
or -X- _ O
scripted -X- _ O
conversations -X- _ O
already -X- _ O
have -X- _ O
to -X- _ O
process -X- _ O
the -X- _ O
out-ofdomain -X- _ O
input. -X- _ O
The -X- _ O
third -X- _ O
problem -X- _ O
stems -X- _ O
from -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
injecting -X- _ O
word -X- _ O
errors -X- _ O
into -X- _ O
the -X- _ O
transcript. -X- _ O
Due -X- _ O
to -X- _ O
efficiency -X- _ O
requirements -X- _ O
, -X- _ O
most -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
use -X- _ O
unsophisticated -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
ngram -X- _ O
models -X- _ O
with -X- _ O
limited -X- _ O
vocabulary. -X- _ O
Thus -X- _ O
, -X- _ O
many -X- _ O
utterances -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
audio -X- _ O
may -X- _ O
be -X- _ O
unrecognized -X- _ O
and -X- _ O
deleted -X- _ O
from -X- _ O
the -X- _ O
output -X- _ O
, -X- _ O
while -X- _ O
other -X- _ O
utterances -X- _ O
may -X- _ O
cause -X- _ O
substitutions -X- _ O
or -X- _ O
insertions -X- _ O
of -X- _ O
erroneous -X- _ O
tokens -X- _ O
into -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O

Consider -X- _ O
the -X- _ O
following -X- _ O
sentence -X- _ O
: -X- _ O
" -X- _ O
I -X- _ O
am -X- _ O
to -X- _ O
see -X- _ O
[ -X- _ O
Dr -X- _ O
Smith -X- _ O
] -X- _ O
PERSON -X- _ O
at -X- _ O
[ -X- _ O
9 -X- _ O
am -X- _ O
] -X- _ O
TIME -X- _ O
on -X- _ O
[ -X- _ O
Monday -X- _ O
, -X- _ O
May -X- _ O
14th -X- _ O
] -X- _ O
DATE -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
NER -X- _ B-TaskName
model -X- _ O
2 -X- _ O
correctly -X- _ O
recognizes -X- _ O
three -X- _ O
entity -X- _ O
spans -X- _ O
in -X- _ O
the -X- _ O
sentence. -X- _ O
Compare -X- _ O
this -X- _ O
to -X- _ O
the -X- _ O
NER -X- _ O
spans -X- _ O
recognized -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
far -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
: -X- _ O
" -X- _ O
I -X- _ O
am -X- _ O
to -X- _ O
see -X- _ O
doctor -X- _ O
[ -X- _ O
Smith -X- _ O
] -X- _ O
PERSON -X- _ O
at -X- _ O
nine -X- _ O
I -X- _ O
am -X- _ O
on -X- _ O
[ -X- _ O
monday -X- _ O
] -X- _ O
DATE -X- _ O
[ -X- _ O
uhm -X- _ O
] -X- _ O
ORG -X- _ O
yeah -X- _ O
[ -X- _ O
monday -X- _ O
] -X- _ O
DATE -X- _ O
may -X- _ O
for -X- _ O
teen. -X- _ O
" -X- _ O
Two -X- _ O
entity -X- _ O
spans -X- _ O
have -X- _ O
been -X- _ O
cut -X- _ O
short -X- _ O
, -X- _ O
an -X- _ O
incorrect -X- _ O
label -X- _ O
has -X- _ O
replaced -X- _ O
one -X- _ O
span -X- _ O
's -X- _ O
label -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
recognized -X- _ O
a -X- _ O
filler -X- _ O
uhm -X- _ O
as -X- _ O
the -X- _ O
entity -X- _ O
ORG -X- _ O
! -X- _ O
With -X- _ O
a -X- _ O
few -X- _ O
more -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
and -X- _ O
lowercase -X- _ O
output -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
recognize -X- _ O
a -X- _ O
single -X- _ O
entity -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
: -X- _ O
" -X- _ O
I -X- _ O
am -X- _ O
to -X- _ O
see -X- _ O
doctor -X- _ O
uhm -X- _ O
doctor -X- _ O
smith -X- _ O
at -X- _ O
nine -X- _ O
I -X- _ O
am -X- _ O
on -X- _ O
man -X- _ O
day -X- _ O
may -X- _ O
for -X- _ O
teen -X- _ O
. -X- _ O
" -X- _ O

The -X- _ O
main -X- _ O
problem -X- _ O
is -X- _ O
that -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
are -X- _ O
very -X- _ O
" -X- _ O
unnatural -X- _ O
" -X- _ O
from -X- _ O
the -X- _ O
point -X- _ O
of -X- _ O
view -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
because -X- _ O
they -X- _ O
tend -X- _ O
to -X- _ O
break -X- _ O
the -X- _ O
grammar -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
on -X- _ O
which -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
depends. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
consequential -X- _ O
errors -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
is -X- _ O
the -X- _ O
confusion -X- _ O
about -X- _ O
the -X- _ O
part-of-speech -X- _ O
tag. -X- _ O
Consider -X- _ O
possible -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
" -X- _ O
My -X- _ O
[ -X- _ O
second -X- _ O
] -X- _ O
ORDINAL -X- _ O
visit -X- _ O
is -X- _ O
[ -X- _ O
Wednesday -X- _ O
] -X- _ O
DATE -X- _ O
at -X- _ O
[ -X- _ O
half -X- _ O
past -X- _ O
one -X- _ O
] -X- _ O
TIME -X- _ O
. -X- _ O
" -X- _ O
Changing -X- _ O
the -X- _ O
personal -X- _ O
pronoun -X- _ O
" -X- _ O
My -X- _ O
" -X- _ O
to -X- _ O
the -X- _ O
noun -X- _ O
" -X- _ O
May -X- _ O
" -X- _ O
forces -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
to -X- _ O
recognize -X- _ O
a -X- _ O
DATE -X- _ O
span -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
reasonable. -X- _ O
But -X- _ O
if -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
changes -X- _ O
the -X- _ O
preposition -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
into -X- _ O
a -X- _ O
verb -X- _ O
" -X- _ O
add -X- _ O
, -X- _ O
" -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
loses -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
recognize -X- _ O
the -X- _ O
utterance -X- _ O
" -X- _ O
half -X- _ O
past -X- _ O
one -X- _ O
" -X- _ O
as -X- _ O
TIME -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
preposition. -X- _ O
Similarly -X- _ O
, -X- _ O
changing -X- _ O
" -X- _ O
half -X- _ O
past -X- _ O
one -X- _ O
" -X- _ O
to -X- _ O
" -X- _ O
[ -X- _ O
one -X- _ O
thirty -X- _ O
] -X- _ O
TIME -X- _ O
" -X- _ O
retrieves -X- _ O
the -X- _ O
TIME -X- _ O
span -X- _ O
, -X- _ O
but -X- _ O
an -X- _ O
ASR -X- _ B-TaskName
error -X- _ O
confusing -X- _ O
the -X- _ O
numeral -X- _ O
" -X- _ O
one -X- _ O
" -X- _ O
with -X- _ O
the -X- _ O
conjunction -X- _ O
" -X- _ O
when -X- _ O
" -X- _ O
produces -X- _ O
" -X- _ O
[ -X- _ O
Wednesday -X- _ O
] -X- _ O
DATE -X- _ O
at -X- _ O
when -X- _ O
[ -X- _ O
thirty -X- _ O
] -X- _ O
DATE -X- _ O
. -X- _ O
" -X- _ O
If -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
word -X- _ O
is -X- _ O
mistakenly -X- _ O
recognized -X- _ O
as -X- _ O
the -X- _ O
verb -X- _ O
" -X- _ O
want -X- _ O
, -X- _ O
" -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
produces -X- _ O
" -X- _ O
[ -X- _ O
Wednesday -X- _ O
] -X- _ O
DATE -X- _ O
at -X- _ O
want -X- _ O
[ -X- _ O
thirty -X- _ O
] -X- _ O
CARDINAL -X- _ O
" -X- _ O
. -X- _ O

Unfortunately -X- _ O
, -X- _ O
the -X- _ O
problems -X- _ O
mentioned -X- _ O
above -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
easily -X- _ O
solved. -X- _ O
Word -X- _ B-MetricName
error -X- _ I-MetricName
rates -X- _ I-MetricName
( -X- _ O
WER -X- _ B-MetricName
) -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
remain -X- _ O
high -X- _ O
for -X- _ O
spontaneous -X- _ O
human -X- _ O
conversations -X- _ O
( -X- _ O
Del -X- _ O
Rio -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
announced -X- _ O
results -X- _ O
claiming -X- _ O
WERs -X- _ B-MetricName
at -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
5 -X- _ O
% -X- _ O
apply -X- _ O
to -X- _ O
conversations -X- _ O
with -X- _ O
digital -X- _ O
assistants -X- _ O
, -X- _ O
where -X- _ O
spoken -X- _ O
utterances -X- _ O
are -X- _ O
imperative -X- _ O
phrases -X- _ O
with -X- _ O
limited -X- _ O
vocabulary. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
representative -X- _ O
of -X- _ O
spontaneous -X- _ O
human -X- _ O
open -X- _ O
dialogues -X- _ O
, -X- _ O
which -X- _ O
lack -X- _ O
the -X- _ O
rigid -X- _ O
grammatical -X- _ O
phrase -X- _ O
structure -X- _ O
and -X- _ O
contain -X- _ O
fillers -X- _ O
, -X- _ O
back-channeling -X- _ O
, -X- _ O
repetitions -X- _ O
, -X- _ O
hesitation -X- _ O
markers -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
elements -X- _ O
which -X- _ O
are -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
. -X- _ O

The -X- _ O
interplay -X- _ O
of -X- _ O
two -X- _ O
phenomena -X- _ O
makes -X- _ O
the -X- _ O
processing -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
transcripts -X- _ O
with -X- _ O
NLP -X- _ O
models -X- _ O
so -X- _ O
challenging. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
every -X- _ O
NLP -X- _ O
model -X- _ O
is -X- _ O
inherently -X- _ O
flawed -X- _ O
and -X- _ O
produces -X- _ O
errors -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
not -X- _ O
recognizing -X- _ O
an -X- _ O
instance -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
injects -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
insertions -X- _ O
, -X- _ O
deletions -X- _ O
, -X- _ O
and -X- _ O
substitutions. -X- _ O
This -X- _ O
changes -X- _ O
the -X- _ O
structure -X- _ O
and -X- _ O
semantics -X- _ O
of -X- _ O
transcribed -X- _ O
speech -X- _ O
and -X- _ O
introduces -X- _ O
yet -X- _ O
another -X- _ O
source -X- _ O
of -X- _ O
errors -X- _ O
: -X- _ O
alignment. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
on -X- _ O
the -X- _ O
transcript -X- _ O
, -X- _ O
one -X- _ O
has -X- _ O
to -X- _ O
align -X- _ O
tokens -X- _ O
between -X- _ O
gold -X- _ O
transcripts -X- _ O
and -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
to -X- _ O
match -X- _ O
entity -X- _ O
spans. -X- _ O
This -X- _ O
process -X- _ O
may -X- _ O
produce -X- _ O
artifacts -X- _ O
that -X- _ O
significantly -X- _ O
skew -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
evaluation -X- _ O
. -X- _ O

The -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task -X- _ O
is -X- _ O
usually -X- _ O
performed -X- _ O
using -X- _ O
precision -X- _ O
, -X- _ O
recall -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score. -X- _ O
Unfortunately -X- _ O
, -X- _ O
these -X- _ O
measures -X- _ O
are -X- _ O
of -X- _ O
limited -X- _ O
use -X- _ O
for -X- _ O
processing -X- _ O
spontaneous -X- _ O
conversation -X- _ O
transcripts -X- _ O
because -X- _ O
they -X- _ O
confound -X- _ O
two -X- _ O
independent -X- _ O
factors -X- _ O
contributing -X- _ O
to -X- _ O
the -X- _ O
errors -X- _ O
mentioned -X- _ O
above -X- _ O
: -X- _ O
the -X- _ O
inability -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
to -X- _ O
recognize -X- _ O
a -X- _ O
span -X- _ O
as -X- _ O
an -X- _ O
entity -X- _ O
and -X- _ O
the -X- _ O
word -X- _ O
error -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
wrong -X- _ O
transcription -X- _ O
of -X- _ O
a -X- _ O
token -X- _ O
. -X- _ O

Our -X- _ O
paper -X- _ O
is -X- _ O
a -X- _ O
reality -X- _ O
check -X- _ O
on -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
in -X- _ O
spontaneous -X- _ O
speech -X- _ O
transcripts. -X- _ O
Using -X- _ O
popular -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
state-of-the-art -X- _ O
language -X- _ O
models -X- _ O
fail -X- _ O
to -X- _ O
discover -X- _ O
entity -X- _ O
spans -X- _ O
in -X- _ O
transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
speech. -X- _ O
We -X- _ O
identify -X- _ O
several -X- _ O
artifacts -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
entity -X- _ O
recognition. -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
propensity -X- _ O
of -X- _ O
each -X- _ O
type -X- _ O
of -X- _ O
artifact -X- _ O
to -X- _ O
influence -X- _ O
the -X- _ O
recognition -X- _ O
of -X- _ O
named -X- _ O
entities. -X- _ O
This -X- _ O
approach -X- _ O
brings -X- _ O
us -X- _ O
closer -X- _ O
to -X- _ O
understanding -X- _ O
the -X- _ O
true -X- _ O
reasons -X- _ O
for -X- _ O
NER -X- _ B-TaskName
model -X- _ O
failures -X- _ O
on -X- _ O
spontaneous -X- _ O
speech -X- _ O
transcripts. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
misalignment -X- _ O
artifacts -X- _ O
are -X- _ O
essential -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
NLP -X- _ O
models -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
considered -X- _ O
when -X- _ O
evaluating -X- _ O
downstream -X- _ O
NLP -X- _ O
models -X- _ O
on -X- _ O
spontaneous -X- _ O
speech -X- _ O
transcripts -X- _ O
. -X- _ O

Entity -X- _ O
span -X- _ O
alignment -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
entity -X- _ O
spans -X- _ O
recognized -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
compared -X- _ O
to -X- _ O
those -X- _ O
recognized -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
must -X- _ O
perform -X- _ O
token -X- _ O
alignment -X- _ O
between -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
and -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
may -X- _ O
differ -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens. -X- _ O
Alignment -X- _ O
is -X- _ O
performed -X- _ O
after -X- _ O
diarisation -X- _ O
( -X- _ O
separating -X- _ O
speakers -X- _ O
' -X- _ O
utterances -X- _ O
into -X- _ O
separate -X- _ O
channels -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
channel -X- _ O
independently. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
greedy -X- _ O
alignment -X- _ O
procedure. -X- _ O
We -X- _ O
begin -X- _ O
by -X- _ O
running -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
on -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
and -X- _ O
tagging -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
transcript -X- _ O
using -X- _ O
the -X- _ O
IOB -X- _ O
scheme -X- _ O
( -X- _ O
B -X- _ O
-beginning -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
, -X- _ O
I -X- _ O
-inside -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
, -X- _ O
O -X- _ O
-outside -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
) -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
collapse -X- _ O
all -X- _ O
adjacent -X- _ O
I-tags -X- _ O
so -X- _ O
that -X- _ O
each -X- _ O
channel -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
B-tags -X- _ O
and -X- _ O
O-tags. -X- _ O
We -X- _ O
repeat -X- _ O
the -X- _ O
same -X- _ O
procedure -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
and -X- _ O
then -X- _ O
align -X- _ O
both -X- _ O
transcripts. -X- _ O
The -X- _ O
alignment -X- _ O
of -X- _ O
gold -X- _ O
transcripts -X- _ O
, -X- _ O
normalized -X- _ O
gold -X- _ O
transcripts -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
is -X- _ O
performed -X- _ O
by -X- _ O
the -X- _ O
fstalign -X- _ O
( -X- _ O
McNamara -X- _ O
and -X- _ O
Kokotov -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
kaldialign -X- _ O
( -X- _ O
Żelasko -X- _ O
and -X- _ O
Guo -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
libraries -X- _ O
, -X- _ O
with -X- _ O
minor -X- _ O
additional -X- _ O
corrections. -X- _ O
All -X- _ O
transcripts -X- _ O
are -X- _ O
matched -X- _ O
at -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
terminology -X- _ O
( -X- _ O
Pallett -X- _ O
, -X- _ O
1985 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
distinguish -X- _ O
the -X- _ O
following -X- _ O
types -X- _ O
of -X- _ O
errors -X- _ O
: -X- _ O

• -X- _ O
insertion -X- _ O
: -X- _ O
a -X- _ O
token -X- _ O
has -X- _ O
been -X- _ O
inserted -X- _ O
into -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O

• -X- _ O
substitution -X- _ O
: -X- _ O
a -X- _ O
token -X- _ O
has -X- _ O
been -X- _ O
wrongly -X- _ O
transcribed -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
both -X- _ O
transcripts -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
tokens -X- _ O
differ -X- _ O
, -X- _ O

• -X- _ O
deletion -X- _ O
: -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
has -X- _ O
not -X- _ O
recognized -X- _ O
a -X- _ O
token -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
sequence -X- _ O
of -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
is -X- _ O
shorter -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
gold -X- _ O
transcript -X- _ O
. -X- _ O

In -X- _ O
parallel -X- _ O
, -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
can -X- _ O
introduce -X- _ O
the -X- _ O
following -X- _ O
errors -X- _ O
: -X- _ O

• -X- _ O
hallucination -X- _ O
: -X- _ O
an -X- _ O
entity -X- _ O
tag -X- _ O
has -X- _ O
been -X- _ O
produced -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O

• -X- _ O
replacement -X- _ O
: -X- _ O
an -X- _ O
entity -X- _ O
tag -X- _ O
has -X- _ O
been -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
token -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
class -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O

• -X- _ O
omission -X- _ O
: -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
does -X- _ O
not -X- _ O
produce -X- _ O
an -X- _ O
entity -X- _ O
tag -X- _ O
for -X- _ O
a -X- _ O
token -X- _ O
tagged -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
. -X- _ O

Let -X- _ O
us -X- _ O
now -X- _ O
describe -X- _ O
in -X- _ O
detail -X- _ O
all -X- _ O
possible -X- _ O
combinations -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NLP -X- _ O
errors -X- _ O
and -X- _ O
their -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
recognition -X- _ O
of -X- _ O
named -X- _ O
entities. -X- _ O
For -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
clarity -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
only -X- _ O
consider -X- _ O
artifacts -X- _ O
of -X- _ O
the -X- _ O
ASR-NLP -X- _ B-TaskName
gap -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
entity -X- _ O
span. -X- _ O
Detailed -X- _ O
examples -X- _ O
of -X- _ O
every -X- _ O
combination -X- _ O
of -X- _ O
ASR-NLP -X- _ B-TaskName
errors -X- _ O
discovered -X- _ O
in -X- _ O
the -X- _ O
Earnings-21 -X- _ B-DatasetName
dataset -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
let -X- _ O
us -X- _ O
consider -X- _ O
a -X- _ O
scenario -X- _ O
where -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
and -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
are -X- _ O
perfectly -X- _ O
aligned -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
all -X- _ O
tokens -X- _ O
are -X- _ O
correctly -X- _ O
recognized. -X- _ O
The -X- _ O
gold -X- _ O
transcript -X- _ O
contains -X- _ O
the -X- _ O
utterance -X- _ O
" -X- _ O
second -X- _ O
B-DATE -X- _ O
quarter -X- _ O
B-DATE -X- _ O
twenty -X- _ O
B-DATE -X- _ O
twenty -X- _ O
B-DATE -X- _ O
. -X- _ O
" -X- _ O
The -X- _ O
following -X- _ O
entity -X- _ O
span -X- _ O
errors -X- _ O
are -X- _ O
possible -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
: -X- _ O
• -X- _ O
full -X- _ O
match -X- _ O
: -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
receives -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
tag -X- _ O
as -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
( -X- _ O
row -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
full -X- _ O
omission -X- _ O
: -X- _ O
no -X- _ O
entity -X- _ O
tags -X- _ O
are -X- _ O
produced -X- _ O
for -X- _ O
tokens -X- _ O
inside -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
entity -X- _ O
span -X- _ O
( -X- _ O
row -X- _ O
C -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
full -X- _ O
replacement -X- _ O
: -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
has -X- _ O
a -X- _ O
different -X- _ O
entity -X- _ O
tag -X- _ O
from -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
( -X- _ O
row -X- _ O
D -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
match -X- _ O
with -X- _ O
replacement -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
have -X- _ O
different -X- _ O
entity -X- _ O
tags -X- _ O
from -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
( -X- _ O
row -X- _ O
E -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
match -X- _ O
with -X- _ O
omission -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
entity -X- _ O
tags -X- _ O
( -X- _ O
row -X- _ O
F -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
match -X- _ O
with -X- _ O
omission -X- _ O
and -X- _ O
replacement -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-MethodName
output -X- _ O
have -X- _ O
a -X- _ O
different -X- _ O
entity -X- _ O
class -X- _ O
tag -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
tokens -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
entity -X- _ O
tags -X- _ O
. -X- _ O

Consider -X- _ O
a -X- _ O
situation -X- _ O
where -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
inserts -X- _ O
a -X- _ O
token -X- _ O
into -X- _ O
the -X- _ O
gold -X- _ O
transcript. -X- _ O
Obviously -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
mismatch -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
and -X- _ O
the -X- _ O
transcription. -X- _ O
Let -X- _ O
us -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
utterance -X- _ O
" -X- _ O
nextstart -X- _ O
B−ORG -X- _ O
group -X- _ O
I−ORG -X- _ O
" -X- _ O
has -X- _ O
been -X- _ O
mistakenly -X- _ O
transcribed -X- _ O
as -X- _ O
" -X- _ O
next -X- _ O
door -X- _ O
group. -X- _ O
" -X- _ O
Table -X- _ O
2 -X- _ O
summarizes -X- _ O
possible -X- _ O
combinations -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
. -X- _ O

• -X- _ O
full -X- _ O
match -X- _ O
: -X- _ O
tokens -X- _ O
are -X- _ O
tagged -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
class -X- _ O
labels -X- _ O
( -X- _ O
row -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
full -X- _ O
omission -X- _ O
: -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
a -X- _ O
token -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
prevents -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
from -X- _ O
finding -X- _ O
any -X- _ O
entity -X- _ O
tags -X- _ O
( -X- _ O
row -X- _ O
C -X- _ O
) -X- _ O
, -X- _ O
• -X- _ O
full -X- _ O
substitution -X- _ O
: -X- _ O
tag -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
forces -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
to -X- _ O
generate -X- _ O
different -X- _ O
entity -X- _ O
labels -X- _ O
( -X- _ O
row -X- _ O
D -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
substitution -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
are -X- _ O
tagged -X- _ O
with -X- _ O
different -X- _ O
entity -X- _ O
class -X- _ O
labels -X- _ O
( -X- _ O
row -X- _ O
E -X- _ O
) -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
omission -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
entity -X- _ O
tag -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
the -X- _ O
multiplication -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
( -X- _ O
row -X- _ O
F -X- _ O
) -X- _ O
or -X- _ O
shortening -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
( -X- _ O
row -X- _ O
G -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
ASR -X- _ B-TaskName
can -X- _ O
delete -X- _ O
a -X- _ O
token -X- _ O
from -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
possible -X- _ O
misalignment. -X- _ O
In -X- _ O
this -X- _ O
scenario -X- _ O
, -X- _ O
full -X- _ O
matching -X- _ O
is -X- _ O
impossible -X- _ O
because -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
will -X- _ O
contain -X- _ O
an -X- _ O
unmatched -X- _ O
token. -X- _ O
Similarly -X- _ O
, -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
hallucinated -X- _ O
or -X- _ O
fully -X- _ O
substituted. -X- _ O
Let -X- _ O
us -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
utterance -X- _ O
" -X- _ O
next -X- _ O
B-ORG -X- _ O
door -X- _ O
I-ORG -X- _ O
group -X- _ O
I-ORG -X- _ O
" -X- _ O
has -X- _ O
been -X- _ O
mistakenly -X- _ O
transcribed -X- _ O
as -X- _ O
" -X- _ O
next -X- _ O
< -X- _ O
del -X- _ O
> -X- _ O
group -X- _ O
" -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
ASR -X- _ O
failed -X- _ O
to -X- _ O
recognize -X- _ O
the -X- _ O
" -X- _ O
door -X- _ O
" -X- _ O
token -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
presents -X- _ O
possible -X- _ O
combinations -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
. -X- _ O

• -X- _ O
partial -X- _ O
match -X- _ O
: -X- _ O
tokens -X- _ O
not -X- _ O
deleted -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
have -X- _ O
correct -X- _ O
entity -X- _ O
tags -X- _ O
, -X- _ O

• -X- _ O
full -X- _ O
omission -X- _ O
: -X- _ O
the -X- _ O
deletion -X- _ O
of -X- _ O
a -X- _ O
token -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
prevents -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
from -X- _ O
producing -X- _ O
any -X- _ O
entity -X- _ O
tags -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
replacement -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
have -X- _ O
the -X- _ O
wrong -X- _ O
entity -X- _ O
tag -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
omission -X- _ O
: -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
token -X- _ O
results -X- _ O
in -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
not -X- _ O
being -X- _ O
tagged -X- _ O
with -X- _ O
an -X- _ O
entity -X- _ O
tag -X- _ O
, -X- _ O

• -X- _ O
partial -X- _ O
replacement -X- _ O
and -X- _ O
omission -X- _ O
: -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
receive -X- _ O
correct -X- _ O
entity -X- _ O
tags -X- _ O
, -X- _ O
some -X- _ O
receive -X- _ O
wrong -X- _ O
entity -X- _ O
tags -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
do -X- _ O
not -X- _ O
receive -X- _ O
any -X- _ O
entity -X- _ O
tags -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
can -X- _ O
hallucinate -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
where -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
has -X- _ O
no -X- _ O
entities -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
possible -X- _ O
mistakes -X- _ O
is -X- _ O
large -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
obvious -X- _ O
which -X- _ O
scenarios -X- _ O
are -X- _ O
common -X- _ O
or -X- _ O
rare. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
are -X- _ O
to -X- _ O
develop -X- _ O
more -X- _ O
robust -X- _ O
models -X- _ O
for -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
in -X- _ O
the -X- _ O
transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
understand -X- _ O
which -X- _ O
scenarios -X- _ O
are -X- _ O
the -X- _ O
most -X- _ O
impactful -X- _ O
for -X- _ O
the -X- _ O
NER -X- _ B-TaskName
task. -X- _ O
In -X- _ O
the -X- _ O
next -X- _ O
sections -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
experiments -X- _ O
that -X- _ O
try -X- _ O
to -X- _ O
present -X- _ O
a -X- _ O
much -X- _ O
more -X- _ O
detailed -X- _ O
and -X- _ O
nuanced -X- _ O
view -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
. -X- _ O

Datasets -X- _ O
We -X- _ O
use -X- _ O
three -X- _ O
datasets -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

• -X- _ O
OntoNotes -X- _ B-DatasetName
: -X- _ O
the -X- _ O
LDC-released -X- _ O
OntoNotes -X- _ B-DatasetName
v5 -X- _ I-DatasetName
( -X- _ O
Weischedel -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
with -X- _ O
texts -X- _ O
from -X- _ O
news -X- _ O
, -X- _ O
broadcast -X- _ O
/ -X- _ O
telephone -X- _ O
conversations -X- _ O
, -X- _ O
and -X- _ O
web -X- _ O
data -X- _ O
annotated -X- _ O
with -X- _ O
18 -X- _ O
entity -X- _ O
types -X- _ O
. -X- _ O

• -X- _ O
SWNE -X- _ B-DatasetName
: -X- _ O
data -X- _ O
from -X- _ O
Switchboard -X- _ B-DatasetName
Dialog -X- _ I-DatasetName
Acts -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
annotated -X- _ O
with -X- _ O
entity -X- _ O
tags -X- _ O
following -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
v5 -X- _ I-DatasetName
annotation -X- _ O
scheme -X- _ O
( -X- _ O
Choi -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O

• -X- _ O
Earnings-21 -X- _ B-DatasetName
: -X- _ O
audio -X- _ O
and -X- _ O
transcriptions -X- _ O
of -X- _ O
44 -X- _ O
public -X- _ O
phone -X- _ O
calls -X- _ O
which -X- _ O
span -X- _ O
almost -X- _ O
40 -X- _ O
hours -X- _ O
of -X- _ O
recordings -X- _ O
of -X- _ O
human -X- _ O
conversations -X- _ O
, -X- _ O
with -X- _ O
25 -X- _ O
different -X- _ O
entity -X- _ O
classes -X- _ O
annotated -X- _ O
in -X- _ O
transcripts -X- _ O
( -X- _ O
Del -X- _ O
Rio -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
decided -X- _ O
to -X- _ O
omit -X- _ O
the -X- _ O
CoNLL-2003 -X- _ O
/ -X- _ O
CoNLL++ -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
dataset -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
annotated -X- _ O
with -X- _ O
only -X- _ O
four -X- _ O
classes -X- _ O
of -X- _ O
entities. -X- _ O
Unfortunately -X- _ O
, -X- _ O
the -X- _ O
three -X- _ O
listed -X- _ O
datasets -X- _ O
are -X- _ O
the -X- _ O
only -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
that -X- _ O
contain -X- _ O
audio -X- _ O
segments -X- _ O
and -X- _ O
transcripts -X- _ O
annotated -X- _ O
with -X- _ O
entity -X- _ O
types. -X- _ O
One -X- _ O
may -X- _ O
argue -X- _ O
that -X- _ O
these -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
representative -X- _ O
of -X- _ O
spontaneous -X- _ O
conversations. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Earnings-21 -X- _ B-DatasetName
transcripts -X- _ O
sound -X- _ O
heavily -X- _ O
scripted -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
interlocutors -X- _ O
present -X- _ O
speeches -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
free -X- _ O
exchange -X- _ O
of -X- _ O
utterances. -X- _ O
While -X- _ O
this -X- _ O
is -X- _ O
true -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
these -X- _ O
three -X- _ O
datasets -X- _ O
present -X- _ O
the -X- _ O
closest -X- _ O
that -X- _ O
researchers -X- _ O
can -X- _ O
get -X- _ O
to -X- _ O
conversational -X- _ O
audio -X- _ O
transcripts -X- _ O
with -X- _ O
annotated -X- _ O
entity -X- _ O
spans -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
datasets -X- _ O
with -X- _ O
audio -X- _ O
recordings -X- _ O
annotated -X- _ O
with -X- _ O
entity -X- _ O
spans -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
spontaneous -X- _ O
speech. -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
we -X- _ O
are -X- _ O
observing -X- _ O
significant -X- _ O
progress -X- _ O
in -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
in -X- _ O
transcripts -X- _ O
of -X- _ O
scripted -X- _ O
speech. -X- _ O
This -X- _ O
progress -X- _ O
is -X- _ O
made -X- _ O
possible -X- _ O
mostly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
publication -X- _ O
of -X- _ O
annotated -X- _ O
datasets. -X- _ O
Yadav -X- _ O
et -X- _ O
al. -X- _ O
present -X- _ O
a -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
TED -X- _ O
talks -X- _ O
, -X- _ O
Mozilla -X- _ O
Common -X- _ O
Voice -X- _ O
recordings -X- _ O
, -X- _ O
LibriSpeech -X- _ O
audiobook -X- _ O
recordings -X- _ O
, -X- _ O
and -X- _ O
VoxForge -X- _ O
recordings. -X- _ O
As -X- _ O
the -X- _ O
authors -X- _ O
observe -X- _ O
, -X- _ O
NER -X- _ B-TaskName
models -X- _ O
achieve -X- _ O
promising -X- _ O
results -X- _ O
on -X- _ O
these -X- _ O
transcripts -X- _ O
( -X- _ O
probably -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
transcript -X- _ O
is -X- _ O
semantically -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
typical -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
NER -X- _ B-TaskName
models -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
same -X- _ O
dataset -X- _ O
is -X- _ O
used -X- _ O
by -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
to -X- _ O
illustrate -X- _ O
the -X- _ O
error -X- _ O
correction -X- _ O
model. -X- _ O
Recently -X- _ O
, -X- _ O
annotated -X- _ O
transcripts -X- _ O
of -X- _ O
speech -X- _ O
( -X- _ O
albeit -X- _ O
non-conversional -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
released -X- _ O
for -X- _ O
Scandinavian -X- _ O
languages -X- _ O
( -X- _ O
Porjazovski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
French -X- _ O
( -X- _ O
Millour -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
Chinese -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
mentioning -X- _ O
that -X- _ O
NER -X- _ B-TaskName
task -X- _ O
has -X- _ O
been -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
recent -X- _ O
Spoken -X- _ O
Language -X- _ O
Understanding -X- _ O
Evaluation -X- _ O
( -X- _ O
SLUE -X- _ O
) -X- _ O
benchmark -X- _ O
( -X- _ O
Shon -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
the -X- _ O
annotation -X- _ O
covers -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
VoxPopuli -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
representative -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
, -X- _ O
the -X- _ O
VoxPopuli -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
recorded -X- _ O
speeches -X- _ O
in -X- _ O
the -X- _ O
European -X- _ O
Parliament -X- _ O
. -X- _ O

Entity -X- _ O
classes -X- _ O
annotated -X- _ O
in -X- _ O
the -X- _ O
above -X- _ O
datasets -X- _ O
can -X- _ O
be -X- _ O
broadly -X- _ O
divided -X- _ O
into -X- _ O
closed-domain -X- _ O
and -X- _ O
opendomain -X- _ O
types. -X- _ O
Closed-domain -X- _ O
entity -X- _ O
classes -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
almost -X- _ O
gazetteers -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
these -X- _ O
are -X- _ O
classes -X- _ O
for -X- _ O
which -X- _ O
a -X- _ O
vast -X- _ O
majority -X- _ O
of -X- _ O
entities -X- _ O
can -X- _ O
be -X- _ O
listed. -X- _ O
Examples -X- _ O
of -X- _ O
closed-domain -X- _ O
entity -X- _ O
classes -X- _ O
include -X- _ O
geographical -X- _ O
locations -X- _ O
or -X- _ O
first -X- _ O
names -X- _ O
( -X- _ O
since -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
US -X- _ O
first -X- _ O
names -X- _ O
follows -X- _ O
a -X- _ O
power -X- _ O
law -X- _ O
distribution -X- _ O
( -X- _ O
Hahn -X- _ O
and -X- _ O
Bentley -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
relatively -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
first -X- _ O
names -X- _ O
represents -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
first -X- _ O
names -X- _ O
encountered -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
open-domain -X- _ O
entity -X- _ O
classes -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
summarized -X- _ O
using -X- _ O
a -X- _ O
gazetteer. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
case -X- _ O
with -X- _ O
numbers -X- _ O
, -X- _ O
product -X- _ O
names -X- _ O
, -X- _ O
money -X- _ O
, -X- _ O
or -X- _ O
organizations. -X- _ O
Unfortunately -X- _ O
, -X- _ O
gazetteers -X- _ O
are -X- _ O
not -X- _ O
a -X- _ O
viable -X- _ O
solution -X- _ O
even -X- _ O
for -X- _ O
closed-domain -X- _ O
entity -X- _ O
classes -X- _ O
because -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
may -X- _ O
produce -X- _ O
tokens -X- _ O
outside -X- _ O
the -X- _ O
gazetteer -X- _ O
. -X- _ O

One -X- _ O
possible -X- _ O
solution -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
try -X- _ O
to -X- _ O
overcome -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
by -X- _ O
retrofitting -X- _ O
token -X- _ O
representations -X- _ O
using -X- _ O
domain -X- _ O
datasets. -X- _ O
This -X- _ O
technique -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
static -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
mitigate -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
by -X- _ O
. -X- _ O

It -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
see -X- _ O
the -X- _ O
same -X- _ O
technique -X- _ O
applied -X- _ O
to -X- _ O
transformer-based -X- _ O
embeddings -X- _ O
. -X- _ O

Experiments -X- _ O
One -X- _ O
might -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
variable -X- _ O
influencing -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
on -X- _ O
a -X- _ O
transcript -X- _ O
is -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
a -X- _ O
particular -X- _ O
ASR -X- _ B-TaskName
system. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
find -X- _ O
this -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
case. -X- _ O
The -X- _ O
ASR-NLP -X- _ B-TaskName
gap -X- _ O
is -X- _ O
equally -X- _ O
pronounced -X- _ O
for -X- _ O
all -X- _ O
major -X- _ O
commercial -X- _ O
ASR -X- _ B-TaskName
systems. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
offered -X- _ O
by -X- _ O
Microsoft -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
lowest -X- _ O
reported -X- _ O
WER -X- _ B-MetricName
on -X- _ O
the -X- _ O
Earnings-21 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Del -X- _ O
Rio -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Performance -X- _ O
on -X- _ O
gold -X- _ O
transcripts -X- _ O
In -X- _ O
our -X- _ O
first -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
state-of-theart -X- _ O
NER -X- _ B-TaskName
model -X- _ O
on -X- _ O
gold -X- _ O
transcripts. -X- _ O
We -X- _ O
train -X- _ O
a -X- _ O
transformer -X- _ O
using -X- _ O
the -X- _ O
Roberta-Large -X- _ B-MethodName
architecture -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
train -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
dataset -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
Earnings-21 -X- _ B-DatasetName
, -X- _ O
SWNE -X- _ B-DatasetName
, -X- _ O
and -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
datasets. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
comparison -X- _ O
as -X- _ O
fair -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
we -X- _ O
normalize -X- _ O
gold -X- _ O
transcripts -X- _ O
using -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
heuristics. -X- _ O
Normalization -X- _ O
changes -X- _ O
all -X- _ O
numbers -X- _ O
into -X- _ O
respective -X- _ O
words. -X- _ O
We -X- _ O
unify -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
currency -X- _ O
indicator -X- _ O
when -X- _ O
spelling -X- _ O
monetary -X- _ O
values -X- _ O
and -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
percent -X- _ O
sign. -X- _ O
All -X- _ O
gold -X- _ O
transcripts -X- _ O
are -X- _ O
properly -X- _ O
cased -X- _ O
and -X- _ O
punctuated. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
as -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
micro -X- _ B-MetricName
F -X- _ I-MetricName
1 -X- _ I-MetricName
score -X- _ O
because -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
highly -X- _ O
imbalanced -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model. -X- _ O
We -X- _ O
must -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
experimental -X- _ O
setting -X- _ O
is -X- _ O
very -X- _ O
favorable -X- _ O
for -X- _ O
the -X- _ O
ASR. -X- _ B-TaskName
Not -X- _ O
only -X- _ O
is -X- _ O
the -X- _ O
transcript -X- _ O
fully -X- _ O
normalized -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
alignment -X- _ O
procedure -X- _ O
is -X- _ O
fine-tuned -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
misalignments -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
text -X- _ O
fragments -X- _ O
chunked -X- _ O
according -X- _ O
to -X- _ O
punctuation -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcripts -X- _ O
and -X- _ O
not -X- _ O
to -X- _ O
fixed-width -X- _ O
sliding -X- _ O
windows. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
of -X- _ O
much -X- _ O
higher -X- _ O
quality -X- _ O
than -X- _ O
should -X- _ O
be -X- _ O
expected -X- _ O
from -X- _ O
the -X- _ O
commercial -X- _ O
ASR -X- _ B-TaskName
. -X- _ O

Despite -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
OntoNotes -X- _ B-DatasetName
contains -X- _ O
a -X- _ O
significant -X- _ O
amount -X- _ O
of -X- _ O
transcripts -X- _ O
of -X- _ O
unscripted -X- _ O
human -X- _ O
conversations -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
deteriorates -X- _ O
dramatically -X- _ O
on -X- _ O
SWNE -X- _ B-DatasetName
and -X- _ O
Earnings-21 -X- _ B-DatasetName
datasets. -X- _ O
For -X- _ O
all -X- _ O
entity -X- _ O
classes -X- _ O
, -X- _ O
the -X- _ O
recognition -X- _ O
in -X- _ O
SWNE -X- _ B-DatasetName
and -X- _ O
Earnings-21 -X- _ B-DatasetName
is -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
OntoNotes. -X- _ O
The -X- _ O
NER -X- _ B-TaskName
model -X- _ O
struggles -X- _ O
particularly -X- _ O
with -X- _ O
open-domain -X- _ O
entity -X- _ O
classes. -X- _ O
The -X- _ O
complete -X- _ O
failure -X- _ O
to -X- _ O
recognize -X- _ O
MONEY -X- _ O
, -X- _ O
PRODUCT -X- _ O
or -X- _ O
TIME -X- _ O
entities -X- _ O
makes -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
practically -X- _ O
unusable -X- _ O
in -X- _ O
real-world -X- _ O
scenarios. -X- _ O
Leaving -X- _ O
aside -X- _ O
more -X- _ O
exotic -X- _ O
classes -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
by -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
( -X- _ O
LANGUAGE -X- _ O
, -X- _ O
LAW -X- _ O
, -X- _ O
WORK_OF_ART -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
performs -X- _ O
better -X- _ O
( -X- _ O
albeit -X- _ O
not -X- _ O
satisfactorily -X- _ O
) -X- _ O
for -X- _ O
closed-domain -X- _ O
classes -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
can -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
degree -X- _ O
memorize -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
instances -X- _ O
of -X- _ O
a -X- _ O
class. -X- _ O
For -X- _ O
open-domain -X- _ O
entity -X- _ O
classes -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
disappointingly -X- _ O
bad. -X- _ O
Please -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
properly -X- _ O
cased -X- _ O
and -X- _ O
punctuated -X- _ O
transcripts -X- _ O
of -X- _ O
conversations -X- _ O
and -X- _ O
not -X- _ O
to -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
, -X- _ O
yet -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
are -X- _ O
significantly -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
scores -X- _ O
obtained -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Performance -X- _ O
on -X- _ O
ASR -X- _ B-TaskName
transcripts -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
our -X- _ O
NER -X- _ B-TaskName
model -X- _ O
on -X- _ O
the -X- _ O
Earnings-21 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
every -X- _ O
error -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2. -X- _ O
Transcripts -X- _ O
of -X- _ O
Earnings-21 -X- _ B-DatasetName
recordings -X- _ O
are -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
Microsoft -X- _ B-MethodName
ASR. -X- _ I-MethodName
The -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O
The -X- _ O
first -X- _ O
column -X- _ O
reports -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
NER -X- _ B-TaskName
model -X- _ O
errors -X- _ O
when -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
is -X- _ O
fully -X- _ O
matched -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
( -X- _ O
no -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
in -X- _ O
the -X- _ O
transcript -X- _ O
) -X- _ O
. -X- _ O
Subsequent -X- _ O
columns -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
NER -X- _ B-TaskName
model -X- _ O
errors -X- _ O
when -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
is -X- _ O
misaligned -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
due -X- _ O
to -X- _ O
token -X- _ O
insertion -X- _ O
, -X- _ O
substitution -X- _ O
, -X- _ O
or -X- _ O
deletion -X- _ O
by -X- _ O
the -X- _ O
ASR. -X- _ B-TaskName
Please -X- _ O
note -X- _ O
that -X- _ O
ASR -X- _ B-TaskName
insertion -X- _ O
, -X- _ O
substitution -X- _ O
, -X- _ O
and -X- _ O
deletion -X- _ O
errors -X- _ O
often -X- _ O
co-occur -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
entity -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O
so -X- _ O
a -X- _ O
single -X- _ O
entity -X- _ O
span -X- _ O
may -X- _ O
contribute -X- _ O
to -X- _ O
multiple -X- _ O
cells -X- _ O
in -X- _ O
the -X- _ O
table. -X- _ O
Our -X- _ O
intention -X- _ O
is -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
real -X- _ O
impact -X- _ O
of -X- _ O
each -X- _ O
type -X- _ O
of -X- _ O
ASR-NLP -X- _ B-TaskName
error -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
clearly -X- _ O
show -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
joint -X- _ O
ASR-NLP -X- _ B-TaskName
model -X- _ O
evaluation -X- _ O
, -X- _ O
as -X- _ O
reflected -X- _ O
by -X- _ O
the -X- _ O
breakdown -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
error -X- _ O
sources -X- _ O
4 -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
makes -X- _ O
mistakes -X- _ O
on -X- _ O
fully -X- _ O
matched -X- _ O
transcripts -X- _ O
of -X- _ O
spoken -X- _ O
conversations -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
manages -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
in -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
without -X- _ O
errors. -X- _ O
These -X- _ O
errors -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
approximately -X- _ O
half -X- _ O
of -X- _ O
all -X- _ O
recorded -X- _ O
errors. -X- _ O
Let -X- _ O
us -X- _ O
stress -X- _ O
this -X- _ O
result -X- _ O
again -X- _ O
: -X- _ O
NER -X- _ B-TaskName
models -X- _ O
are -X- _ O
inherently -X- _ O
incapable -X- _ O
of -X- _ O
processing -X- _ O
the -X- _ O
transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
; -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
introduces -X- _ O
no -X- _ O
errors -X- _ O
, -X- _ O
37 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
entity -X- _ O
spans -X- _ O
are -X- _ O
partially -X- _ O
or -X- _ O
fully -X- _ O
wrong -X- _ O
( -X- _ O
first -X- _ O
column -X- _ O
in -X- _ O
Tab. -X- _ O
5 -X- _ O
) -X- _ O

We -X- _ O
also -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
is -X- _ O
very -X- _ O
sensitive -X- _ O
to -X- _ O
errors -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
ASR. -X- _ B-TaskName
It -X- _ O
can -X- _ O
correctly -X- _ O
recognize -X- _ O
only -X- _ O
18 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
entities -X- _ O
when -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
substitutes -X- _ O
a -X- _ O
token -X- _ O
inside -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
, -X- _ O
6.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
entities -X- _ O
when -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
inserts -X- _ O
a -X- _ O
token -X- _ O
inside -X- _ O
the -X- _ O
entity -X- _ O
span -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
fails -X- _ O
to -X- _ O
correctly -X- _ O
recognize -X- _ O
an -X- _ O
entity -X- _ O
when -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
deletes -X- _ O
a -X- _ O
token -X- _ O
inside -X- _ O
the -X- _ O
entity -X- _ O
span. -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
many -X- _ O
hallucinated -X- _ O
entities -X- _ O
and -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
omissions. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
entity -X- _ O
errors -X- _ O
doubles -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
made -X- _ O
on -X- _ O
fully -X- _ O
matched -X- _ O
transcript -X- _ O
: -X- _ O
ca. -X- _ O
6200 -X- _ O
omitted -X- _ O
entities -X- _ O
in -X- _ O
total -X- _ O
vs. -X- _ O
3600 -X- _ O
with -X- _ O
perfect -X- _ O
transcript -X- _ O
and -X- _ O
ca. -X- _ O
2000 -X- _ O
hallucinated -X- _ O
ones -X- _ O
versus -X- _ O
1000 -X- _ O
with -X- _ O
the -X- _ O
perfect -X- _ O
transcript. -X- _ O
Again -X- _ O
, -X- _ O
let -X- _ O
us -X- _ O
reiterate -X- _ O
this -X- _ O
finding -X- _ O
: -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
is -X- _ O
helpless -X- _ O
when -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
are -X- _ O
introduced -X- _ O
inside -X- _ O
entity -X- _ O
spans -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
retrieve -X- _ O
an -X- _ O
entity -X- _ O
when -X- _ O
tokens -X- _ O
are -X- _ O
inserted -X- _ O
, -X- _ O
substituted -X- _ O
, -X- _ O
or -X- _ O
deleted -X- _ O
from -X- _ O
entity -X- _ O
spans. -X- _ O
WER -X- _ B-MetricName
of -X- _ O
20.0 -X- _ B-MetricValue
reported -X- _ O
by -X- _ O
( -X- _ O
Del -X- _ O
Rio -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
! -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
case -X- _ O
for -X- _ O
partial -X- _ O
matches -X- _ O
, -X- _ O
while -X- _ O
smaller -X- _ O
than -X- _ O
hallucinated -X- _ O
, -X- _ O
replacement -X- _ O
, -X- _ O
and -X- _ O
omissions -X- _ O
, -X- _ O
is -X- _ O
of -X- _ O
great -X- _ O
importance. -X- _ O
The -X- _ O
true -X- _ O
effect -X- _ O
of -X- _ O
entity -X- _ O
hallucinations -X- _ O
and -X- _ O
omissions -X- _ O
in -X- _ O
a -X- _ O
joint -X- _ O
ASR-NLP -X- _ B-MethodName
system -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
measured -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task. -X- _ O
Usually -X- _ O
, -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
is -X- _ O
a -X- _ O
single -X- _ O
step -X- _ O
in -X- _ O
a -X- _ O
wider -X- _ O
NLP -X- _ O
task. -X- _ O
This -X- _ O
task -X- _ O
may -X- _ O
have -X- _ O
a -X- _ O
separate -X- _ O
evaluation -X- _ O
scheme -X- _ O
with -X- _ O
different -X- _ O
metrics -X- _ O
and -X- _ O
business -X- _ O
objectives. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
intent -X- _ O
retrieval -X- _ O
and -X- _ O
slot -X- _ O
filling -X- _ O
, -X- _ O
hallucinating -X- _ O
or -X- _ O
omitting -X- _ O
an -X- _ O
entity -X- _ O
span -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
situation -X- _ O
where -X- _ O
the -X- _ O
intent -X- _ O
is -X- _ O
either -X- _ O
not -X- _ O
matched -X- _ O
or -X- _ O
matched -X- _ O
in -X- _ O
the -X- _ O
wrong -X- _ O
place. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
partial -X- _ O
matches -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
evaluate. -X- _ O
With -X- _ O
partial -X- _ O
matching -X- _ O
, -X- _ O
the -X- _ O
intent -X- _ O
is -X- _ O
caught -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
slot -X- _ O
is -X- _ O
filled -X- _ O
, -X- _ O
but -X- _ O
most -X- _ O
probably -X- _ O
, -X- _ O
the -X- _ O
slot -X- _ O
is -X- _ O
filled -X- _ O
with -X- _ O
incorrect -X- _ O
values. -X- _ O
The -X- _ O
scale -X- _ O
of -X- _ O
failures -X- _ O
and -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
upstream -X- _ O
model -X- _ O
improvements -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
measured -X- _ O
by -X- _ O
evaluating -X- _ O
the -X- _ O
entire -X- _ O
NLP -X- _ O
pipeline -X- _ O
on -X- _ O
a -X- _ O
reference -X- _ O
dataset -X- _ O
with -X- _ O
annotations -X- _ O
of -X- _ O
intents -X- _ O
and -X- _ O
slots. -X- _ O
This -X- _ O
observation -X- _ O
strengthens -X- _ O
our -X- _ O
belief -X- _ O
that -X- _ O
measuring -X- _ O
the -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
errors -X- _ O
in -X- _ O
a -X- _ O
joint -X- _ O
ASR-NLP -X- _ B-MethodName
system -X- _ O
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
focusing -X- _ O
on -X- _ O
technical -X- _ O
details -X- _ O
of -X- _ O
measures -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
, -X- _ O
WER -X- _ B-MetricName
, -X- _ O
or -X- _ O
entity -X- _ B-MetricName
WER -X- _ I-MetricName
. -X- _ O

Related -X- _ O
Work -X- _ O
In -X- _ O
our -X- _ O
opinion -X- _ O
, -X- _ O
the -X- _ O
NLP -X- _ O
research -X- _ O
community -X- _ O
has -X- _ O
an -X- _ O
overly -X- _ O
optimistic -X- _ O
view -X- _ O
of -X- _ O
the -X- _ O
WERs -X- _ B-MetricName
introduced -X- _ O
by -X- _ O
ASR -X- _ B-TaskName
systems. -X- _ O
Recent -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
WERs -X- _ B-MetricName
in -X- _ O
transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
human -X- _ O
speech -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
expected. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Szymański -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
a -X- _ O
transcript -X- _ O
of -X- _ O
a -X- _ O
standard -X- _ O
GSM -X- _ O
phone -X- _ O
call -X- _ O
conversation -X- _ O
is -X- _ O
subject -X- _ O
to -X- _ O
a -X- _ O
16 -X- _ O
% -X- _ O
-20 -X- _ O
% -X- _ O
error -X- _ O
rate. -X- _ O
Del -X- _ O
Rio -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
confirm -X- _ O
this -X- _ O
result -X- _ O
and -X- _ O
report -X- _ O
how -X- _ O
WERs -X- _ B-MetricName
differ -X- _ O
between -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
entity -X- _ O
spans. -X- _ O
Spans -X- _ O
related -X- _ O
to -X- _ O
date -X- _ O
, -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
ordinal -X- _ O
numbers -X- _ O
were -X- _ O
observed -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
lower -X- _ O
WER -X- _ B-MetricName
than -X- _ O
entities -X- _ O
related -X- _ O
to -X- _ O
proper -X- _ O
names. -X- _ O
Facility -X- _ O
names -X- _ O
, -X- _ O
organizations -X- _ O
, -X- _ O
and -X- _ O
personal -X- _ O
names -X- _ O
demonstrate -X- _ O
a -X- _ O
very -X- _ O
high -X- _ O
WER -X- _ B-MetricName
of -X- _ O
30 -X- _ B-MetricValue
% -X- _ I-MetricValue
-50 -X- _ I-MetricValue
% -X- _ I-MetricValue
. -X- _ O
McNamara -X- _ O
and -X- _ O
Kokotov -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
also -X- _ O
released -X- _ O
a -X- _ O
library -X- _ O
for -X- _ O
using -X- _ O
Finite -X- _ O
State -X- _ O
Transducers -X- _ O
( -X- _ O
FSTs -X- _ O
) -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
different -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
entity -X- _ O
( -X- _ O
2020 -X- _ O
vs. -X- _ O
twenty -X- _ O
twenty -X- _ O
) -X- _ O
among -X- _ O
ASRs -X- _ B-TaskName
. -X- _ O

These -X- _ O
findings -X- _ O
are -X- _ O
in -X- _ O
stark -X- _ O
contrast -X- _ O
to -X- _ O
initial -X- _ O
reports. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Surdeanu -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
reported -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
in -X- _ O
Switchboard -X- _ O
corpus -X- _ O
to -X- _ O
be -X- _ O
within -X- _ O
5 -X- _ O
% -X- _ O
from -X- _ O
a -X- _ O
system -X- _ O
evaluated -X- _ O
on -X- _ O
clean -X- _ O
textual -X- _ O
data. -X- _ O
Similarly -X- _ O
, -X- _ O
Béchet -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2002 -X- _ O
) -X- _ O
claims -X- _ O
to -X- _ O
have -X- _ O
achieved -X- _ O
approximately -X- _ O
0.90 -X- _ B-MetricValue
F -X- _ B-MetricName
1 -X- _ I-MetricName
for -X- _ O
recognizing -X- _ O
phone -X- _ O
numbers -X- _ O
and -X- _ O
0.70 -X- _ B-MetricValue
F -X- _ B-MetricName
1 -X- _ I-MetricName
for -X- _ O
recognizing -X- _ O
money -X- _ O
mentions -X- _ O
in -X- _ O
the -X- _ O
transcripts -X- _ O
from -X- _ O
the -X- _ O
AT -X- _ O
& -X- _ O
T -X- _ O
How -X- _ O
may -X- _ O
I -X- _ O
help -X- _ O
you -X- _ O
? -X- _ O
system -X- _ O
under -X- _ O
27.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
WER -X- _ B-MetricName
ratio. -X- _ O
Favre -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
apply -X- _ O
NER -X- _ O
models -X- _ O
to -X- _ O
French -X- _ O
corpora -X- _ O
and -X- _ O
achieve -X- _ O
0.74 -X- _ B-MetricValue
F -X- _ B-MetricName
1 -X- _ I-MetricName
for -X- _ O
a -X- _ O
relatively -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
named -X- _ O
entities. -X- _ O
Precision -X- _ O
, -X- _ O
recall -X- _ O
, -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
scores -X- _ O
are -X- _ O
standard -X- _ O
metrics -X- _ O
for -X- _ O
reporting -X- _ O
NER -X- _ B-TaskName
model -X- _ O
performance -X- _ O
in -X- _ O
NLP. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
metrics -X- _ O
can -X- _ O
produce -X- _ O
unreliable -X- _ O
scores -X- _ O
where -X- _ O
entity -X- _ O
spans -X- _ O
are -X- _ O
marked -X- _ O
on -X- _ O
spontaneous -X- _ O
human -X- _ O
conversation -X- _ O
transcripts -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
conversational -X- _ O
artifacts -X- _ O
( -X- _ O
repetitions -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
backchanneling -X- _ O
, -X- _ O
phatic -X- _ O
expressions -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
entity -X- _ O
span -X- _ O
tagging -X- _ O
where -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
metric -X- _ O
produces -X- _ O
highly -X- _ O
misleading -X- _ O
scores -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
6 -X- _ O
. -X- _ O

To -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
these -X- _ O
artifacts -X- _ O
, -X- _ O
Message -X- _ O
Understanding -X- _ O
Conference -X- _ O
( -X- _ O
MUC -X- _ O
) -X- _ O
( -X- _ O
Grishman -X- _ O
and -X- _ O
Sundheim -X- _ O
( -X- _ O
1996 -X- _ O
) -X- _ O
; -X- _ O
Nadeau -X- _ O
and -X- _ O
Sekine -X- _ O
( -X- _ O
2007 -X- _ O
) -X- _ O
) -X- _ O
introduced -X- _ O
metrics -X- _ O
that -X- _ O
allow -X- _ O
for -X- _ O
partial -X- _ O
matching -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
span. -X- _ O
MUC -X- _ O
defines -X- _ O
six -X- _ O
categories -X- _ O
of -X- _ O
partial -X- _ O
matching -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
span -X- _ O
overlap -X- _ O
, -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
matched -X- _ O
entity -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
strictness -X- _ O
of -X- _ O
expectations -X- _ O
, -X- _ O
as -X- _ O
outlined -X- _ O
by -X- _ O
Batista -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
this -X- _ O
problem -X- _ O
has -X- _ O
been -X- _ O
addressed -X- _ O
by -X- _ O
Caubrière -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
who -X- _ O
argues -X- _ O
for -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
slot -X- _ O
error -X- _ O
rates -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
Hatmi -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
was -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
attempt -X- _ O
to -X- _ O
incorporate -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
into -X- _ O
the -X- _ O
automatic -X- _ O
speech -X- _ O
transcription -X- _ O
process. -X- _ O
The -X- _ O
authors -X- _ O
tagged -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
dictionary -X- _ O
with -X- _ O
named -X- _ O
entity -X- _ O
tags -X- _ O
( -X- _ O
since -X- _ O
ASR -X- _ O
can -X- _ O
not -X- _ O
produce -X- _ O
any -X- _ O
words -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
its -X- _ O
dictionary -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
initial -X- _ O
approach -X- _ O
has -X- _ O
been -X- _ O
superseded -X- _ O
by -X- _ O
methods -X- _ O
aiming -X- _ O
at -X- _ O
training -X- _ O
end-to-end -X- _ O
joint -X- _ O
models -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
, -X- _ O
as -X- _ O
proposed -X- _ O
by -X- _ O
Ghannay -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Serdyuk -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Stiefel -X- _ O
and -X- _ O
Vu -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
train -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
to -X- _ O
predict -X- _ O
transcription -X- _ O
tokens -X- _ O
and -X- _ O
their -X- _ O
part-of-speech -X- _ O
or -X- _ O
named -X- _ O
entity -X- _ O
tags -X- _ O
in -X- _ O
these -X- _ O
works -X- _ O
. -X- _ O

Limitations -X- _ O
Obviously -X- _ O
, -X- _ O
the -X- _ O
work -X- _ O
presented -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
conversations -X- _ O
in -X- _ O
English. -X- _ O
Since -X- _ O
we -X- _ O
are -X- _ O
investigating -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
, -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
practically -X- _ O
no -X- _ O
datasets -X- _ O
of -X- _ O
human -X- _ O
conversations -X- _ O
( -X- _ O
both -X- _ O
audio -X- _ O
and -X- _ O
transcripts -X- _ O
) -X- _ O
annotated -X- _ O
with -X- _ O
entity -X- _ O
spans -X- _ O
apart -X- _ O
from -X- _ O
SWNE -X- _ B-DatasetName
, -X- _ O
OntoNotes -X- _ B-DatasetName
and -X- _ O
Earnings-21 -X- _ B-DatasetName
, -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
paper. -X- _ O
These -X- _ O
datasets -X- _ O
are -X- _ O
relatively -X- _ O
small -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
frequency -X- _ O
of -X- _ O
appearance -X- _ O
of -X- _ O
entity -X- _ O
classes -X- _ O
is -X- _ O
extremely -X- _ O
skewed -X- _ O
, -X- _ O
with -X- _ O
several -X- _ O
entity -X- _ O
classes -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
handful -X- _ O
of -X- _ O
examples -X- _ O
. -X- _ O

Another -X- _ O
significant -X- _ O
limitation -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
reported -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
metric. -X- _ O
Following -X- _ O
the -X- _ O
common -X- _ O
practice -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
chosen -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
as -X- _ O
the -X- _ O
primary -X- _ O
metric -X- _ O
of -X- _ O
entity -X- _ O
recognition. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
metric -X- _ O
is -X- _ O
questionable -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
NER -X- _ B-TaskName
recognition -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
transcripts -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
highly -X- _ O
dependent -X- _ O
on -X- _ O
two -X- _ O
factors -X- _ O
: -X- _ O
the -X- _ O
WER -X- _ B-MetricName
produced -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
span -X- _ O
alignment. -X- _ O
Consider -X- _ O
a -X- _ O
gold -X- _ O
transcript -X- _ O
annotation -X- _ O
" -X- _ O
John -X- _ O
B-PERSON -X- _ O
F. -X- _ O
I-PERSON -X- _ O
Kennedy -X- _ O
I-PERSON -X- _ O
" -X- _ O
and -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
with -X- _ O
" -X- _ O
F. -X- _ O
" -X- _ O
transcribed -X- _ O
as -X- _ O
" -X- _ O
eh -X- _ O
" -X- _ O
annotated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
" -X- _ O
John -X- _ O
B-PERSON -X- _ O
eh -X- _ O
Kennedy -X- _ O
B-PERSON -X- _ O
. -X- _ O
" -X- _ O
Should -X- _ O
this -X- _ O
annotation -X- _ O
be -X- _ O
considered -X- _ O
correct -X- _ O
? -X- _ O
The -X- _ O
original -X- _ O
person -X- _ O
entity -X- _ O
starting -X- _ O
at -X- _ O
" -X- _ O
John -X- _ O
" -X- _ O
is -X- _ O
only -X- _ O
partially -X- _ O
matched -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
new -X- _ O
person -X- _ O
entity -X- _ O
starting -X- _ O
at -X- _ O
" -X- _ O
Kennedy -X- _ O
" -X- _ O
is -X- _ O
introduced -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ O
output. -X- _ O
Consider -X- _ O
another -X- _ O
gold -X- _ O
annotation -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
transcript -X- _ O
: -X- _ O
" -X- _ O
second -X- _ O
B-DATE -X- _ O
quarter -X- _ O
I-DATE -X- _ O
twenty -X- _ O
I-DATE -X- _ O
twenty -X- _ O
I-DATE -X- _ O
, -X- _ O
" -X- _ O
which -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model -X- _ O
tags -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

" -X- _ O
second -X- _ O
B-DATE -X- _ O
quarter -X- _ O
I-DATE -X- _ O
twenty -X- _ O
B-CARDINAL -X- _ O
twenty -X- _ O
I-CARDINAL -X- _ O
" -X- _ O
( -X- _ O
NER -X- _ B-TaskName
model -X- _ O
trained -X- _ O
on -X- _ O
written -X- _ O
language -X- _ O
does -X- _ O
not -X- _ O
recognize -X- _ O
" -X- _ O
twenty -X- _ O
twenty -X- _ O
" -X- _ O
as -X- _ O
a -X- _ O
valid -X- _ O
date -X- _ O
) -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
how -X- _ O
should -X- _ O
this -X- _ O
scenario -X- _ O
be -X- _ O
scored -X- _ O
by -X- _ O
an -X- _ O
accuracy -X- _ O
metric -X- _ O
? -X- _ O
Unfortunately -X- _ O
, -X- _ O
the -X- _ O
traditional -X- _ O
definition -X- _ O
of -X- _ O
the -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
is -X- _ O
too -X- _ O
restrictive -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
robust -X- _ O
score -X- _ O
that -X- _ O
could -X- _ O
paint -X- _ O
a -X- _ O
reliable -X- _ O
picture -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
performance. -X- _ O
The -X- _ O
design -X- _ O
and -X- _ O
implementation -X- _ O
of -X- _ O
a -X- _ O
metric -X- _ O
that -X- _ O
could -X- _ O
compute -X- _ O
the -X- _ O
alignment -X- _ O
of -X- _ O
entity -X- _ O
spans -X- _ O
in -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
would -X- _ O
be -X- _ O
a -X- _ O
significant -X- _ O
step -X- _ O
in -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
producing -X- _ O
more -X- _ O
robust -X- _ O
NER -X- _ B-TaskName
models -X- _ O
for -X- _ O
spoken -X- _ O
conversations -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
with -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
on -X- _ O
audio -X- _ O
files -X- _ O
from -X- _ O
the -X- _ O
Earnings-21 -X- _ B-DatasetName
dataset. -X- _ O
These -X- _ O
files -X- _ O
are -X- _ O
recorded -X- _ O
at -X- _ O
11 -X- _ O
kHz-44 -X- _ O
kHz -X- _ O
, -X- _ O
while -X- _ O
typical -X- _ O
call -X- _ O
center -X- _ O
conversations -X- _ O
are -X- _ O
recorded -X- _ O
at -X- _ O
8 -X- _ O
kHz-16 -X- _ O
kHz. -X- _ O
Unfortunately -X- _ O
, -X- _ O
training -X- _ O
datasets -X- _ O
with -X- _ O
recording -X- _ O
characteristics -X- _ O
resembling -X- _ O
real-world -X- _ O
usage -X- _ O
scenarios -X- _ O
are -X- _ O
unavailable. -X- _ O
We -X- _ O
also -X- _ O
do -X- _ O
not -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
racial -X- _ O
, -X- _ O
gender -X- _ O
, -X- _ O
and -X- _ O
age -X- _ O
disparity -X- _ O
( -X- _ O
Koenecke -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
availability -X- _ O
of -X- _ O
sufficiently -X- _ O
representative -X- _ O
and -X- _ O
inclusive -X- _ O
datasets. -X- _ O
It -X- _ O
is -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
to -X- _ O
be -X- _ O
expected -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
deteriorates -X- _ O
for -X- _ O
the -X- _ O
recordings -X- _ O
of -X- _ O
speakers -X- _ O
other -X- _ O
than -X- _ O
male -X- _ O
speakers -X- _ O
of -X- _ O
General -X- _ O
American -X- _ O
. -X- _ O

Conclusions -X- _ O
Our -X- _ O
work -X- _ O
provides -X- _ O
a -X- _ O
thorough -X- _ O
, -X- _ O
albeit -X- _ O
pessimistic -X- _ O
, -X- _ O
reality -X- _ O
check -X- _ O
on -X- _ O
the -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
in -X- _ O
conversational -X- _ O
transcripts. -X- _ O
Our -X- _ O
first -X- _ O
conclusion -X- _ O
is -X- _ O
straightforward -X- _ O
: -X- _ O
currently -X- _ O
available -X- _ O
NER -X- _ B-TaskName
models -X- _ O
are -X- _ O
not -X- _ O
trained -X- _ O
on -X- _ O
representative -X- _ O
data -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
annotated -X- _ O
datasets -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
their -X- _ O
performance -X- _ O
on -X- _ O
transcripts -X- _ O
of -X- _ O
spontaneous -X- _ O
conversations -X- _ O
is -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
their -X- _ O
performance -X- _ O
on -X- _ O
written -X- _ O
language. -X- _ O
Importantly -X- _ O
, -X- _ O
this -X- _ O
failure -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
attributed -X- _ O
solely -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
word -X- _ O
errors. -X- _ O
As -X- _ O
we -X- _ O
show -X- _ O
, -X- _ O
NER -X- _ B-TaskName
models -X- _ O
exhibit -X- _ O
very -X- _ O
high -X- _ O
entity -X- _ O
WERs -X- _ B-MetricName
even -X- _ O
on -X- _ O
gold -X- _ O
transcripts -X- _ O
, -X- _ O
where -X- _ O
no -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
are -X- _ O
present. -X- _ O
When -X- _ O
the -X- _ O
transcript -X- _ O
contains -X- _ O
ASR -X- _ B-TaskName
insertions -X- _ O
, -X- _ O
substitutions -X- _ O
, -X- _ O
or -X- _ O
deletions -X- _ O
, -X- _ O
the -X- _ O
entity -X- _ O
recognition -X- _ O
rates -X- _ O
fall -X- _ O
to -X- _ O
the -X- _ O
level -X- _ O
where -X- _ O
NER -X- _ B-TaskName
models -X- _ O
become -X- _ O
unusable -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
a -X- _ O
completely -X- _ O
new -X- _ O
approach -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
meaningfully -X- _ O
measure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
NER -X- _ O
models -X- _ O
on -X- _ O
conversational -X- _ O
transcripts. -X- _ O
Traditional -X- _ O
metrics -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
or -X- _ O
entity -X- _ O
WER -X- _ B-MetricName
do -X- _ O
not -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
intricate -X- _ O
interplay -X- _ O
of -X- _ O
factors -X- _ O
( -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
, -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
, -X- _ O
artifacts -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
) -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
provide -X- _ O
a -X- _ O
useful -X- _ O
insight -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
performance. -X- _ O
We -X- _ O
need -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
more -X- _ O
complex -X- _ O
evaluation -X- _ O
scheme -X- _ O
that -X- _ O
would -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
token -X- _ O
alignment -X- _ O
errors -X- _ O
, -X- _ O
partial -X- _ O
entity -X- _ O
span -X- _ O
matchings -X- _ O
, -X- _ O
ASR -X- _ B-TaskName
word -X- _ O
errors -X- _ O
, -X- _ O
and -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
. -X- _ O

Ethics -X- _ O
statement -X- _ O
Following -X- _ O
the -X- _ O
ACM -X- _ O
Code -X- _ O
of -X- _ O
Ethics -X- _ O
and -X- _ O
Professional -X- _ O
Conduct -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
ethical -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
work -X- _ O
presented -X- _ O
in -X- _ O
this -X- _ O
paper. -X- _ O
Our -X- _ O
work -X- _ O
aims -X- _ O
at -X- _ O
broadening -X- _ O
the -X- _ O
accessibility -X- _ O
of -X- _ O
communication -X- _ O
technology. -X- _ O
Spontaneous -X- _ O
spoken -X- _ O
language -X- _ O
is -X- _ O
the -X- _ O
least -X- _ O
limiting -X- _ O
and -X- _ O
exclusive -X- _ O
mode -X- _ O
of -X- _ O
interacting -X- _ O
with -X- _ O
an -X- _ O
information -X- _ O
system. -X- _ O
This -X- _ O
mode -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
any -X- _ O
digital -X- _ O
competencies -X- _ O
or -X- _ O
expensive -X- _ O
resources. -X- _ O
The -X- _ O
ability -X- _ O
to -X- _ O
correctly -X- _ O
process -X- _ O
spontaneous -X- _ O
human -X- _ O
conversations -X- _ O
opens -X- _ O
access -X- _ O
to -X- _ O
technology -X- _ O
to -X- _ O
stakeholders -X- _ O
who -X- _ O
might -X- _ O
have -X- _ O
been -X- _ O
previously -X- _ O
excluded. -X- _ O
We -X- _ O
strive -X- _ O
to -X- _ O
diminish -X- _ O
discrimination -X- _ O
resulting -X- _ O
from -X- _ O
biased -X- _ O
training -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
cause -X- _ O
specific -X- _ O
individuals -X- _ O
to -X- _ O
be -X- _ O
disproportionally -X- _ O
mistranscribed -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
accent -X- _ O
, -X- _ O
dialect -X- _ O
, -X- _ O
or -X- _ O
speech -X- _ O
impediments. -X- _ O
As -X- _ O
digital -X- _ O
voice -X- _ O
applications -X- _ O
become -X- _ O
increasingly -X- _ O
integrated -X- _ O
into -X- _ O
society -X- _ O
's -X- _ O
infrastructure -X- _ O
, -X- _ O
we -X- _ O
feel -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
statistical -X- _ O
models -X- _ O
processing -X- _ O
spoken -X- _ O
communications -X- _ O
continuously -X- _ O
. -X- _ O

The -X- _ O
ability -X- _ O
to -X- _ O
better -X- _ O
process -X- _ O
and -X- _ O
understand -X- _ O
spoken -X- _ O
human -X- _ O
conversations -X- _ O
carries -X- _ O
the -X- _ O
significant -X- _ O
ethical -X- _ O
risk -X- _ O
associated -X- _ O
with -X- _ O
clandestine -X- _ O
eavesdropping -X- _ O
by -X- _ O
adversarial -X- _ O
agents. -X- _ O
Correct -X- _ O
recognition -X- _ O
of -X- _ O
spoken -X- _ O
names -X- _ O
of -X- _ O
people -X- _ O
, -X- _ O
places -X- _ O
, -X- _ O
organizations -X- _ O
, -X- _ O
or -X- _ O
events -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
malevolently -X- _ O
used -X- _ O
by -X- _ O
authoritarian -X- _ O
government -X- _ O
agencies -X- _ O
trying -X- _ O
to -X- _ O
suppress -X- _ O
free -X- _ O
speech. -X- _ O
Recognition -X- _ O
of -X- _ O
names -X- _ O
of -X- _ O
products -X- _ O
or -X- _ O
services -X- _ O
may -X- _ O
be -X- _ O
utilized -X- _ O
by -X- _ O
marketers -X- _ O
for -X- _ O
non-consensual -X- _ O
profiling. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
best -X- _ O
interest -X- _ O
to -X- _ O
foster -X- _ O
public -X- _ O
awareness -X- _ O
and -X- _ O
understanding -X- _ O
of -X- _ O
computing -X- _ O
, -X- _ O
the -X- _ O
automatic -X- _ O
processing -X- _ O
of -X- _ O
spontaneous -X- _ O
speech -X- _ O
, -X- _ O
and -X- _ O
its -X- _ O
consequences -X- _ O
. -X- _ O

A -X- _ O
Examples -X- _ O
of -X- _ O
ASR-NLP -X- _ B-TaskName
errors -X- _ O
from -X- _ O
the -X- _ O
Earnings-21 -X- _ B-DatasetName
dataset -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
several -X- _ O
examples -X- _ O
of -X- _ O
alignments -X- _ O
of -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
with -X- _ O
entity -X- _ O
tags. -X- _ O
In -X- _ O
each -X- _ O
table -X- _ O
, -X- _ O
the -X- _ O
upper -X- _ O
two -X- _ O
rows -X- _ O
present -X- _ O
entity -X- _ O
tags -X- _ O
and -X- _ O
word -X- _ O
tokens -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
transcript -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
bottom -X- _ O
two -X- _ O
rows -X- _ O
present -X- _ O
word -X- _ O
tokens -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
ASR -X- _ O
and -X- _ O
entity -X- _ O
tags -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
NER -X- _ B-TaskName
model. -X- _ O
A -X- _ O
detailed -X- _ O
description -X- _ O
of -X- _ O
each -X- _ O
case -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
caption -X- _ O
of -X- _ O
each -X- _ O

Our -X- _ O
work -X- _ O
does -X- _ O
not -X- _ O
introduce -X- _ O
new -X- _ O
models -X- _ O
or -X- _ O
methods -X- _ O
but -X- _ O
provides -X- _ O
a -X- _ O
negative -X- _ O
reality -X- _ O
check -X- _ O
on -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
NER -X- _ B-TaskName
recognition -X- _ O
from -X- _ O
spoken -X- _ O
transcripts. -X- _ O
We -X- _ O
address -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
potential -X- _ O
risks -X- _ O
of -X- _ O
NER -X- _ B-TaskName
in -X- _ O
conversational -X- _ O
transcripts -X- _ O
in -X- _ O
Section -X- _ O
8 -X- _ O
Ethics -X- _ O
statement -X- _ O
. -X- _ O

C1. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
computational -X- _ O
budget -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPU -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
infrastructure -X- _ O
used -X- _ O
? -X- _ O
Although -X- _ O
we -X- _ O
have -X- _ O
experimented -X- _ O
with -X- _ O
several -X- _ O
NER -X- _ B-TaskName
model -X- _ O
architectures -X- _ O
, -X- _ O
our -X- _ O
contribution -X- _ O
is -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
SOTA -X- _ O
models. -X- _ O
Quite -X- _ O
the -X- _ O
contrary -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
negative -X- _ O
results -X- _ O
and -X- _ O
we -X- _ O
have -X- _ O
decided -X- _ O
to -X- _ O
omit -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
benchmark -X- _ O
model -X- _ O
training -X- _ O
to -X- _ O
focus -X- _ O
the -X- _ O
paper -X- _ O
on -X- _ O
the -X- _ O
presentation -X- _ O
of -X- _ O
a -X- _ O
much -X- _ O
more -X- _ O
important -X- _ O
aspect -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
the -X- _ O
deep -X- _ O
dive -X- _ O
into -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
errors -X- _ O
. -X- _ O

C2. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
including -X- _ O
hyperparameter -X- _ O
search -X- _ O
and -X- _ O
best-found -X- _ O
hyperparameter -X- _ O
values -X- _ O
? -X- _ O
As -X- _ O
above -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
experiments -X- _ O
only -X- _ O
serve -X- _ O
to -X- _ O
illustrate -X- _ O
a -X- _ O
much -X- _ O
more -X- _ O
important -X- _ O
and -X- _ O
overlooked -X- _ O
issue. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
find -X- _ O
the -X- _ O
particular -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
trained -X- _ O
NER -X- _ B-TaskName
model -X- _ O
important. -X- _ O
We -X- _ O
provide -X- _ O
the -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
training -X- _ O
dataset. -X- _ O
The -X- _ O
training -X- _ O
uses -X- _ O
default -X- _ O
values -X- _ O
of -X- _ O
hyper-parameters -X- _ O
. -X- _ O

C3. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
descriptive -X- _ O
statistics -X- _ O
about -X- _ O
your -X- _ O
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
error -X- _ O
bars -X- _ O
around -X- _ O
results -X- _ O
, -X- _ O
summary -X- _ O
statistics -X- _ O
from -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
it -X- _ O
transparent -X- _ O
whether -X- _ O
you -X- _ O
are -X- _ O
reporting -X- _ O
the -X- _ O
max -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
etc. -X- _ O
or -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
? -X- _ O
Our -X- _ O
experiments -X- _ O
involve -X- _ O
the -X- _ O
description -X- _ O
of -X- _ O
particularities -X- _ O
of -X- _ O
ASR-NER -X- _ B-TaskName
errors -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
of -X- _ O
each -X- _ O
error -X- _ O
combination -X- _ O
. -X- _ O

CrossSum -X- _ B-DatasetName
: -X- _ O
Beyond -X- _ B-MethodName
English-Centric -X- _ I-MethodName
Cross-Lingual -X- _ I-MethodName
Summarization -X- _ I-MethodName
for -X- _ O
1,500+ -X- _ O
Language -X- _ O
Pairs -X- _ O

We -X- _ O
present -X- _ O
CrossSum -X- _ B-DatasetName
, -X- _ O
a -X- _ O
large-scale -X- _ O
crosslingual -X- _ O
summarization -X- _ O
dataset -X- _ O
comprising -X- _ O
1.68 -X- _ O
million -X- _ O
article-summary -X- _ O
samples -X- _ O
in -X- _ O
1,500+ -X- _ O
language -X- _ O
pairs. -X- _ O
We -X- _ O
create -X- _ O
CrossSum -X- _ B-DatasetName
by -X- _ O
aligning -X- _ O
parallel -X- _ O
articles -X- _ O
written -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
via -X- _ O
cross-lingual -X- _ O
retrieval -X- _ O
from -X- _ O
a -X- _ O
multilingual -X- _ O
abstractive -X- _ O
summarization -X- _ O
dataset -X- _ O
and -X- _ O
perform -X- _ O
a -X- _ O
controlled -X- _ O
human -X- _ O
evaluation -X- _ O
to -X- _ O
validate -X- _ O
its -X- _ O
quality. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
multistage -X- _ O
data -X- _ O
sampling -X- _ O
algorithm -X- _ O
to -X- _ O
effectively -X- _ O
train -X- _ O
a -X- _ O
cross-lingual -X- _ B-TaskName
summarization -X- _ I-TaskName
model -X- _ O
capable -X- _ O
of -X- _ O
summarizing -X- _ O
an -X- _ O
article -X- _ O
in -X- _ O
any -X- _ O
target -X- _ O
language. -X- _ O
We -X- _ O
also -X- _ O
introduce -X- _ O
LaSE -X- _ B-MetricName
, -X- _ O
an -X- _ O
embedding-based -X- _ O
metric -X- _ O
for -X- _ O
automatically -X- _ O
evaluating -X- _ O
model-generated -X- _ O
summaries. -X- _ O
LaSE -X- _ B-MetricName
is -X- _ O
strongly -X- _ O
correlated -X- _ O
with -X- _ O
ROUGE -X- _ B-MetricName
and -X- _ O
, -X- _ O
unlike -X- _ O
ROUGE -X- _ B-MetricName
, -X- _ O
can -X- _ O
be -X- _ O
reliably -X- _ O
measured -X- _ O
even -X- _ O
in -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
references -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O
Performance -X- _ O
on -X- _ O
ROUGE -X- _ B-MetricName
and -X- _ O
LaSE -X- _ B-MetricName
indicate -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
consistently -X- _ O
outperforms -X- _ O
baseline -X- _ O
models. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
CrossSum -X- _ B-DatasetName
is -X- _ O
the -X- _ O
largest -X- _ O
cross-lingual -X- _ B-TaskName
summarization -X- _ I-TaskName
dataset -X- _ O
and -X- _ O
the -X- _ O
first -X- _ O
ever -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
centered -X- _ O
around -X- _ O
English. -X- _ O
We -X- _ O
are -X- _ O
releasing -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
scripts -X- _ O
, -X- _ O
and -X- _ O
models -X- _ O
to -X- _ O
spur -X- _ O
future -X- _ O
research -X- _ O
on -X- _ O
cross-lingual -X- _ B-TaskName
summarization. -X- _ I-TaskName
The -X- _ O
resources -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
csebuetnlp -X- _ O
/ -X- _ O
CrossSum -X- _ O
. -X- _ O

Introduction -X- _ O
Cross-lingual -X- _ B-TaskName
summarization -X- _ I-TaskName
( -X- _ O
hereinafter -X- _ O
XLS -X- _ B-TaskName
) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
generating -X- _ O
a -X- _ O
summary -X- _ O
in -X- _ O
a -X- _ O
target -X- _ O
language -X- _ O
given -X- _ O
a -X- _ O
source -X- _ O
text -X- _ O
in -X- _ O
another -X- _ O
language. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
challenging -X- _ O
as -X- _ O
it -X- _ O
combines -X- _ O
summarization -X- _ O
and -X- _ O
translation -X- _ O
in -X- _ O
one -X- _ O
task -X- _ O
, -X- _ O
both -X- _ O
challenging -X- _ O
tasks -X- _ O
in -X- _ O
their -X- _ O
own -X- _ O
right. -X- _ O
Earlier -X- _ O
approaches -X- _ O
to -X- _ O
XLS -X- _ B-TaskName
thus -X- _ O
employed -X- _ O
pipeline -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
translate-thensummarize -X- _ O
( -X- _ O
Leuski -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
and -X- _ O
summarizethen-translate -X- _ O
( -X- _ O
Wan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O
Not -X- _ O
only -X- _ O
are -X- _ O
they -X- _ O
computationally -X- _ O
expensive -X- _ O
, -X- _ O
having -X- _ O
to -X- _ O
use -X- _ O
multiple -X- _ O
* -X- _ O
These -X- _ O
authors -X- _ O
contributed -X- _ O
equally -X- _ O
to -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
A -X- _ O
sample -X- _ O
article-summary -X- _ O
pair -X- _ O
from -X- _ O
Cross-Sum -X- _ B-DatasetName
, -X- _ O
the -X- _ O
article -X- _ O
is -X- _ O
written -X- _ O
in -X- _ O
Japanese -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
summary -X- _ O
is -X- _ O
in -X- _ O
Bengali. -X- _ O
We -X- _ O
translate -X- _ O
the -X- _ O
texts -X- _ O
to -X- _ O
English -X- _ O
inside -X- _ O
parentheses -X- _ O
for -X- _ O
better -X- _ O
understanding. -X- _ O
Words -X- _ O
and -X- _ O
phrases -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
summary -X- _ O
are -X- _ O
color-coded. -X- _ O
models -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
approaches -X- _ O
also -X- _ O
suffer -X- _ O
from -X- _ O
errorpropagation -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
from -X- _ O
one -X- _ O
model -X- _ O
to -X- _ O
another -X- _ O
, -X- _ O
degrading -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
. -X- _ O

The -X- _ O
success -X- _ O
of -X- _ O
sequence-to-sequence -X- _ O
( -X- _ O
seq2seq -X- _ O
) -X- _ O
models -X- _ O
( -X- _ O
Cho -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Sutskever -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
advances -X- _ O
in -X- _ O
Transformer-based -X- _ O
models -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
have -X- _ O
aided -X- _ O
in -X- _ O
the -X- _ O
emergence -X- _ O
of -X- _ O
end-to-end -X- _ O
methods -X- _ O
that -X- _ O
can -X- _ O
perform -X- _ O
XLS -X- _ B-TaskName
with -X- _ O
one -X- _ O
single -X- _ O
model -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
availability -X- _ O
of -X- _ O
XLS -X- _ B-TaskName
datasets -X- _ O
( -X- _ O
Ladhak -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Perez-Beltrachini -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
also -X- _ O
helped -X- _ O
this -X- _ O
task -X- _ O
gain -X- _ O
popularity -X- _ O
in -X- _ O
recent -X- _ O
times. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
cover -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
languages -X- _ O
, -X- _ O
contain -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
, -X- _ O
or -X- _ O
use -X- _ O
English -X- _ O
as -X- _ O
the -X- _ O
pivot -X- _ O
language -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
always -X- _ O
remains -X- _ O
English -X- _ O
) -X- _ O
, -X- _ O
thereby -X- _ O
limiting -X- _ O
their -X- _ O
applicability -X- _ O
to -X- _ O
a -X- _ O
great -X- _ O
extent -X- _ O
. -X- _ O

To -X- _ O
democratize -X- _ O
XLS -X- _ B-TaskName
beyond -X- _ O
high-resource -X- _ O
languages -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
CrossSum -X- _ B-DatasetName
, -X- _ O
a -X- _ O
large-scale -X- _ O
XLS -X- _ B-TaskName
dataset -X- _ O
containing -X- _ O
1.68 -X- _ O
million -X- _ O
article-summary -X- _ O
samples -X- _ O
in -X- _ O
1,500+ -X- _ O
language -X- _ O
pairs. -X- _ O
We -X- _ O
align -X- _ O
parallel -X- _ O
articles -X- _ O
1 -X- _ O
written -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
via -X- _ O
cross-lingual -X- _ O
retrieval -X- _ O
from -X- _ O
the -X- _ O
multilingual -X- _ O
XL-Sum -X- _ B-TaskName
( -X- _ O
Hasan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
dataset. -X- _ O
We -X- _ O
introduce -X- _ O
and -X- _ O
rigorously -X- _ O
study -X- _ O
the -X- _ O
notions -X- _ O
'induced -X- _ O
pairs -X- _ O
' -X- _ O
and -X- _ O
'implicit -X- _ O
leakage -X- _ O
' -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
coverage -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
while -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
ensuring -X- _ O
maximum -X- _ O
quality. -X- _ O
We -X- _ O
also -X- _ O
perform -X- _ O
a -X- _ O
controlled -X- _ O
human -X- _ O
evaluation -X- _ O
of -X- _ O
CrossSum -X- _ B-DatasetName
spanning -X- _ O
nine -X- _ O
languages -X- _ O
from -X- _ O
high-to -X- _ O
low-resource -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
alignments -X- _ O
are -X- _ O
highly -X- _ O
accurate -X- _ O
. -X- _ O

We -X- _ O
design -X- _ O
MLS -X- _ B-MethodName
, -X- _ O
a -X- _ O
multistage -X- _ O
language -X- _ O
sampling -X- _ O
algorithm -X- _ O
, -X- _ O
for -X- _ O
successfully -X- _ O
training -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
generate -X- _ O
a -X- _ O
summary -X- _ O
in -X- _ O
any -X- _ O
target -X- _ O
language -X- _ O
for -X- _ O
an -X- _ O
input -X- _ O
article -X- _ O
in -X- _ O
any -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
both -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
languages -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
dataset. -X- _ O
For -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
XLS -X- _ B-TaskName
with -X- _ O
CrossSum -X- _ B-DatasetName
on -X- _ O
a -X- _ O
broad -X- _ O
and -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
languages -X- _ O
without -X- _ O
relying -X- _ O
on -X- _ O
English -X- _ O
as -X- _ O
the -X- _ O
standalone -X- _ O
pivot -X- _ O
, -X- _ O
consistently -X- _ O
outperforming -X- _ O
many-to-one -X- _ O
and -X- _ O
one-to-many -X- _ O
models -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
summarize-then-translate -X- _ O
baselines -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
LaSE -X- _ B-MetricName
, -X- _ O
an -X- _ O
embedding-based -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
summaries -X- _ O
when -X- _ O
reference -X- _ O
summaries -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
but -X- _ O
may -X- _ O
be -X- _ O
available -X- _ O
in -X- _ O
another -X- _ O
language -X- _ O
, -X- _ O
potentially -X- _ O
opening -X- _ O
new -X- _ O
doors -X- _ O
for -X- _ O
evaluating -X- _ O
lowresource -X- _ O
languages. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
LaSE -X- _ B-MetricName
by -X- _ O
its -X- _ O
high -X- _ O
correlation -X- _ O
with -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
de-facto -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
text -X- _ O
summarization -X- _ O
systems -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
CrossSum -X- _ B-DatasetName
is -X- _ O
the -X- _ O
largest -X- _ O
publicly -X- _ O
available -X- _ O
abdtractive -X- _ O
XLS -X- _ B-TaskName
dataset -X- _ O
, -X- _ O
both -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
language -X- _ O
pairs. -X- _ O
We -X- _ O
are -X- _ O
releasing -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
scripts -X- _ O
, -X- _ O
and -X- _ O
models -X- _ O
hoping -X- _ O
that -X- _ O
these -X- _ O
resources -X- _ O
will -X- _ O
encourage -X- _ O
the -X- _ O
community -X- _ O
to -X- _ O
push -X- _ O
the -X- _ O
boundaries -X- _ O
of -X- _ O
XLS -X- _ B-TaskName
beyond -X- _ O
English -X- _ O
and -X- _ O
other -X- _ O
high-resource -X- _ O
languages -X- _ O
. -X- _ O

The -X- _ O
CrossSum -X- _ B-DatasetName
Dataset -X- _ O
The -X- _ O
most -X- _ O
straightforward -X- _ O
way -X- _ O
of -X- _ O
curating -X- _ O
a -X- _ O
highquality -X- _ O
XLS -X- _ B-TaskName
dataset -X- _ O
is -X- _ O
via -X- _ O
crowd-sourcing -X- _ O
( -X- _ O
Nguyen -X- _ O
and -X- _ O
Daumé -X- _ O
III -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
difficult -X- _ O
to -X- _ O
find -X- _ O
crowd -X- _ O
workers -X- _ O
having -X- _ O
professional -X- _ O
command -X- _ O
over -X- _ O
low-resource -X- _ O
languages -X- _ O
or -X- _ O
distant -X- _ O
language -X- _ O
pairs. -X- _ O
Moreover -X- _ O
, -X- _ O
scalability -X- _ O
issues -X- _ O
might -X- _ O
arise -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
time -X- _ O
and -X- _ O
budget -X- _ O
constraints -X- _ O
for -X- _ O
1 -X- _ O
We -X- _ O
re-purpose -X- _ O
the -X- _ O
terminology -X- _ O
of -X- _ O
parallel -X- _ O
corpus -X- _ O
here. -X- _ O
crowd-sourcing. -X- _ O
Therefore -X- _ O
, -X- _ O
synthetic -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
automatic -X- _ O
methods -X- _ O
( -X- _ O
Ladhak -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Perez-Beltrachini -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
gained -X- _ O
traction -X- _ O
over -X- _ O
crowd-sourcing -X- _ O
. -X- _ O

Automatic -X- _ O
curation -X- _ O
of -X- _ O
an -X- _ O
XLS -X- _ B-TaskName
dataset -X- _ O
is -X- _ O
simply -X- _ O
to -X- _ O
pair -X- _ O
an -X- _ O
article -X- _ O
A -X- _ O
in -X- _ O
a -X- _ O
source -X- _ O
language -X- _ O
with -X- _ O
the -X- _ O
summary -X- _ O
of -X- _ O
a -X- _ O
parallel -X- _ O
article -X- _ O
B -X- _ O
written -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
assuming -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
a -X- _ O
multilingual -X- _ O
dataset -X- _ O
having -X- _ O
identical -X- _ O
contents -X- _ O
in -X- _ O
different -X- _ O
languages. -X- _ O
Two -X- _ O
contemporary -X- _ O
works -X- _ O
have -X- _ O
compiled -X- _ O
large-scale -X- _ O
multilingual -X- _ O
summarization -X- _ O
datasets -X- _ O
, -X- _ O
namely -X- _ O
XL-Sum -X- _ B-DatasetName
( -X- _ O
Hasan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
1.35M -X- _ O
samples -X- _ O
in -X- _ O
45 -X- _ O
languages -X- _ O
) -X- _ O
and -X- _ O
MassiveSumm -X- _ O
( -X- _ O
Varab -X- _ O
and -X- _ O
Schluter -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
28.8M -X- _ O
samples -X- _ O
in -X- _ O
92 -X- _ O
languages -X- _ O
) -X- _ O
. -X- _ O
Though -X- _ O
substantially -X- _ O
larger -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
, -X- _ O
MassiveSumm -X- _ B-DatasetName
is -X- _ O
not -X- _ O
publicly -X- _ O
available. -X- _ O
Since -X- _ O
public -X- _ O
availability -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
promoting -X- _ O
open -X- _ O
research -X- _ O
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
XL-Sum -X- _ B-DatasetName
, -X- _ O
distributed -X- _ O
under -X- _ O
a -X- _ O
non-commercial -X- _ O
license. -X- _ O
Additionally -X- _ O
, -X- _ O
all -X- _ O
articles -X- _ O
of -X- _ O
XL-Sum -X- _ B-DatasetName
are -X- _ O
crawled -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
source -X- _ O
, -X- _ O
BBC -X- _ O
News. -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
BBC -X- _ O
publishes -X- _ O
similar -X- _ O
news -X- _ O
content -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
and -X- _ O
follow -X- _ O
similar -X- _ O
summarization -X- _ O
strategies. -X- _ O
Hence -X- _ O
adopting -X- _ O
XL-Sum -X- _ B-DatasetName
would -X- _ O
increase -X- _ O
the -X- _ O
quality -X- _ O
and -X- _ O
quantity -X- _ O
of -X- _ O
the -X- _ O
article-summary -X- _ O
pairs -X- _ O
. -X- _ O

Unlike -X- _ O
previous -X- _ O
automatic -X- _ O
methods -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
explicit -X- _ O
links -X- _ O
between -X- _ O
parallel -X- _ O
articles -X- _ O
in -X- _ O
XL-Sum. -X- _ B-DatasetName
Fortunately -X- _ O
, -X- _ O
language-agnostic -X- _ O
sentence -X- _ O
representations -X- _ O
( -X- _ O
Artetxe -X- _ O
and -X- _ O
Schwenk -X- _ O
, -X- _ O
2019a -X- _ O
; -X- _ O
Feng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
have -X- _ O
achieved -X- _ O
state-of-the-art -X- _ O
results -X- _ O
in -X- _ O
crosslingual -X- _ O
text -X- _ O
mining -X- _ O
( -X- _ O
Artetxe -X- _ O
and -X- _ O
Schwenk -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
hence -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
search -X- _ O
identical -X- _ O
contents -X- _ O
across -X- _ O
languages. -X- _ O
For -X- _ O
simplicity -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
the -X- _ O
search -X- _ O
over -X- _ O
summaries -X- _ O
only. -X- _ O
To -X- _ O
ensure -X- _ O
maximum -X- _ O
quality -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
two -X- _ O
conditions -X- _ O
for -X- _ O
a -X- _ O
summary -X- _ O
S -X- _ O
A -X- _ O
in -X- _ O
language -X- _ O
A -X- _ O
to -X- _ O
be -X- _ O
aligned -X- _ O
with -X- _ O
another -X- _ O
summary -X- _ O
S -X- _ O
B -X- _ O
in -X- _ O
language -X- _ O
B -X- _ O
: -X- _ O

1. -X- _ O
S -X- _ O
B -X- _ O
must -X- _ O
be -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
of -X- _ O
S -X- _ O
A -X- _ O
among -X- _ O
all -X- _ O
summaries -X- _ O
in -X- _ O
B -X- _ O
, -X- _ O
and -X- _ O
vice-versa. -X- _ O
2. -X- _ O
The -X- _ O
similarity -X- _ O
between -X- _ O
S -X- _ O
A -X- _ O
and -X- _ O
S -X- _ O
B -X- _ O
must -X- _ O
be -X- _ O
above -X- _ O
the -X- _ O
threshold -X- _ O
, -X- _ O
τ -X- _ B-HyperparameterName
. -X- _ O
The -X- _ O
similarity -X- _ O
of -X- _ O
a -X- _ O
summary -X- _ O
pair -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
inner -X- _ O
product -X- _ O
of -X- _ O
their -X- _ O
Language-agnostic -X- _ O
BERT -X- _ O
Sentence -X- _ O
Embeddings -X- _ O
( -X- _ O
LaBSE -X- _ O
) -X- _ O
( -X- _ O
Feng -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
( -X- _ O
a -X- _ O
unit -X- _ O
vector -X- _ O
for -X- _ O
an -X- _ O
input -X- _ O
text -X- _ O
sequence -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
empirically -X- _ O
set -X- _ O
the -X- _ O
similarity -X- _ O
threshold -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
over -X- _ O
all -X- _ O
languages -X- _ O
that -X- _ O
maximized -X- _ O
their -X- _ O
respective -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
score -X- _ O
( -X- _ O
τ -X- _ B-HyperparameterName
= -X- _ O
0.7437 -X- _ B-HyperparameterValue
) -X- _ O
in -X- _ O
the -X- _ O
BUCC -X- _ O
mining -X- _ O
tasks -X- _ O
( -X- _ O
Zweigenbaum -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
Training -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
respecting -X- _ O
the -X- _ O
original -X- _ O
XL-Sum -X- _ B-DatasetName
splits -X- _ O
causes -X- _ O
unusually -X- _ O
high -X- _ O
ROUGE -X- _ B-HyperparameterName
scores -X- _ O
( -X- _ O
marked -X- _ O
red -X- _ O
) -X- _ O
in -X- _ O
many-to-one -X- _ O
models -X- _ O
due -X- _ O
to -X- _ O
implicit -X- _ O
data -X- _ O
leakage. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
redid -X- _ O
the -X- _ O
splits -X- _ O
taking -X- _ O
the -X- _ O
issue -X- _ O
into -X- _ O
account -X- _ O
, -X- _ O
and -X- _ O
consequently -X- _ O
, -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
set -X- _ O
( -X- _ O
marked -X- _ O
blue -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
exhibit -X- _ O
any -X- _ O
unusual -X- _ O
spike -X- _ O
. -X- _ O

Induced -X- _ O
Pairs -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
many -X- _ O
summary -X- _ O
pairs -X- _ O
, -X- _ O
despite -X- _ O
being -X- _ O
nearest -X- _ O
neighbors -X- _ O
in -X- _ O
their -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
were -X- _ O
filtered -X- _ O
out -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
threshold -X- _ O
τ -X- _ B-HyperparameterName
. -X- _ O
Although -X- _ O
interestingly -X- _ O
, -X- _ O
both -X- _ O
were -X- _ O
aligned -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
summary -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
language. -X- _ O
Moreover -X- _ O
, -X- _ O
these -X- _ O
pairs -X- _ O
are -X- _ O
prevalent -X- _ O
if -X- _ O
their -X- _ O
languages -X- _ O
are -X- _ O
distant -X- _ O
or -X- _ O
low-resource. -X- _ O
LaBSE -X- _ B-MethodName
uses -X- _ O
contrastive -X- _ O
learning -X- _ O
( -X- _ O
Guo -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
to -X- _ O
rank -X- _ O
parallel -X- _ O
sentences -X- _ O
over -X- _ O
non-parallels -X- _ O
. -X- _ O

Since -X- _ O
parallel -X- _ O
pairs -X- _ O
are -X- _ O
mostly -X- _ O
found -X- _ O
for -X- _ O
highresource -X- _ O
and -X- _ O
linguistically -X- _ O
close -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
LaBSE -X- _ B-MethodName
fails -X- _ O
to -X- _ O
assign -X- _ O
high -X- _ O
similarity -X- _ O
to -X- _ O
sentences -X- _ O
from -X- _ O
languages -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
. -X- _ O

To -X- _ O
include -X- _ O
these -X- _ O
pairs -X- _ O
into -X- _ O
CrossSum -X- _ B-DatasetName
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
notion -X- _ O
'induced -X- _ O
pairs. -X- _ O
' -X- _ O
Formally -X- _ O
, -X- _ O
two -X- _ O
summaries -X- _ O
S -X- _ O
A -X- _ O
, -X- _ O
S -X- _ O
B -X- _ O
in -X- _ O
languages -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
are -X- _ O
induced -X- _ O
pairs -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
nearest -X- _ O
neighbors -X- _ O
of -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
their -X- _ O
similarity -X- _ O
score -X- _ O
is -X- _ O
below -X- _ O
τ -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
both -X- _ O
are -X- _ O
aligned -X- _ O
with -X- _ O
S -X- _ O
C -X- _ O
in -X- _ O
language -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
through -X- _ O
a -X- _ O
chain -X- _ O
of -X- _ O
aligned -X- _ O
pairs -X- _ O

We -X- _ O
thus -X- _ O
incorporate -X- _ O
the -X- _ O
induced -X- _ O
pairs -X- _ O
into -X- _ O
Cross-Sum -X- _ B-DatasetName
through -X- _ O
a -X- _ O
simple -X- _ O
graph-based -X- _ O
algorithm. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
all -X- _ O
summaries -X- _ O
as -X- _ O
vertices -X- _ O
in -X- _ O
a -X- _ O
graph -X- _ O
and -X- _ O
draw -X- _ O
an -X- _ O
edge -X- _ O
between -X- _ O
two -X- _ O
vertices -X- _ O
if -X- _ O
the -X- _ O
summaries -X- _ O
are -X- _ O
aligned. -X- _ O
Then -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
connected -X- _ O
components -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
and -X- _ O
draw -X- _ O
edges -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
induced -X- _ O
pairs -X- _ O
) -X- _ O
between -X- _ O
all -X- _ O
vertices -X- _ O
in -X- _ O
a -X- _ O
component. -X- _ O
Again -X- _ O
to -X- _ O
ensure -X- _ O
quality -X- _ O
, -X- _ O
before -X- _ O
computing -X- _ O
the -X- _ O
induced -X- _ O
pairs -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
max-flow -X- _ O
min-cut -X- _ O
theorem -X- _ O
( -X- _ O
Dantzig -X- _ O
and -X- _ O
Fulkerson -X- _ O
, -X- _ O
1955 -X- _ O
) -X- _ O
considering -X- _ O
the -X- _ O
similarity -X- _ O
scores -X- _ O
as -X- _ O
edge -X- _ O
weights -X- _ O
to -X- _ O
limit -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
vertices -X- _ O
( -X- _ O
since -X- _ O
ideally -X- _ O
, -X- _ O
a -X- _ O
component -X- _ O
should -X- _ O
have -X- _ O
at -X- _ O
most -X- _ O
45 -X- _ B-HyperparameterValue
vertices -X- _ O
, -X- _ O
one -X- _ O
summary -X- _ O
from -X- _ O
each -X- _ O
language -X- _ O
) -X- _ O
and -X- _ O
set -X- _ O
their -X- _ O
minimum -X- _ O
acceptance -X- _ O
threshold -X- _ O
to -X- _ O
τ -X- _ B-HyperparameterName
′ -X- _ O
← -X- _ O
τ -X- _ B-HyperparameterName
− -X- _ O
0.10. -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
assess -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
alignments -X- _ O
using -X- _ O
human -X- _ O
evaluation -X- _ O
. -X- _ O

We -X- _ O
finally -X- _ O
assembled -X- _ O
the -X- _ O
originally -X- _ O
aligned -X- _ O
pairs -X- _ O
and -X- _ O
induced -X- _ O
pairs -X- _ O
to -X- _ O
create -X- _ O
the -X- _ O
CrossSum -X- _ B-DatasetName
dataset. -X- _ O
Figure -X- _ O
6 -X- _ O
( -X- _ O
Appendix -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
article-summary -X- _ O
statistics -X- _ O
for -X- _ O
all -X- _ O
language -X- _ O
pairs -X- _ O
in -X- _ O
CrossSum. -X- _ B-DatasetName
As -X- _ O
evident -X- _ O
from -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
CrossSum -X- _ B-DatasetName
is -X- _ O
not -X- _ O
centered -X- _ O
only -X- _ O
around -X- _ O
the -X- _ O
English -X- _ O
language -X- _ O
but -X- _ O
rather -X- _ O
distributed -X- _ O
across -X- _ O
multiple -X- _ O
languages -X- _ O
. -X- _ O

Implicit -X- _ O
Leakage -X- _ O
We -X- _ O
initially -X- _ O
made -X- _ O
the -X- _ O
traindev-test -X- _ O
splits -X- _ O
respecting -X- _ O
the -X- _ O
original -X- _ O
XL-Sum -X- _ B-DatasetName
splits -X- _ O
and -X- _ O
performed -X- _ O
an -X- _ O
initial -X- _ O
assessment -X- _ O
of -X- _ O
Cross-Sum -X- _ B-DatasetName
by -X- _ O
training -X- _ O
a -X- _ O
many-to-one -X- _ O
model -X- _ O
( -X- _ O
articles -X- _ O
written -X- _ O
in -X- _ O
any -X- _ O
source -X- _ O
language -X- _ O
being -X- _ O
summarized -X- _ O
into -X- _ O
one -X- _ O
target -X- _ O
language -X- _ O
) -X- _ O
. -X- _ O
Upon -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
very -X- _ O
high -X- _ O
ROUGE-2 -X- _ B-MetricName
scores -X- _ O
( -X- _ O
around -X- _ O
40 -X- _ O
) -X- _ O
for -X- _ O
many -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
even -X- _ O
reaching -X- _ O
as -X- _ O
high -X- _ O
as -X- _ O
60 -X- _ O
for -X- _ O
some -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
Hasan -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
reported -X- _ O
ROUGE-2 -X- _ B-MetricName
in -X- _ O
the -X- _ O
10-20 -X- _ O
range -X- _ O
for -X- _ O
the -X- _ O
multilingual -X- _ O
summarization -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
inspected -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
many -X- _ O
summaries -X- _ O
were -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
references. -X- _ O
Through -X- _ O
closer -X- _ O
inspection -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
their -X- _ O
corresponding -X- _ O
articles -X- _ O
had -X- _ O
a -X- _ O
parallel -X- _ O
counterpart -X- _ O
occurring -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
in -X- _ O
some -X- _ O
other -X- _ O
language -X- _ O
. -X- _ O

During -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
parallel -X- _ O
articles -X- _ O
( -X- _ O
albeit -X- _ O
written -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
) -X- _ O
and -X- _ O
generate -X- _ O
the -X- _ O
same -X- _ O
output -X- _ O
by -X- _ O
memorizing -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
sample. -X- _ O
While -X- _ O
models -X- _ O
should -X- _ O
undoubtedly -X- _ O
be -X- _ O
credited -X- _ O
for -X- _ O
being -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
these -X- _ O
cross-lingual -X- _ O
mappings -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
ideal -X- _ O
for -X- _ O
benchmarking -X- _ O
purposes -X- _ O
as -X- _ O
this -X- _ O
creates -X- _ O
unusually -X- _ O
high -X- _ O
ROUGE -X- _ B-MetricName
scores. -X- _ O
We -X- _ O
denote -X- _ O
this -X- _ O
phenomenon -X- _ O
as -X- _ O
'implicit -X- _ O
leakage -X- _ O
' -X- _ O
and -X- _ O
make -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
split -X- _ O
to -X- _ O
avoid -X- _ O
this. -X- _ O
Before -X- _ O
proceeding -X- _ O
, -X- _ O
we -X- _ O
deduplicate -X- _ O
the -X- _ O
XL-Sum -X- _ B-DatasetName
dataset -X- _ O
4 -X- _ O
using -X- _ O
semantic -X- _ O
similarity -X- _ O
, -X- _ O
considering -X- _ O
two -X- _ O
summaries -X- _ O
S -X- _ O
A -X- _ O
, -X- _ O
S -X- _ O
′ -X- _ O
A -X- _ O
in -X- _ O
language -X- _ O
A -X- _ O
to -X- _ O
be -X- _ O
duplicates -X- _ O
of -X- _ O
one -X- _ O
another -X- _ O
if -X- _ O
their -X- _ O
LaBSE -X- _ B-MethodName
representations -X- _ O
have -X- _ O
similarity -X- _ O
above -X- _ O
0.95. -X- _ O
We -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
component -X- _ O
graph -X- _ O
mentioned -X- _ O
previously -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
leakage -X- _ O
and -X- _ O
assign -X- _ O
all -X- _ O
article-summary -X- _ O
pairs -X- _ O
originating -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
( -X- _ O
dev -X- _ O
/ -X- _ O
test -X- _ O
) -X- _ O
set -X- _ O
of -X- _ O
CrossSum -X- _ B-DatasetName
, -X- _ O
creating -X- _ O
an -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
-10 -X- _ I-HyperparameterValue
% -X- _ I-HyperparameterValue
-10 -X- _ I-HyperparameterValue
% -X- _ I-HyperparameterValue
split -X- _ B-HyperparameterName
for -X- _ O
all -X- _ O
language -X- _ O
pairs. -X- _ O
Since -X- _ O
parallel -X- _ O
articles -X- _ O
no -X- _ O
longer -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
one -X- _ O
and -X- _ O
the -X- _ O
dev -X- _ O
/ -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
another -X- _ O
, -X- _ O
the -X- _ O
leakage -X- _ O
is -X- _ O
not -X- _ O
observed -X- _ O
anymore -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
validated -X- _ O
this -X- _ O
by -X- _ O
inspecting -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
and -X- _ O
found -X- _ O
no -X- _ O
exact -X- _ O
copies -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
of -X- _ O
CrossSum -X- _ B-DatasetName
To -X- _ O
establish -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
our -X- _ O
automatic -X- _ O
alignment -X- _ O
pipeline -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
a -X- _ O
human -X- _ O
evaluation -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
alignments -X- _ O
. -X- _ O

We -X- _ O
selected -X- _ O
all -X- _ O
possible -X- _ O
combinations -X- _ O
of -X- _ O
language -X- _ O
pairs -X- _ O
from -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
nine -X- _ O
languages -X- _ O
ranging -X- _ O
from -X- _ O
high-resource -X- _ O
to -X- _ O
low-resource -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
alignment -X- _ O
quality -X- _ O
in -X- _ O
different -X- _ O
pair -X- _ O
configurations -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
high-high -X- _ O
, -X- _ O
low-high -X- _ O
, -X- _ O
low-low -X- _ O
) -X- _ O
as -X- _ O
per -X- _ O
the -X- _ O
language -X- _ O
diversity -X- _ O
categorization -X- _ O
by -X- _ O
Joshi -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
chose -X- _ O
three -X- _ O
high-resource -X- _ O
languages -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
Arabic -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
simplified -X- _ O
) -X- _ O
Chinese -X- _ O
( -X- _ O
categories -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
) -X- _ O
; -X- _ O
three -X- _ O
mid-resource -X- _ O
languages -X- _ O
, -X- _ O
Indonesian -X- _ O
, -X- _ O
Bengali -X- _ O
, -X- _ O
and -X- _ O
Urdu -X- _ O
( -X- _ O
category -X- _ O
3 -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
three -X- _ O
low-resource -X- _ O
languages -X- _ O
, -X- _ O
Punjabi -X- _ O
, -X- _ O
Swahili -X- _ O
, -X- _ O
and -X- _ O
Pashto -X- _ O
( -X- _ O
categories -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
representative -X- _ O
languages -X- _ O
and -X- _ O
randomly -X- _ O
sampled -X- _ O
fifty -X- _ O
cross-lingual -X- _ O
summary -X- _ O
alignments -X- _ O
from -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
for -X- _ O
annotation. -X- _ O
As -X- _ O
a -X- _ O
direct -X- _ O
evaluation -X- _ O
of -X- _ O
these -X- _ O
pairs -X- _ O
would -X- _ O
require -X- _ O
bilinguallyproficient -X- _ O
annotators -X- _ O
for -X- _ O
both -X- _ O
languages -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
practically -X- _ O
intractable -X- _ O
for -X- _ O
distantly -X- _ O
related -X- _ O
languages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Bengali-Swahili -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
resorted -X- _ O
to -X- _ O
a -X- _ O
pivoting -X- _ O
approach -X- _ O
during -X- _ O
annotation -X- _ O
for -X- _ O
language -X- _ O
pairs -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
contain -X- _ O
English. -X- _ O
For -X- _ O
a -X- _ O
language -X- _ O
pair -X- _ O
( -X- _ O
l -X- _ O
1 -X- _ O
− -X- _ O
l -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
l -X- _ O
1 -X- _ O
̸ -X- _ O
= -X- _ O
en -X- _ O
and -X- _ O
l -X- _ O
2 -X- _ O
̸ -X- _ O
= -X- _ O
en -X- _ O
, -X- _ O
we -X- _ O
sampled -X- _ O
alignments -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
such -X- _ O
that -X- _ O
∃ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
e -X- _ O
) -X- _ O
∈ -X- _ O
( -X- _ O
l -X- _ O
1 -X- _ O
−en -X- _ O
) -X- _ O
and -X- _ O
∃ -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
e -X- _ O
) -X- _ O
∈ -X- _ O
( -X- _ O
l -X- _ O
2 -X- _ O
− -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
an -X- _ O
English -X- _ O
article -X- _ O
e. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
ensure -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
articles -X- _ O
of -X- _ O
the -X- _ O
sampled -X- _ O
cross-lingual -X- _ O
pair -X- _ O
have -X- _ O
a -X- _ O
corresponding -X- _ O
cross-lingual -X- _ O
pair -X- _ O
with -X- _ O
an -X- _ O
English -X- _ O
article. -X- _ O
An -X- _ O
alignment -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
would -X- _ O
be -X- _ O
deemed -X- _ O
correct -X- _ O
if -X- _ O
both -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
e -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
e -X- _ O
) -X- _ O
are -X- _ O
correct. -X- _ O
This -X- _ O
formulation -X- _ O
thus -X- _ O
reduced -X- _ O
the -X- _ O
original -X- _ O
problem -X- _ O
to -X- _ O
annotating -X- _ O
samples -X- _ O
from -X- _ O
language -X- _ O
pairs -X- _ O
( -X- _ O
l -X- _ O
1 -X- _ O
− -X- _ O
en -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
l -X- _ O
2 -X- _ O
− -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
l -X- _ O
1 -X- _ O
and -X- _ O
l -X- _ O
2 -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
previously -X- _ O
selected -X- _ O
languages -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
English -X- _ O
. -X- _ O

We -X- _ O
hired -X- _ O
bilingually -X- _ O
proficient -X- _ O
expert -X- _ O
annotators -X- _ O
adept -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
interest -X- _ O
and -X- _ O
English. -X- _ O
Two -X- _ O
annotators -X- _ O
labeled -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
where -X- _ O
one -X- _ O
language -X- _ O
is -X- _ O
English. -X- _ O
We -X- _ O
presented -X- _ O
them -X- _ O
with -X- _ O
corresponding -X- _ O
summaries -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
pairs -X- _ O
( -X- _ O
and -X- _ O
optionally -X- _ O
the -X- _ O
articles -X- _ O
themselves -X- _ O
) -X- _ O
and -X- _ O
elicited -X- _ O
yes -X- _ O
/ -X- _ O
no -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
: -X- _ O
" -X- _ O
Can -X- _ O
the -X- _ O
provided -X- _ O
sequences -X- _ O
be -X- _ O
considered -X- _ O
summaries -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
article -X- _ O
? -X- _ O
" -X- _ O
5 -X- _ O
We -X- _ O
deem -X- _ O
a -X- _ O
sequence -X- _ O
pair -X- _ O
accurate -X- _ O
if -X- _ O
both -X- _ O
annotators -X- _ O
judge -X- _ O
it -X- _ O
as -X- _ O
valid. -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
alignment -X- _ O
accuracies -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
pairs -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

As -X- _ O
evident -X- _ O
from -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
judge -X- _ O
the -X- _ O
aligned -X- _ O
summaries -X- _ O
to -X- _ O
be -X- _ O
highly -X- _ O
accurate -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
95.67 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
used -X- _ O
Cohen -X- _ B-MetricName
's -X- _ I-MetricName
Kappa -X- _ I-MetricName
( -X- _ O
Cohen -X- _ O
, -X- _ O
1960 -X- _ O
) -X- _ O
to -X- _ O
establish -X- _ O
the -X- _ O
interannotator -X- _ O
agreement -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
corresponding -X- _ O
statistics -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

Multistage -X- _ B-HyperparameterName
Language -X- _ I-HyperparameterName
Sampling -X- _ I-HyperparameterName
( -X- _ O
MLS -X- _ B-HyperparameterName
) -X- _ O
From -X- _ O
Figure -X- _ O
6 -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
CrossSum -X- _ B-DatasetName
is -X- _ O
heavily -X- _ O
imbalanced. -X- _ O
Thus -X- _ O
, -X- _ O
training -X- _ O
directly -X- _ O
without -X- _ O
upsampling -X- _ O
low-resource -X- _ O
languages -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
their -X- _ O
degraded -X- _ O
performance. -X- _ O
Conneau -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
used -X- _ O
probability -X- _ O
smoothing -X- _ O
for -X- _ O
upsampling -X- _ O
in -X- _ O
multilingual -X- _ O
pretraining -X- _ O
and -X- _ O
sampled -X- _ O
all -X- _ O
examples -X- _ O
of -X- _ O
a -X- _ O
batch -X- _ O
from -X- _ O
one -X- _ O
language. -X- _ O
However -X- _ O
, -X- _ O
extending -X- _ O
this -X- _ O
technique -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
pairs -X- _ O
in -X- _ O
CrossSum -X- _ B-DatasetName
would -X- _ O
result -X- _ O
in -X- _ O
many -X- _ O
batches -X- _ O
having -X- _ O
repeated -X- _ O
samples -X- _ O
as -X- _ O
many -X- _ O
language -X- _ O
pairs -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
enough -X- _ O
training -X- _ O
samples -X- _ O
in -X- _ O
total -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
batch -X- _ O
sizes -X- _ O
used -X- _ O
in -X- _ O
practice -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Conneau -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
used -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
exceeds -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
nearly -X- _ O
1,000 -X- _ B-HyperparameterValue
language -X- _ O
pairs -X- _ O
in -X- _ O
CrossSum -X- _ B-DatasetName
) -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
many -X- _ O
language -X- _ O
pairs -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
sampled -X- _ O
during -X- _ O
training -X- _ O
for -X- _ O
lack -X- _ O
of -X- _ O
enough -X- _ O
training -X- _ O
steps -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
our -X- _ O
constraints -X- _ O
on -X- _ O
computational -X- _ O
resources -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
their -X- _ O
method -X- _ O
to -X- _ O
introduce -X- _ O
a -X- _ O
Multistage -X- _ B-HyperparameterName
Language -X- _ I-HyperparameterName
Sampling -X- _ I-HyperparameterName
algorithm -X- _ O
( -X- _ O
MLS -X- _ B-HyperparameterName
) -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
target -X- _ O
summaries -X- _ O
of -X- _ O
a -X- _ O
batch -X- _ O
are -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
use -X- _ O
an -X- _ O
exponent -X- _ O
smoothing -X- _ O
factor -X- _ O
α -X- _ B-HyperparameterName
and -X- _ O
normalize -X- _ O
the -X- _ O
probabilities -X- _ O

We -X- _ O
again -X- _ O
smooth -X- _ O
p -X- _ O
j|i -X- _ O
by -X- _ O
a -X- _ O
factor -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
obtain -X- _ O
the -X- _ O
normalized -X- _ O
probabilities -X- _ O

Using -X- _ O
the -X- _ O
probabilities -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
with -X- _ O
the -X- _ O
MLS -X- _ B-MethodName
algorithm -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O

Evaluating -X- _ O
Summaries -X- _ O
Across -X- _ O
Languages -X- _ O
A -X- _ O
sufficient -X- _ O
number -X- _ O
of -X- _ O
reference -X- _ O
samples -X- _ O
are -X- _ O
essential -X- _ O
for -X- _ O
the -X- _ O
reliable -X- _ O
evaluation -X- _ O
of -X- _ O
model-generated -X- _ O
summaries. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
many -X- _ O
CrossSum -X- _ B-DatasetName
language -X- _ O
pairs -X- _ O
, -X- _ O
even -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
are -X- _ O
small -X- _ O
, -X- _ O
let -X- _ O

Update -X- _ O
model -X- _ O
parameters -X- _ O
using -X- _ O
batch -X- _ O
alone -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
( -X- _ O
the -X- _ O
median -X- _ O
size -X- _ O
is -X- _ O
only -X- _ O
33 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
Japanese-Bengali -X- _ O
language -X- _ O
pair -X- _ O
has -X- _ O
34 -X- _ O
test -X- _ O
samples -X- _ O
only -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
too -X- _ O
few -X- _ O
for -X- _ O
reliable -X- _ O
evaluation. -X- _ O
But -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
in-language -X- _ O
6 -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
Japanese -X- _ O
and -X- _ O
Bengali -X- _ O
are -X- _ O
nearly -X- _ O
1,000. -X- _ O
Being -X- _ O
able -X- _ O
to -X- _ O
evaluate -X- _ O
against -X- _ O
reference -X- _ O
summaries -X- _ O
written -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
would -X- _ O
thus -X- _ O
alleviate -X- _ O
this -X- _ O
insufficiency -X- _ O
problem -X- _ O
by -X- _ O
leveraging -X- _ O
the -X- _ O
in-language -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language. -X- _ O
For -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
cross-lingual -X- _ O
similarity -X- _ O
metrics -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
lexical -X- _ O
overlap -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
unlike -X- _ O
ROUGE -X- _ B-MetricName
) -X- _ O
are -X- _ O
required. -X- _ O
Embedding-based -X- _ O
similarity -X- _ O
metrics -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
recently -X- _ O
gained -X- _ O
popularity. -X- _ O
We -X- _ O
draw -X- _ O
inspiration -X- _ O
from -X- _ O
them -X- _ O
and -X- _ O
design -X- _ O
a -X- _ O
similarity -X- _ O
metric -X- _ O
that -X- _ O
can -X- _ O
effectively -X- _ O
measure -X- _ O
similarity -X- _ O
across -X- _ O
languages -X- _ O
in -X- _ O
a -X- _ O
language-independent -X- _ O
manner. -X- _ O
We -X- _ O
consider -X- _ O
three -X- _ O
essential -X- _ O
factors -X- _ O
: -X- _ O
1. -X- _ O
Meaning -X- _ O
Similarity -X- _ O
: -X- _ O
The -X- _ O
generated -X- _ O
and -X- _ O
reference -X- _ O
summaries -X- _ O
should -X- _ O
convey -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
irrespective -X- _ O
of -X- _ O
their -X- _ O
languages. -X- _ O
Just -X- _ O
like -X- _ O
our -X- _ O
alignment -X- _ O
procedure -X- _ O
from -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
LaBSE -X- _ B-MethodName
to -X- _ O
compute -X- _ O
the -X- _ O
meaning -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
( -X- _ O
s -X- _ O
gen -X- _ O
) -X- _ O
and -X- _ O
reference -X- _ O
summary -X- _ O
( -X- _ O
s -X- _ O
where -X- _ O
emb -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
embedding -X- _ O
vector -X- _ O
output -X- _ O
of -X- _ O
LaBSE -X- _ B-MethodName
for -X- _ O
input -X- _ O
text -X- _ O
s -X- _ O
. -X- _ O

Language -X- _ O
Confidence -X- _ O
: -X- _ O
The -X- _ O
metric -X- _ O
should -X- _ O
identify -X- _ O
, -X- _ O
with -X- _ O
high -X- _ O
confidence -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
summary -X- _ O
is -X- _ O
indeed -X- _ O
being -X- _ O
generated -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
fastText -X- _ B-MethodName
language-ID -X- _ O
classifier -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
language -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
summary -X- _ O
and -X- _ O
define -X- _ O
the -X- _ O
Language -X- _ O
Confidence -X- _ O
( -X- _ O
LC -X- _ O
) -X- _ O
as -X- _ O
: -X- _ O
LC -X- _ O
( -X- _ O
s -X- _ O
gen -X- _ O
, -X- _ O
s -X- _ O
ref -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
if -X- _ O
L -X- _ O
ref -X- _ O
= -X- _ O
argmax -X- _ O
P -X- _ O
( -X- _ O
L -X- _ O
gen -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
L -X- _ O
gen -X- _ O
= -X- _ O
L -X- _ O
ref -X- _ O
) -X- _ O
, -X- _ O
otherwise -X- _ O
3. -X- _ O
Length -X- _ O
Penalty -X- _ O
: -X- _ O
Generated -X- _ O
summaries -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
unnecessarily -X- _ O
long -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
metric -X- _ O
should -X- _ O
penalize -X- _ O
long -X- _ O
summaries. -X- _ O
While -X- _ O
model-based -X- _ O
metrics -X- _ O
may -X- _ O
indicate -X- _ O
how -X- _ O
similar -X- _ O
a -X- _ O
generated -X- _ O
summary -X- _ O
is -X- _ O
to -X- _ O
its -X- _ O
reference -X- _ O
and -X- _ O
language -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
how -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
determine -X- _ O
its -X- _ O
brevity. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
brevity -X- _ O
penalty -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
length -X- _ O
penalty -X- _ O
: -X- _ O

We -X- _ O
finally -X- _ O
define -X- _ O
our -X- _ O
metric -X- _ O
, -X- _ O
Language-agnostic -X- _ B-MetricName
Summary -X- _ I-MetricName
Evaluation -X- _ I-MetricName
( -X- _ O
LaSE -X- _ B-MetricName
) -X- _ O
score -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Experiments -X- _ O
& -X- _ O
Discussions -X- _ O
One -X- _ O
model -X- _ O
capable -X- _ O
of -X- _ O
generating -X- _ O
summaries -X- _ O
in -X- _ O
any -X- _ O
target -X- _ O
language -X- _ O
for -X- _ O
an -X- _ O
input -X- _ O
article -X- _ O
from -X- _ O
any -X- _ O
source -X- _ O
language -X- _ O
is -X- _ O
highly -X- _ O
desirable. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
such -X- _ O
a -X- _ O
'many-to-many -X- _ O
' -X- _ O
model -X- _ O
( -X- _ O
m2m -X- _ O
in -X- _ O
brief -X- _ O
) -X- _ O
would -X- _ O
outperform -X- _ O
many-toone -X- _ O
( -X- _ O
m2o -X- _ O
) -X- _ O
or -X- _ O
one-to-many -X- _ O
( -X- _ O
o2m -X- _ O
) -X- _ O
models -X- _ O
7 -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
widely-used -X- _ O
practices -X- _ O
for -X- _ O
XLS -X- _ B-TaskName
( -X- _ O
Ladhak -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Perez-Beltrachini -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
establish -X- _ O
that -X- _ O
the -X- _ O
m2m -X- _ O
model -X- _ O
, -X- _ O
trained -X- _ O
in -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
samples -X- _ O
from -X- _ O
all -X- _ O
possible -X- _ O
language -X- _ O
pairs -X- _ O
using -X- _ O
the -X- _ O
MLS -X- _ B-MethodName
algorithm -X- _ O
from -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
consistently -X- _ O
outperforms -X- _ O
m2o -X- _ O
, -X- _ O
o2m -X- _ O
, -X- _ O
and -X- _ O
summarize-then-translate -X- _ O
( -X- _ O
s.+t. -X- _ O
) -X- _ O
baselines -X- _ O
given -X- _ O
equal -X- _ O
training -X- _ O
steps -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
proposed -X- _ O
m2m -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
five -X- _ O
different -X- _ O
m2o -X- _ B-MethodName
and -X- _ O
o2m -X- _ B-MethodName
models -X- _ O
using -X- _ O
five -X- _ O
highly -X- _ O
spoken -X- _ O
8 -X- _ O
and -X- _ O
typologically -X- _ O
diverse -X- _ O
pivot -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
'one -X- _ O
' -X- _ O
in -X- _ O
m2o -X- _ B-MethodName
and -X- _ O
o2m -X- _ B-MethodName
) -X- _ O
languages -X- _ O
: -X- _ O
English -X- _ O
, -X- _ O
Chinese -X- _ O
( -X- _ O
simplified -X- _ O
) -X- _ O
, -X- _ O
Hindi -X- _ O
, -X- _ O
Arabic -X- _ O
, -X- _ O
and -X- _ O
Russian. -X- _ O
As -X- _ O
another -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
summarizethen-translate -X- _ O
pipeline. -X- _ O
As -X- _ O
fine-tuning -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Xue -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
have -X- _ O
shown -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
monolingual -X- _ O
and -X- _ O
multilingual -X- _ O
text -X- _ O
summarization -X- _ O
( -X- _ O
Rothe -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Hasan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
fine-tune -X- _ O
each -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
pretrained -X- _ O
mT5 -X- _ O
( -X- _ O
Xue -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
by -X- _ O
providing -X- _ O
explicit -X- _ O
cross-lingual -X- _ O
supervision. -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
ROUGE-2 -X- _ B-MetricName
F1 -X- _ B-MetricName
and -X- _ O
LaSE -X- _ B-MetricName
in -X- _ O
Figures -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
9 -X- _ O
. -X- _ O
We -X- _ O
limit -X- _ O
our -X- _ O
evaluation -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
languages -X- _ O
supported -X- _ O
by -X- _ O
mT5 -X- _ B-MethodName
, -X- _ O
fastText -X- _ B-MethodName
, -X- _ O
and -X- _ O
M2M-100 -X- _ B-MethodName
( -X- _ O
the -X- _ O
translation -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
s.+t. -X- _ O
) -X- _ O
. -X- _ O

Results -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
m2m -X- _ B-MethodName
model -X- _ O
consistently -X- _ O
outperforms -X- _ O
m2o -X- _ B-MethodName
, -X- _ O
o2m -X- _ B-MethodName
, -X- _ O
and -X- _ O
s.+t. -X- _ B-MethodName
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
ROUGE-2 -X- _ B-MetricName
( -X- _ O
LaSE -X- _ B-MetricName
) -X- _ O
score -X- _ O
of -X- _ O
8.15 -X- _ B-MetricValue
( -X- _ O
57.15 -X- _ B-MetricValue
) -X- _ O
over -X- _ O
all -X- _ O
languages -X- _ O
tested -X- _ O
, -X- _ O
3.12 -X- _ B-MetricValue
( -X- _ O
9.02 -X- _ B-MetricValue
) -X- _ O
above -X- _ O
s.+t. -X- _ B-MethodName
Moreover -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
o2m -X- _ B-MethodName
models -X- _ O
on -X- _ O
language -X- _ O
pairs -X- _ O
where -X- _ O
the -X- _ O
pivots -X- _ O
are -X- _ O
the -X- _ O
targets -X- _ O
, -X- _ O
the -X- _ O
m2m -X- _ O
model -X- _ O
scores -X- _ O
1.80 -X- _ B-MetricValue
( -X- _ O
5.84 -X- _ B-MetricValue
) -X- _ O
over -X- _ O
m2os -X- _ B-MethodName
, -X- _ O
and -X- _ O
on -X- _ O
those -X- _ O
where -X- _ O
the -X- _ O
pivots -X- _ O
are -X- _ O
the -X- _ O
sources -X- _ O
, -X- _ O
6.52 -X- _ B-MetricValue
( -X- _ O
51.80 -X- _ B-MetricValue
) -X- _ O
over -X- _ O
o2ms -X- _ B-MethodName
. -X- _ O

Upon -X- _ O
inspection -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
the -X- _ O
m2o -X- _ O
models -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
non-trivial -X- _ O
summaries. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
o2m -X- _ O
models -X- _ O
completely -X- _ O
failed -X- _ O
to -X- _ O
produce -X- _ O
cross-lingual -X- _ O
summaries -X- _ O
, -X- _ O
performing -X- _ O
in-language -X- _ O
summarization -X- _ O
( -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
the -X- _ O
summary -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
its -X- _ O
input -X- _ O
article -X- _ O
) -X- _ O
for -X- _ O
all -X- _ O
targets. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
varying -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
hampers -X- _ O
the -X- _ O
decoder -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
generate -X- _ O
from -X- _ O
a -X- _ O
specific -X- _ O
language -X- _ O
, -X- _ O
possibly -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
vast -X- _ O
diversity -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
batch -X- _ O
( -X- _ O
discussed -X- _ O
further -X- _ O
in -X- _ O
Appendix -X- _ O
E -X- _ O
) -X- _ O
. -X- _ O
s.+t. -X- _ O
performed -X- _ O
well -X- _ O
on -X- _ O
high-resource -X- _ O
languages -X- _ O
but -X- _ O
poorly -X- _ O
on -X- _ O
lowresource -X- _ O
ones. -X- _ O
This -X- _ O
was -X- _ O
revealed -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
limitation -X- _ O
of -X- _ O
the -X- _ O
translation -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
pipeline -X- _ O
. -X- _ O

Zero-shot -X- _ O
Cross-lingual -X- _ O
Transfer -X- _ O
The -X- _ O
previous -X- _ O
experiments -X- _ O
were -X- _ O
done -X- _ O
in -X- _ O
a -X- _ O
fully -X- _ O
supervised -X- _ O
fashion. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
many -X- _ O
low-resource -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
samples -X- _ O
are -X- _ O
not -X- _ O
abundantly -X- _ O
available. -X- _ O
Hence -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
attractive -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
perform -X- _ O
zero-shot -X- _ O
cross-lingual -X- _ O
generation -X- _ O
( -X- _ O
Duan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
without -X- _ O
relying -X- _ O
on -X- _ O
any -X- _ O
labeled -X- _ O
examples -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
fine-tuned -X- _ O
mT5 -X- _ B-MethodName
with -X- _ O
only -X- _ O
the -X- _ O
inlanguage -X- _ O
samples -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
both -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
multilingual -X- _ O
fashion -X- _ O
and -X- _ O
, -X- _ O
during -X- _ O
inference -X- _ O
, -X- _ O
varied -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O
Unfortunately -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
totally -X- _ O
fails -X- _ O
at -X- _ O
generating -X- _ O
cross-lingual -X- _ O
summaries -X- _ O
and -X- _ O
performs -X- _ O
in-language -X- _ O
summarization -X- _ O
instead. -X- _ O
We -X- _ O
also -X- _ O
fine-tuned -X- _ O
m2o -X- _ B-MethodName
models -X- _ O
( -X- _ O
with -X- _ O
only -X- _ O
the -X- _ O
in-language -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
monolingual -X- _ O
fashion -X- _ O
and -X- _ O
ran -X- _ O
inference -X- _ O
in -X- _ O
a -X- _ O
zeroshot -X- _ O
setting -X- _ O
with -X- _ O
samples -X- _ O
from -X- _ O
other -X- _ O
languages -X- _ O
as -X- _ O
input. -X- _ O
Here -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
nontrivial -X- _ O
summaries -X- _ O
for -X- _ O
some -X- _ O
language -X- _ O
pairs -X- _ O
but -X- _ O
still -X- _ O
lag -X- _ O
behind -X- _ O
fully -X- _ O
supervised -X- _ O
models -X- _ O
by -X- _ O
a -X- _ O
significant -X- _ O
margin. -X- _ O
We -X- _ O
have -X- _ O
included -X- _ O
Figures -X- _ O
10 -X- _ O
and -X- _ O
11 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
to -X- _ O
illustrate -X- _ O
this -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
ran -X- _ O
inference -X- _ O
with -X- _ O
the -X- _ O
m2m -X- _ B-MethodName
model -X- _ O
on -X- _ O
distant -X- _ O
low-resource -X- _ O
language -X- _ O
pairs -X- _ O
that -X- _ O
were -X- _ O
absent -X- _ O
in -X- _ O
training. -X- _ O
Their -X- _ O
LaSE -X- _ B-MetricName
scores -X- _ O
were -X- _ O
substantially -X- _ O
below -X- _ O
supervised -X- _ O
pairs -X- _ O
, -X- _ O
meaning -X- _ O
zeroshot -X- _ O
transfer -X- _ O
in -X- _ O
supervised -X- _ O
multilingual -X- _ O
models -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
shows -X- _ O
weak -X- _ O
performance -X- _ O
. -X- _ O

Analysis -X- _ O
of -X- _ O
Results -X- _ O
Statistical -X- _ O
significance -X- _ O
While -X- _ O
the -X- _ O
scores -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
experiments -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
m2m -X- _ O
model -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
others -X- _ O
, -X- _ O
the -X- _ O
differences -X- _ O
are -X- _ O
very -X- _ O
close -X- _ O
in -X- _ O
many -X- _ O
language -X- _ O
pairs. -X- _ O
Therefore -X- _ O
, -X- _ O
a -X- _ O
statistical -X- _ O
significance -X- _ O
test -X- _ O
is -X- _ O
still -X- _ O
warranted -X- _ O
to -X- _ O
support -X- _ O
our -X- _ O
claim -X- _ O
further. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
experimented -X- _ O
on -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
the -X- _ O
Bootstrap -X- _ O
resampling -X- _ O
test -X- _ O
( -X- _ O
Koehn -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
m2m -X- _ O
model -X- _ O
against -X- _ O
the -X- _ O
best-performing -X- _ O
model -X- _ O
among -X- _ O
the -X- _ O
others -X- _ O
in -X- _ O
a -X- _ O
one -X- _ O
vs. -X- _ O
all -X- _ O
manner -X- _ O
: -X- _ O
if -X- _ O
m2m -X- _ O
has -X- _ O
the -X- _ O
best -X- _ O
( -X- _ O
ROUGE-2 -X- _ B-MetricName
/ -X- _ O
LaSE -X- _ B-MetricName
) -X- _ O
score -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
second-best -X- _ O
score -X- _ O
, -X- _ O
and -X- _ O
if -X- _ O
m2m -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
best -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
best. -X- _ O
Results -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.05 -X- _ O
) -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
reveal -X- _ O
that -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
42 -X- _ O
% -X- _ O
language -X- _ O
pairs -X- _ O
tested -X- _ O
, -X- _ O
m2m -X- _ O
is -X- _ O
significantly -X- _ O
better -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
less -X- _ O
than -X- _ O
10 -X- _ O
% -X- _ O
pairs -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
considerably -X- _ O
worse. -X- _ O
10 -X- _ O
This -X- _ O
provides -X- _ O
additional -X- _ O
evidence -X- _ O
in -X- _ O
support -X- _ O
of -X- _ O
our -X- _ O
claim -X- _ O
that -X- _ O
the -X- _ O
m2m -X- _ O
model -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
others -X- _ O
. -X- _ O

How -X- _ O
reliable -X- _ O
is -X- _ O
LaSE -X- _ B-MetricName
? -X- _ O
At -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
validated -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
LaSE -X- _ B-MetricName
by -X- _ O
showing -X- _ O
its -X- _ O
correlation -X- _ O
with -X- _ O
ROUGE-2. -X- _ B-MetricName
We -X- _ O
took -X- _ O
different -X- _ O
checkpoints -X- _ O
of -X- _ O
the -X- _ O
in-language -X- _ O
summarization -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
s.+t. -X- _ O
and -X- _ O
computed -X- _ O
ROUGE-2 -X- _ B-MetricName
and -X- _ O
LaSE -X- _ B-MetricName
for -X- _ O
the -X- _ O
nine -X- _ O
languages -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
for -X- _ O
each -X- _ O
checkpoint. -X- _ O
The -X- _ O
correlation -X- _ O
coefficients -X- _ O
of -X- _ O
the -X- _ O
calculated -X- _ O
scores -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
column -X- _ O
of -X- _ O
Table -X- _ O
2. -X- _ O
For -X- _ O
all -X- _ O
languages -X- _ O
( -X- _ O
from -X- _ O
high-to -X- _ O
low-resource -X- _ O
) -X- _ O
, -X- _ O
LaSE -X- _ B-MetricName
has -X- _ O
a -X- _ O
near-perfect -X- _ O
correlation -X- _ O
with -X- _ O
ROUGE-2 -X- _ B-MetricName
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
LaSE -X- _ B-MetricName
is -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
language-agnostic -X- _ O
and -X- _ O
can -X- _ O
even -X- _ O
be -X- _ O
computed -X- _ O
in -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
references -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
summaries -X- _ O
with -X- _ O
references -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
language -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
using -X- _ O
the -X- _ O
m2m -X- _ B-MethodName
model. -X- _ O
For -X- _ O
each -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
compute -X- _ O
the -X- _ O
standard -X- _ O
LaSE -X- _ B-MetricName
for -X- _ O
different -X- _ O
source -X- _ O
languages -X- _ O
( -X- _ O
denoted -X- _ O
as -X- _ O
LaSE-in-lang -X- _ B-MetricName
) -X- _ O
. -X- _ O
We -X- _ O
again -X- _ O
compute -X- _ O
LaSE -X- _ B-MetricName
after -X- _ O
swapping -X- _ O
the -X- _ O
reference -X- _ O
texts -X- _ O
with -X- _ O
the -X- _ O
references -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
11 -X- _ O
( -X- _ O
denoted -X- _ O
as -X- _ O
LaSE-out-lang -X- _ B-MetricName
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
show -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
variants -X- _ O
of -X- _ O
LaSE -X- _ B-MetricName
in -X- _ O
the -X- _ O
third -X- _ O
column -X- _ O
of -X- _ O
Table -X- _ O
2 -X- _ O
12 -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
language. -X- _ O
Results -X- _ O
show -X- _ O
a -X- _ O
substantial -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
variants -X- _ O
of -X- _ O
LaSE -X- _ B-MetricName
for -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O

From -X- _ O
these -X- _ O
two -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
conclude -X- _ O
that -X- _ O
LaSE -X- _ B-MetricName
is -X- _ O
an -X- _ O
ideal -X- _ O
metric -X- _ O
for -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
summarization -X- _ O
systems -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
in -X- _ O
a -X- _ O
language-independent -X- _ O
manner. -X- _ O
2021 -X- _ O
) -X- _ O
introduced -X- _ O
multiple -X- _ O
pretraining -X- _ O
objectives -X- _ O
specifically -X- _ O
tailored -X- _ O
to -X- _ O
cross-lingual -X- _ O
tasks -X- _ O
that -X- _ O
showed -X- _ O
improved -X- _ O
results -X- _ O
on -X- _ O
XLS. -X- _ B-TaskName
We -X- _ O
refer -X- _ O
our -X- _ O
readers -X- _ O
to -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
comprehensive -X- _ O
literature -X- _ O
review. -X- _ O
Until -X- _ O
recently -X- _ O
, -X- _ O
XLS -X- _ B-TaskName
was -X- _ O
limited -X- _ O
primarily -X- _ O
to -X- _ O
English-Chinese -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
benchmark -X- _ O
datasets. -X- _ O
To -X- _ O
promote -X- _ O
the -X- _ O
task -X- _ O
beyond -X- _ O
this -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
Ladhak -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
introduced -X- _ O
Wikilingua -X- _ O
, -X- _ O
a -X- _ O
large-scale -X- _ O
many-to-one -X- _ O
dataset -X- _ O
with -X- _ O
English -X- _ O
as -X- _ O
the -X- _ O
pivot -X- _ O
language -X- _ O
, -X- _ O
while -X- _ O
Perez-Beltrachini -X- _ O
and -X- _ O
Lapata -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
introduced -X- _ O
XWikis -X- _ O
, -X- _ O
containing -X- _ O
4 -X- _ O
languages -X- _ O
in -X- _ O
12 -X- _ O
directions -X- _ O
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2023 -X- _ O
) -X- _ O
explored -X- _ O
zeroshot -X- _ O
cross-lingual -X- _ O
summarization -X- _ O
by -X- _ O
prompting -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2023 -X- _ O
) -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
Chat-GPT -X- _ O
13 -X- _ O
, -X- _ O
GPT-4 -X- _ O
( -X- _ O
OpenAI -X- _ O
, -X- _ O
2023 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
BLOOMZ -X- _ O
( -X- _ O
Muennighoff -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O

Conclusion -X- _ O
& -X- _ O
Future -X- _ O
Works -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
presented -X- _ O
CrossSum -X- _ B-DatasetName
, -X- _ O
a -X- _ O
largescale -X- _ O
, -X- _ O
non-English-centric -X- _ O
XLS -X- _ B-TaskName
dataset -X- _ O
containing -X- _ O
1.68 -X- _ O
million -X- _ O
samples -X- _ O
in -X- _ O
1,500+ -X- _ O
language -X- _ O
pairs. -X- _ O
CrossSum -X- _ B-DatasetName
provides -X- _ O
the -X- _ O
first -X- _ O
publicly -X- _ O
available -X- _ O
XLS -X- _ B-TaskName
dataset -X- _ O
for -X- _ O
many -X- _ O
of -X- _ O
these -X- _ O
pairs. -X- _ O
Performing -X- _ O
a -X- _ O
limited-scale -X- _ O
human -X- _ O
evaluation -X- _ O
of -X- _ O
CrossSum -X- _ B-DatasetName
, -X- _ O
we -X- _ O
introduced -X- _ O
MLS -X- _ B-MethodName
, -X- _ O
a -X- _ O
multistage -X- _ O
sampling -X- _ O
algorithm -X- _ O
for -X- _ O
general-purpose -X- _ O
cross-lingual -X- _ O
generation -X- _ O
, -X- _ O
and -X- _ O
LaSE -X- _ O
, -X- _ O
a -X- _ O
language-agnostic -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
summaries -X- _ O
when -X- _ O
reference -X- _ O
summaries -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
available. -X- _ O
We -X- _ O
demonstrated -X- _ O
that -X- _ O
training -X- _ O
one -X- _ O
multilingual -X- _ O
model -X- _ O
can -X- _ O
help -X- _ O
towards -X- _ O
better -X- _ O
XLS -X- _ B-TaskName
than -X- _ O
baselines. -X- _ O
We -X- _ O
also -X- _ O
shed -X- _ O
light -X- _ O
on -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
perform -X- _ O
zero-shot -X- _ B-TaskName
and -X- _ I-TaskName
few-shot -X- _ I-TaskName
XLS -X- _ I-TaskName
with -X- _ O
CrossSum. -X- _ O
We -X- _ O
share -X- _ O
our -X- _ O
findings -X- _ O
and -X- _ O
resources -X- _ O
in -X- _ O
the -X- _ O
hopes -X- _ O
of -X- _ O
making -X- _ O
the -X- _ O
XLS -X- _ B-TaskName
research -X- _ O
community -X- _ O
more -X- _ O
inclusive -X- _ O
and -X- _ O
diverse -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
investigate -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
Cross-Sum -X- _ B-DatasetName
for -X- _ O
other -X- _ O
summarization -X- _ O
tasks -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
multidocument -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
multi-modal -X- _ O
summarization -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
also -X- _ O
like -X- _ O
to -X- _ O
explore -X- _ O
better -X- _ O
techniques -X- _ O
for -X- _ O
m2m -X- _ O
, -X- _ O
zeroshot -X- _ O
, -X- _ O
and -X- _ O
few-shot -X- _ O
cross-lingual -X- _ O
summarization -X- _ O
. -X- _ O

Limitations -X- _ O
Though -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
our -X- _ O
work -X- _ O
has -X- _ O
many -X- _ O
merits -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
its -X- _ O
limitations -X- _ O
must -X- _ O
be -X- _ O
acknowledged. -X- _ O
Despite -X- _ O
exhaustive -X- _ O
human -X- _ O
annotation -X- _ O
being -X- _ O
the -X- _ O
most -X- _ O
reliable -X- _ O
means -X- _ O
of -X- _ O
ensuring -X- _ O
the -X- _ O
maximum -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
had -X- _ O
to -X- _ O
resort -X- _ O
to -X- _ O
the -X- _ O
automatic -X- _ O
curation -X- _ O
of -X- _ O
CrossSum -X- _ B-DatasetName
due -X- _ O
to -X- _ O
the -X- _ O
enormous -X- _ O
scale -X- _ O
of -X- _ O
the -X- _ O
dataset. -X- _ O
As -X- _ O
identified -X- _ O
in -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
, -X- _ O
not -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
alignments -X- _ O
made -X- _ O
by -X- _ O
LaBSE -X- _ B-MethodName
are -X- _ O
correct. -X- _ O
They -X- _ O
are -X- _ O
primarily -X- _ O
summaries -X- _ O
describing -X- _ O
similar -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
having -X- _ O
a -X- _ O
substantial -X- _ O
degree -X- _ O
of -X- _ O
syntactic -X- _ O
or -X- _ O
semantic -X- _ O
similarity -X- _ O
) -X- _ O
but -X- _ O
non-identical -X- _ O
events. -X- _ O
LaBSE -X- _ B-MethodName
also -X- _ O
fails -X- _ O
to -X- _ O
penalize -X- _ O
numerical -X- _ O
mismatches -X- _ O
, -X- _ O
especially -X- _ O
if -X- _ O
the -X- _ O
summaries -X- _ O
depict -X- _ O
the -X- _ O
same -X- _ O
event -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
any -X- _ O
mistake -X- _ O
made -X- _ O
by -X- _ O
LaBSE -X- _ B-MethodName
in -X- _ O
the -X- _ O
curation -X- _ O
phase -X- _ O
may -X- _ O
propagate -X- _ O
to -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
using -X- _ O
CrossSum. -X- _ B-DatasetName
And -X- _ O
since -X- _ O
LaBSE -X- _ B-MethodName
is -X- _ O
a -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
LaSE -X- _ B-MetricName
metric -X- _ O
, -X- _ O
these -X- _ O
biases -X- _ O
may -X- _ O
remain -X- _ O
unidentified -X- _ O
by -X- _ O
LaSE -X- _ B-MethodName
in -X- _ O
the -X- _ O
evaluation -X- _ O
stage. -X- _ O
However -X- _ O
, -X- _ O
no -X- _ O
matter -X- _ O
which -X- _ O
automatic -X- _ O
method -X- _ O
we -X- _ O
use -X- _ O
, -X- _ O
there -X- _ O
will -X- _ O
be -X- _ O
such -X- _ O
frailties -X- _ O
in -X- _ O
these -X- _ O
extreme -X- _ O
cases. -X- _ O
Since -X- _ O
the -X- _ O
objective -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
not -X- _ O
to -X- _ O
scrutinize -X- _ O
the -X- _ O
pitfalls -X- _ O
of -X- _ O
LaBSE -X- _ B-MethodName
but -X- _ O
rather -X- _ O
to -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
means -X- _ O
of -X- _ O
curation -X- _ O
and -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
deem -X- _ O
LaBSE -X- _ B-MethodName
the -X- _ O
best -X- _ O
choice -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
extensive -X- _ O
language -X- _ O
coverage -X- _ O
and -X- _ O
empirical -X- _ O
performance -X- _ O
in -X- _ O
cross-lingual -X- _ O
mining -X- _ O
among -X- _ O
existing -X- _ O
alternatives -X- _ O
. -X- _ O

Ethical -X- _ O
Considerations -X- _ O
License -X- _ O
CrossSum -X- _ B-DatasetName
is -X- _ O
a -X- _ O
derivative -X- _ O
of -X- _ O
the -X- _ O
XL-Sum -X- _ B-DatasetName
dataset. -X- _ O
XL-Sum -X- _ B-DatasetName
has -X- _ O
been -X- _ O
released -X- _ O
under -X- _ O
the -X- _ O
Creative -X- _ O
Commons -X- _ O
Attribution-NonCommercial-ShareAlike -X- _ O
4.0 -X- _ O
International -X- _ O
License -X- _ O
( -X- _ O
CC -X- _ O
BY-NC-SA -X- _ O
4.0 -X- _ O
) -X- _ O
, -X- _ O
allowing -X- _ O
modifications -X- _ O
and -X- _ O
distributions -X- _ O
for -X- _ O
non-commercial -X- _ O
research -X- _ O
purposes. -X- _ O
We -X- _ O
are -X- _ O
adhering -X- _ O
to -X- _ O
the -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
license -X- _ O
and -X- _ O
releasing -X- _ O
CrossSum -X- _ B-DatasetName
under -X- _ O
the -X- _ O
same -X- _ O
license. -X- _ O
Generated -X- _ O
Text -X- _ O
All -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
use -X- _ O
the -X- _ O
mT5 -X- _ B-MethodName
model -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
multilingual -X- _ O
text -X- _ O
corpus. -X- _ O
For -X- _ O
a -X- _ O
text -X- _ O
generation -X- _ O
model -X- _ O
, -X- _ O
even -X- _ O
small -X- _ O
amounts -X- _ O
of -X- _ O
offensive -X- _ O
or -X- _ O
harmful -X- _ O
texts -X- _ O
in -X- _ O
pretraining -X- _ O
could -X- _ O
lead -X- _ O
to -X- _ O
dangerous -X- _ O
biases -X- _ O
in -X- _ O
generated -X- _ O
text -X- _ O
( -X- _ O
Luccioni -X- _ O
and -X- _ O
Viviano -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
can -X- _ O
potentially -X- _ O
generate -X- _ O
offensive -X- _ O
or -X- _ O
biased -X- _ O
content -X- _ O
learned -X- _ O
during -X- _ O
the -X- _ O
pretraining -X- _ O
phase -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
beyond -X- _ O
our -X- _ O
control. -X- _ O
Text -X- _ O
summarization -X- _ O
systems -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
generate -X- _ O
unfaithful -X- _ O
and -X- _ O
factually -X- _ O
incorrect -X- _ O
( -X- _ O
albeit -X- _ O
fluent -X- _ O
) -X- _ O
( -X- _ O
Maynez -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
texts. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
carefully -X- _ O
examining -X- _ O
the -X- _ O
potential -X- _ O
biases -X- _ O
before -X- _ O
considering -X- _ O
them -X- _ O
in -X- _ O
any -X- _ O
real-world -X- _ O
deployment -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
Annotators -X- _ O
were -X- _ O
hired -X- _ O
from -X- _ O
the -X- _ O
graduates -X- _ O
of -X- _ O
an -X- _ O
institute -X- _ O
that -X- _ O
provides -X- _ O
professional -X- _ O
training -X- _ O
for -X- _ O
many -X- _ O
languages -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
ones -X- _ O
evaluated -X- _ O
in -X- _ O
Section -X- _ O
3. -X- _ O
Each -X- _ O
annotator -X- _ O
was -X- _ O
given -X- _ O
around -X- _ O
200-250 -X- _ O
sequence -X- _ O
pairs -X- _ O
to -X- _ O
evaluate. -X- _ O
Each -X- _ O
annotation -X- _ O
took -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
one -X- _ O
and -X- _ O
a -X- _ O
half -X- _ O
minutes -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
approximately -X- _ O
5-6 -X- _ O
hours -X- _ O
for -X- _ O
annotating -X- _ O
the -X- _ O
whole -X- _ O
set. -X- _ O
Annotators -X- _ O
were -X- _ O
paid -X- _ O
hourly -X- _ O
per -X- _ O
the -X- _ O
standard -X- _ O
remuneration -X- _ O
of -X- _ O
bilingual -X- _ O
professionals -X- _ O
in -X- _ O
local -X- _ O
currency -X- _ O
. -X- _ O

Environmental -X- _ O
Impact -X- _ O
A -X- _ O
total -X- _ O
of -X- _ O
25 -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
this -X- _ O
work. -X- _ O
Each -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
for -X- _ O
about -X- _ O
three -X- _ O
days -X- _ O
on -X- _ O
a -X- _ O
4-GPU -X- _ O
Tesla -X- _ O
P100 -X- _ O
server. -X- _ O
Assuming -X- _ O
0.08 -X- _ O
kg -X- _ O
/ -X- _ O
kWh -X- _ O
carbon -X- _ O
emission -X- _ O
14 -X- _ O
, -X- _ O
less -X- _ O
than -X- _ O
175kg -X- _ O
of -X- _ O
carbon -X- _ O
was -X- _ O
released -X- _ O
into -X- _ O
the -X- _ O
environment -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
below -X- _ O
the -X- _ O
most -X- _ O
computationally -X- _ O
demanding -X- _ O
models -X- _ O
. -X- _ O

Appendix -X- _ O
A -X- _ O
Aligning -X- _ O
Summaries -X- _ O
using -X- _ O
LaBSE -X- _ B-MethodName
In -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
curated -X- _ O
CrossSum -X- _ B-DatasetName
by -X- _ O
aligning -X- _ O
parallel -X- _ O
summaries -X- _ O
in -X- _ O
different -X- _ O
languages. -X- _ O
It -X- _ O
might -X- _ O
be -X- _ O
argued -X- _ O
why -X- _ O
the -X- _ O
articles -X- _ O
themselves -X- _ O
were -X- _ O
not -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
alignment -X- _ O
process. -X- _ O
Initially -X- _ O
, -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
whole-article -X- _ O
embeddings. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
resulted -X- _ O
in -X- _ O
many -X- _ O
false-negative -X- _ O
alignments -X- _ O
, -X- _ O
where -X- _ O
similarity -X- _ O
scores -X- _ O
between -X- _ O
parallel -X- _ O
articles -X- _ O
across -X- _ O
languages -X- _ O
were -X- _ O
relatively -X- _ O
low -X- _ O
( -X- _ O
verified -X- _ O
manually -X- _ O
between -X- _ O
English -X- _ O
and -X- _ O
the -X- _ O
authors -X- _ O
' -X- _ O
native -X- _ O
languages -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
most -X- _ O
likely -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
512-token -X- _ O
limit -X- _ O
of -X- _ O
LaBSE -X- _ B-MethodName
and -X- _ O
different -X- _ O
sequence -X- _ O
lengths -X- _ O
of -X- _ O
those -X- _ O
articles -X- _ O
due -X- _ O
to -X- _ O
different -X- _ O
languages -X- _ O
having -X- _ O
different -X- _ O
subword -X- _ O
segmentation -X- _ O
fertility -X- _ O
( -X- _ O
Ács -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
would -X- _ O
entail -X- _ O
that -X- _ O
parallel -X- _ O
articles -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
might -X- _ O
be -X- _ O
truncated -X- _ O
at -X- _ O
different -X- _ O
locations -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
discrepancies -X- _ O
between -X- _ O
their -X- _ O
embeddings. -X- _ O
As -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
BUCC -X- _ O
evaluation -X- _ O
, -X- _ O
LaBSE -X- _ B-MethodName
is -X- _ O
well-suited -X- _ O
for -X- _ O
sentence-level -X- _ O
retrieval. -X- _ O
Since -X- _ O
summaries -X- _ O
are -X- _ O
good -X- _ O
representatives -X- _ O
of -X- _ O
entire -X- _ O
articles -X- _ O
, -X- _ O
we -X- _ O
finally -X- _ O
chose -X- _ O
summaries -X- _ O
as -X- _ O
our -X- _ O
candidates -X- _ O
for -X- _ O
the -X- _ O
alignment -X- _ O
. -X- _ O

C.1 -X- _ O
Choice -X- _ O
of -X- _ O
Pretrained -X- _ O
Model -X- _ O
Many -X- _ O
pretrained -X- _ O
multilingual -X- _ O
text-to-text -X- _ O
models -X- _ O
are -X- _ O
currently -X- _ O
available -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
mBART -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
CRISS -X- _ O
( -X- _ O
Tran -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
MARGE -X- _ O
, -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
mBART -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
are -X- _ O
pretrained -X- _ O
with -X- _ O
multilingual -X- _ O
objectives -X- _ O
, -X- _ O
CRISS -X- _ O
and -X- _ O
MARGE -X- _ O
are -X- _ O
pretrained -X- _ O
with -X- _ O
a -X- _ O
cross-lingual -X- _ O
one -X- _ O
, -X- _ O
which -X- _ O
better -X- _ O
suits -X- _ O
our -X- _ O
use -X- _ O
case. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
mT5 -X- _ B-MethodName
for -X- _ O
fine-tuning -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
broad -X- _ O
coverage -X- _ O
of -X- _ O
101 -X- _ O
languages -X- _ O
with -X- _ O
support -X- _ O
for -X- _ O
41 -X- _ O
of -X- _ O
the -X- _ O
45 -X- _ O
languages -X- _ O
from -X- _ O
CrossSum -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
only -X- _ O
15 -X- _ O
languages -X- _ O
in -X- _ O
mBART -X- _ O
or -X- _ O
CRISS -X- _ O
and -X- _ O
26 -X- _ O
in -X- _ O
MARGE -X- _ O
. -X- _ O

One -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
segment -X- _ O
the -X- _ O
documents -X- _ O
into -X- _ O
sentences -X- _ O
and -X- _ O
then -X- _ O
translate -X- _ O
them. -X- _ O
But -X- _ O
that -X- _ O
increases -X- _ O
the -X- _ O
compute -X- _ O
overhead -X- _ O
, -X- _ O
and -X- _ O
translations -X- _ O
suffer -X- _ O
from -X- _ O
loss -X- _ O
of -X- _ O
context. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
multilingual -X- _ O
summarization -X- _ O
model -X- _ O
( -X- _ O
Hasan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
coupled -X- _ O
with -X- _ O
the -X- _ O
multilingual -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
model -X- _ O
, -X- _ O
M2M-100 -X- _ O
( -X- _ O
Fan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
our -X- _ O
pipeline -X- _ O
. -X- _ O

C.2.1 -X- _ O
Multilingual -X- _ O
Summarization -X- _ O
The -X- _ O
pipeline -X- _ O
first -X- _ O
performs -X- _ O
in-language -X- _ O
summarization. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
own -X- _ O
model -X- _ O
for -X- _ O
summarization -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
released -X- _ O
by -X- _ O
Hasan -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
rendered -X- _ O
unusable -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
split. -X- _ O
We -X- _ O
extend -X- _ O
our -X- _ O
component -X- _ O
graphs -X- _ O
to -X- _ O
curate -X- _ O
the -X- _ O
in-language -X- _ O
dataset -X- _ O
splits. -X- _ O
We -X- _ O
consider -X- _ O
articles -X- _ O
having -X- _ O
no -X- _ O
parallel -X- _ O
counterpart -X- _ O
in -X- _ O
any -X- _ O
other -X- _ O
language -X- _ O
as -X- _ O
single -X- _ O
node -X- _ O
components -X- _ O
in -X- _ O
the -X- _ O
component -X- _ O
graph. -X- _ O
As -X- _ O
before -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
all -X- _ O
articles -X- _ O
originating -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
component -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
( -X- _ O
dev -X- _ O
/ -X- _ O
test -X- _ O
) -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
extending -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
in-language -X- _ O
splits -X- _ O
too. -X- _ O
We -X- _ O
then -X- _ O
train -X- _ O
the -X- _ O
multilingual -X- _ O
model -X- _ O
by -X- _ O
fine-tuning -X- _ O
mT5 -X- _ B-MethodName
with -X- _ O
the -X- _ O
in-language -X- _ O
splits -X- _ O
, -X- _ O
sampling -X- _ O
each -X- _ O
batch -X- _ B-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
samples -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
language -X- _ O
with -X- _ O
a -X- _ O
sampling -X- _ O
factor -X- _ O
of -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O

C.2.2 -X- _ O
Multilingual -X- _ O
Translation -X- _ O
For -X- _ O
multilingual -X- _ O
translation -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
M2M-100 -X- _ B-MethodName
( -X- _ O
Fan -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
418M -X- _ O
parameters -X- _ O
variant -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
many-to-many -X- _ O
multilingual -X- _ O
translation -X- _ O
model -X- _ O
, -X- _ O
with -X- _ O
support -X- _ O
for -X- _ O
37 -X- _ O
languages -X- _ O
from -X- _ O
CrossSum -X- _ O
. -X- _ O

C.3 -X- _ O
Many-to-One -X- _ O
( -X- _ O
m2o -X- _ B-MethodName
) -X- _ O
Model -X- _ O
Many-to-one -X- _ O
training -X- _ O
is -X- _ O
standard -X- _ O
for -X- _ O
evaluating -X- _ O
cross-lingual -X- _ O
summarization. -X- _ O
In -X- _ O
these -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
text -X- _ O
can -X- _ O
vary -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
remains -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
pivot -X- _ O
language. -X- _ O
Instead -X- _ O
of -X- _ O
sampling -X- _ O
all -X- _ O
samples -X- _ O
of -X- _ O
a -X- _ O
batch -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
8 -X- _ B-HyperparameterValue
minibatches -X- _ B-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
samples -X- _ B-HyperparameterName
using -X- _ O
a -X- _ O
sampling -X- _ O
factor -X- _ O
of -X- _ O
α -X- _ B-HyperparameterValue
= -X- _ O
0.25 -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
source -X- _ O
side -X- _ O
of -X- _ O
each -X- _ O
originating -X- _ O
from -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
Languages -X- _ O
are -X- _ O
ordered -X- _ O
by -X- _ O
the -X- _ O
language -X- _ O
taxonomy -X- _ O
from -X- _ O
Joshi -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
show -X- _ O
better -X- _ O
contrast -X- _ O
between -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
we -X- _ O
color -X- _ O
a -X- _ O
bubble -X- _ O
cyan -X- _ O
if -X- _ O
its -X- _ O
frequency -X- _ O
is -X- _ O
below -X- _ O
500 -X- _ O
( -X- _ O
1218 -X- _ O
pairs -X- _ O
) -X- _ O
, -X- _ O
red -X- _ O
for -X- _ O
500 -X- _ O
to -X- _ O
5000 -X- _ O
( -X- _ O
688 -X- _ O
pairs -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
blue -X- _ O
for -X- _ O
frequencies -X- _ O
exceeding -X- _ O
5000 -X- _ O
( -X- _ O
52 -X- _ O
pairs -X- _ O
) -X- _ O
. -X- _ O

a -X- _ O
single -X- _ O
language -X- _ O
while -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
remains -X- _ O
fixed. -X- _ O
We -X- _ O
then -X- _ O
merge -X- _ O
the -X- _ O
mini-batches -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
batch -X- _ O
and -X- _ O
update -X- _ O
the -X- _ O
model -X- _ O
parameters. -X- _ O
This -X- _ O
is -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
not -X- _ O
many -X- _ O
duplicates -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
batch -X- _ O
( -X- _ O
if -X- _ O
all -X- _ O
256 -X- _ B-HyperparameterValue
samples -X- _ B-HyperparameterName
of -X- _ O
a -X- _ O
batch -X- _ O
are -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
there -X- _ O
might -X- _ O
be -X- _ O
many -X- _ O
duplicates -X- _ O
as -X- _ O
many -X- _ O
language -X- _ O
pairs -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
256 -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
samples -X- _ I-HyperparameterName
) -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
still -X- _ O
benefits -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
low-resource -X- _ O
upsampling -X- _ O
. -X- _ O

C.4 -X- _ O
One-to-many -X- _ O
( -X- _ O
o2m -X- _ B-MethodName
) -X- _ O
Model -X- _ O
o2m -X- _ B-MethodName
models -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
m2o -X- _ B-MethodName
models -X- _ O
: -X- _ O
we -X- _ O
train -X- _ O
them -X- _ O
by -X- _ O
keeping -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
fixed -X- _ O
and -X- _ O
varying -X- _ O
the -X- _ O
target -X- _ O
language. -X- _ O
We -X- _ O
upsample -X- _ O
the -X- _ O
low-resource -X- _ O
target -X- _ O
languages -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
sampling -X- _ O
factor -X- _ O
of -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.25 -X- _ B-HyperparameterValue
and -X- _ O
merge -X- _ O
8 -X- _ B-HyperparameterValue
mini-batches -X- _ B-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
samples -X- _ B-HyperparameterName
each -X- _ O
, -X- _ O
analogous -X- _ O
to -X- _ O
m2o -X- _ B-MethodName
models -X- _ O
. -X- _ O

C.5 -X- _ O
Many-to-many -X- _ O
( -X- _ O
m2m -X- _ B-MethodName
) -X- _ O
Multistage -X- _ O
Model -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
model -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
Algorithm -X- _ O
1. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
standard -X- _ O
language -X- _ O
sampling -X- _ O
( -X- _ O
Conneau -X- _ O
( -X- _ O
marked -X- _ O
red -X- _ O
) -X- _ O
in -X- _ O
many-to-one -X- _ O
models -X- _ O
due -X- _ O
to -X- _ O
implicit -X- _ O
data -X- _ O
leakage. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
taking -X- _ O
the -X- _ O
issue -X- _ O
into -X- _ O
account -X- _ O
, -X- _ O
and -X- _ O
consequently -X- _ O
, -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
set -X- _ O
( -X- _ O
marked -X- _ O
blue -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
exhibit -X- _ O
any -X- _ O
unusual -X- _ O
spike -X- _ O
in -X- _ O
ROUGE-2. -X- _ B-MetricName
et -X- _ O
al. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
then -X- _ O
choose -X- _ O
the -X- _ O
source -X- _ O
based -X- _ O
on -X- _ O
that -X- _ O
decision. -X- _ O
We -X- _ O
use -X- _ O
batch -X- _ O
size -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
8 -X- _ B-HyperparameterValue
mini-batches -X- _ B-HyperparameterName
with -X- _ O
size -X- _ B-HyperparameterName
32 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
0.75 -X- _ B-HyperparameterValue
. -X- _ O

C.6 -X- _ O
Many-to-many -X- _ O
( -X- _ O
m2m -X- _ B-MethodName
) -X- _ O
Unistage -X- _ O
Model -X- _ O
This -X- _ O
algorithm -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
standard -X- _ O
language -X- _ O
sampling -X- _ O
, -X- _ O
the -X- _ O
difference -X- _ O
being -X- _ O
that -X- _ O
languages -X- _ O
are -X- _ O
sampled -X- _ O
as -X- _ O
pairs -X- _ O
from -X- _ O
all -X- _ O
possible -X- _ O
combinations. -X- _ O
Instead -X- _ O
of -X- _ O
sampling -X- _ O
one -X- _ O
language -X- _ O
pair -X- _ O
at -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
8 -X- _ B-HyperparameterValue
pairs -X- _ B-HyperparameterName
, -X- _ O
one -X- _ O
for -X- _ O
each -X- _ O
mini-batch -X- _ B-HyperparameterName
of -X- _ O
size -X- _ O
32. -X- _ B-HyperparameterValue
We -X- _ O
then -X- _ O
merge -X- _ O
the -X- _ O
mini-batches -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
batch -X- _ O
of -X- _ O
256 -X- _ B-HyperparameterValue
samples -X- _ B-HyperparameterName
before -X- _ O
updating -X- _ O
the -X- _ O
model -X- _ O
parameters. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
sampling -X- _ O
factor -X- _ O
of -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.25. -X- _ B-HyperparameterValue
In -X- _ O
all -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
discarded -X- _ O
a -X- _ O
language -X- _ O
pair -X- _ O
from -X- _ O
training -X- _ O
if -X- _ O
it -X- _ O
had -X- _ O
fewer -X- _ O
than -X- _ O
30 -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
samples -X- _ I-HyperparameterName
to -X- _ O
prevent -X- _ O
too -X- _ O
many -X- _ O
duplicates -X- _ O
in -X- _ O
a -X- _ O
mini-batch. -X- _ O
The -X- _ O
training -X- _ O
was -X- _ O
done -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
in-language -X- _ O
samples -X- _ O
. -X- _ O

D.1 -X- _ O
Training -X- _ O
Setups -X- _ O
Fine-tuning -X- _ O
generation -X- _ O
models -X- _ O
is -X- _ O
computeintensive -X- _ O
, -X- _ O
and -X- _ O
due -X- _ O
to -X- _ O
computational -X- _ O
limitations -X- _ O
, -X- _ O
we -X- _ O
fine-tune -X- _ O
all -X- _ O
pretrained -X- _ O
models -X- _ O
for -X- _ O
25k -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
an -X- _ O
effective -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
roughly -X- _ O
takes -X- _ O
about -X- _ O
three -X- _ O
days -X- _ O
on -X- _ O
a -X- _ O
4-GPU -X- _ O
NVIDIA -X- _ O
P100 -X- _ O
server. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
base -X- _ O
variant -X- _ O
of -X- _ O
mT5 -X- _ B-MethodName
, -X- _ O
having -X- _ O
250k -X- _ B-HyperparameterValue
vocabulary -X- _ B-HyperparameterName
, -X- _ O
768 -X- _ B-HyperparameterValue
embedding -X- _ B-HyperparameterName
and -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
2048 -X- _ B-HyperparameterValue
FFN -X- _ B-HyperparameterName
size -X- _ O
, -X- _ O
with -X- _ O
580M -X- _ B-HyperparameterValue
parameters. -X- _ B-HyperparameterName
We -X- _ O
limit -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
512 -X- _ B-HyperparameterValue
and -X- _ O
output -X- _ O
to -X- _ O
84 -X- _ B-HyperparameterValue
tokens. -X- _ B-HyperparameterName
All -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
respective -X- _ O
subsets -X- _ O
of -X- _ O
the -X- _ O
CrossSum -X- _ B-DatasetName
training -X- _ O
set -X- _ O
. -X- _ O

D.2 -X- _ O
Inference -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
jump-start -X- _ O
the -X- _ O
decoder -X- _ O
with -X- _ O
language-specific -X- _ O
BOS -X- _ O
( -X- _ O
beginning -X- _ O
of -X- _ O
sequence -X- _ O
) -X- _ O
tokens -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
at -X- _ O
the -X- _ O
first -X- _ O
decoding -X- _ O
step -X- _ O
for -X- _ O
guiding -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
generate -X- _ O
summaries -X- _ O
in -X- _ O
the -X- _ O
intended -X- _ O
target -X- _ O
language. -X- _ O
We -X- _ O
use -X- _ O
beam -X- _ B-MethodName
search -X- _ I-MethodName
( -X- _ O
Medress -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
1977 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
4 -X- _ B-HyperparameterValue
and -X- _ O
use -X- _ O
a -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
( -X- _ O
Wu -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
of -X- _ O
0.6 -X- _ B-HyperparameterValue
. -X- _ O

E -X- _ O
Ablation -X- _ O
Studies -X- _ O
We -X- _ O
make -X- _ O
several -X- _ O
design -X- _ O
choices -X- _ O
in -X- _ O
the -X- _ O
multistage -X- _ O
sampling -X- _ O
algorithm. -X- _ O
We -X- _ O
break -X- _ O
them -X- _ O
into -X- _ O
two -X- _ O
main -X- _ O
decisions -X- _ O
: -X- _ O

1. -X- _ O
Making -X- _ O
mini-batches -X- _ O
and -X- _ O
sampling -X- _ O
the -X- _ O
language -X- _ O
pair -X- _ O
for -X- _ O
each -X- _ O
mini-batch -X- _ O
. -X- _ O

2. -X- _ O
Keeping -X- _ O
either -X- _ O
the -X- _ O
source -X- _ O
or -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
fixed -X- _ O
for -X- _ O
each -X- _ O
batch -X- _ O
. -X- _ O

To -X- _ O
verify -X- _ O
that -X- _ O
these -X- _ O
choices -X- _ O
indeed -X- _ O
affect -X- _ O
performance -X- _ O
positively -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
five -X- _ O
different -X- _ O
models -X- _ O
for -X- _ O
ablation -X- _ O
: -X- _ O

1. -X- _ O
Sampling -X- _ O
the -X- _ O
language -X- _ O
pair -X- _ O
in -X- _ O
mini-batches -X- _ O
in -X- _ O
one -X- _ O
stage -X- _ O
only -X- _ O
and -X- _ O
then -X- _ O
merging -X- _ O
them -X- _ O
into -X- _ O
large -X- _ O
batches -X- _ O
before -X- _ O
updating -X- _ O
model -X- _ O
parameters -X- _ O
: -X- _ O
m2m-unistage -X- _ B-MethodName
. -X- _ O

2. -X- _ O
Sampling -X- _ O
the -X- _ O
language -X- _ O
pair -X- _ O
with -X- _ O
large -X- _ O
batches -X- _ O
of -X- _ O
256 -X- _ B-HyperparameterValue
samples -X- _ B-HyperparameterName
without -X- _ O
mini-batching -X- _ O
: -X- _ O
m2mlarge -X- _ B-MethodName
. -X- _ O

3. -X- _ O
Multistage -X- _ O
sampling -X- _ O
keeping -X- _ O
only -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
fixed -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
: -X- _ O
m2m-tgt -X- _ B-MethodName
[ -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
] -X- _ O
. -X- _ O

4. -X- _ O
Multistage -X- _ O
sampling -X- _ O
keeping -X- _ O
only -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
fixed -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
: -X- _ O
m2m-src -X- _ B-MethodName
; -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
complement -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O

5. -X- _ O
Multistage -X- _ O
sampling -X- _ O
keeping -X- _ O
either -X- _ O
the -X- _ O
source -X- _ O
or -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
fixed -X- _ O
( -X- _ O
with -X- _ O
equal -X- _ O
probability -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
batch -X- _ O
: -X- _ O
m2m-src-tgt -X- _ B-MethodName
. -X- _ I-MethodName

We -X- _ O
benchmark -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
language -X- _ O
pairs -X- _ O
done -X- _ O
previously -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
mean -X- _ O
ROUGE-2 -X- _ B-MetricName
and -X- _ O
LaSE -X- _ B-MetricName
scores -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O

Model -X- _ O
Scores -X- _ O
Significance -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
m2m-large -X- _ B-MethodName
, -X- _ I-MethodName
the -X- _ O
standard -X- _ O
m2m -X- _ B-MethodName
model -X- _ O
, -X- _ O
has -X- _ O
the -X- _ O
best -X- _ O
average -X- _ O
ROUGE-2 -X- _ B-MetricName
/ -X- _ O
LaSE -X- _ B-MetricName
scores -X- _ O
among -X- _ O
all -X- _ O
m2m -X- _ B-MethodName
variants. -X- _ O
This -X- _ O
begs -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
whether -X- _ O
our -X- _ O
proposed -X- _ O
multistage -X- _ O
sampling -X- _ O
is -X- _ O
, -X- _ O
after -X- _ O
all -X- _ O
, -X- _ O
needed -X- _ O
or -X- _ O
not. -X- _ O
But -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
m2m-tgt -X- _ B-MethodName
model -X- _ O
do -X- _ O
not -X- _ O
fall -X- _ O
much -X- _ O
below. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
statistical -X- _ O
significance -X- _ O
test -X- _ O
results -X- _ O
of -X- _ O
all -X- _ O
m2m -X- _ B-MethodName
models -X- _ O
, -X- _ O
comparing -X- _ O
them -X- _ O
against -X- _ O
m2o -X- _ B-MethodName
, -X- _ O
o2m -X- _ B-MethodName
, -X- _ O
and -X- _ O
s.+t. -X- _ O
in -X- _ O
one -X- _ O
vs. -X- _ O
all -X- _ O
manner -X- _ O
. -X- _ O

Significance -X- _ O
results -X- _ O
paint -X- _ O
a -X- _ O
different -X- _ O
picture -X- _ O
: -X- _ O
m2m-tgt -X- _ B-MethodName
triumphs -X- _ O
over -X- _ O
all -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
getting -X- _ O
significantly -X- _ O
better -X- _ O
results -X- _ O
on -X- _ O
42 -X- _ O
% -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
more -X- _ O
than -X- _ O
double -X- _ O
the -X- _ O
m2m-large -X- _ B-MethodName
model. -X- _ O
We -X- _ O
inspected -X- _ O
the -X- _ O
results -X- _ O
individually -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
notably -X- _ O
better -X- _ O
on -X- _ O
language -X- _ O
pairs -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
adequately -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O
m2mtgt -X- _ B-MethodName
performs -X- _ O
comparatively -X- _ O
worse -X- _ O
on -X- _ O
high-resource -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
think -X- _ O
is -X- _ O
a -X- _ O
fair -X- _ O
compromise -X- _ O
to -X- _ O
uplift -X- _ O
low-resource -X- _ O
ones. -X- _ O
As -X- _ O
m2m-large -X- _ B-MethodName
can -X- _ O
sample -X- _ O
a -X- _ O
pair -X- _ O
only -X- _ O
once -X- _ O
per -X- _ O
batch -X- _ O
, -X- _ O
it -X- _ O
fails -X- _ O
to -X- _ O
incorporate -X- _ O
many -X- _ O
language -X- _ O
pairs -X- _ O
due -X- _ O
to -X- _ O
them -X- _ O
having -X- _ O
insufficient -X- _ O
participation -X- _ O
during -X- _ O
training. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
multistage -X- _ O
sampling -X- _ O
algorithm -X- _ O
performs -X- _ O
well -X- _ O
in -X- _ O
this -X- _ O
regard -X- _ O
by -X- _ O
sampling -X- _ O
in -X- _ O
two -X- _ O
stages -X- _ O
. -X- _ O

While -X- _ O
m2m-tgt -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
the -X- _ O
rest -X- _ O
, -X- _ O
m2msrc -X- _ B-MethodName
falls -X- _ O
behind -X- _ O
all -X- _ O
other -X- _ O
models -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin. -X- _ O
This -X- _ O
phenomenon -X- _ O
also -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
trend -X- _ O
as -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
, -X- _ O
where -X- _ O
o2m -X- _ B-MethodName
models -X- _ O
failed -X- _ O
at -X- _ O
generating -X- _ O
cross-lingual -X- _ O
summaries. -X- _ O
This -X- _ O
is -X- _ O
also -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
our -X- _ O
hypothesis -X- _ O
made -X- _ O
, -X- _ O
as -X- _ O
m2m-src -X- _ B-MethodName
and -X- _ O
m2mtgt -X- _ B-MethodName
mimic -X- _ O
the -X- _ O
training -X- _ O
settings -X- _ O
of -X- _ O
the -X- _ O
o2m -X- _ B-MethodName
and -X- _ O
m2o -X- _ B-MethodName
models -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
batch -X- _ O
level. -X- _ O
The -X- _ O
m2msrc-tgt -X- _ B-MethodName
is -X- _ O
the -X- _ O
middle -X- _ O
ground -X- _ O
between -X- _ O
m2m-src -X- _ B-MethodName
and -X- _ O
m2m-tgt -X- _ B-MethodName
and -X- _ O
, -X- _ O
likewise -X- _ O
, -X- _ O
scores -X- _ O
between -X- _ O
these -X- _ O
two. -X- _ O
In -X- _ O
our -X- _ O
opinion -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
dynamics -X- _ O
between -X- _ O
the -X- _ O
m2o -X- _ B-MethodName
( -X- _ O
m2m-tgt -X- _ B-MethodName
) -X- _ O
and -X- _ O
o2m -X- _ B-MethodName
( -X- _ O
m2m-src -X- _ B-MethodName
) -X- _ O
models -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
finding -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
studied -X- _ O
in -X- _ O
depth -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
research -X- _ O
direction -X- _ O
in -X- _ O
future -X- _ O
works. -X- _ O
B2. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
license -X- _ O
or -X- _ O
terms -X- _ O
for -X- _ O
use -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
distribution -X- _ O
of -X- _ O
any -X- _ O
artifacts -X- _ O
? -X- _ O

