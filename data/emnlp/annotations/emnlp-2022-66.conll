-DOCSTART-
Learning O
to O
Adapt O
to O
Low-Resource B-TaskName
Paraphrase I-TaskName
Generation I-TaskName

Paraphrase B-TaskName
generation I-TaskName
is O
a O
longstanding O
NLP O
task O
and O
achieves O
great O
success O
with O
the O
aid O
of O
large O
corpora. O
However O
, O
transferring O
a O
paraphrasing O
model O
to O
another O
domain O
encounters O
the O
problem O
of O
domain O
shifting O
especially O
when O
the O
data O
is O
sparse. O
At O
the O
same O
time O
, O
widely O
using O
large O
pre-trained O
language O
models O
( O
PLMs O
) O
faces O
the O
overfitting O
problem O
when O
training O
on O
scarce O
labeled O
data. O
To O
mitigate O
these O
two O
issues O
, O
we O
propose O
, O
LAPA B-MethodName
, O
an O
effective O
adapter O
for O
PLMs O
optimized O
by O
meta-learning. O
LAPA B-MethodName
has O
three-stage O
training O
on O
three O
types O
of O
related O
resources O
to O
solve O
this O
problem O
: O
1. O
pre-training O
PLMs O
on O
unsupervised O
corpora O
, O
2. O
inserting O
an O
adapter O
layer O
and O
meta-training O
on O
source O
domain O
labeled O
data O
, O
and O
3. O
fine-tuning O
adapters O
on O
a O
small O
amount O
of O
target O
domain O
labeled O
data. O
This O
method O
enables O
paraphrase O
generation O
models O
to O
learn O
basic O
language O
knowledge O
first O
, O
then O
learn O
the O
paraphrasing O
task O
itself O
later O
, O
and O
finally O
adapt O
to O
the O
target O
task. O
Our O
experimental O
results O
demonstrate O
that O
LAPA B-MethodName
achieves O
state-of-the-art O
in O
supervised O
, O
unsupervised O
, O
and O
low-resource O
settings O
on O
three O
benchmark O
datasets. O
With O
only O
2 O
% O
of O
trainable O
parameters O
and O
1 O
% O
labeled O
data O
of O
the O
target O
task O
, O
our O
approach O
can O
achieve O
a O
competitive O
performance O
with O
previous O
work O
. O

Introduction O
Paraphrase B-TaskName
generation I-TaskName
can O
comprehend O
a O
sentence O
and O
generate O
another O
with O
the O
same O
semantics O
but O
with O
variations O
in O
lexicon O
or O
syntax O
, O
which O
has O
various O
applications O
on O
downstream O
tasks O
including O
query O
rewriting O
( O
Dong O
et O
al. O
, O
2017 O
) O
, O
data O
augmentation O
( O
Iyyer O
et O
al. O
, O
2018 O
) O
and O
language O
model O
pre-training O
( O
Lewis O
et O
al. O
, O
2020a O
) O
. O
Conventional O
approaches O
( O
Prakash O
et O
al. O
, O
2016 O
; O
Chowdhury O
et O
al. O
, O
2022 O
) O
model O
the O
paraphrase B-TaskName
generation I-TaskName
as O
a O
supervised O
encoding-decoding O
problem O
, O
inspired O
by O
machine O
translation O
systems. O
However O
, O
the O
success O
of O
these O
methods O
often O
relies O
on O
a O
large O
number O
of O
parallel O
paraphrases O
, O
whose O
collection O
is O
timeconsuming O
and O
requires O
a O
lot O
of O
domain O
knowledge. O
Therefore O
, O
in O
real O
scenarios O
with O
a O
small O
amount O
of O
parallel O
data O
, O
the O
model O
suffers O
from O
performance O
drops O
facing O
domain O
gaps. O
This O
phenomenon O
, O
known O
as O
domain O
shift O
problem O
( O
Pan O
and O
Yang O
, O
2009 O
) O
, O
comes O
from O
the O
representation O
gap O
between O
training O
and O
testing O
domains O
with O
different O
writing O
styles O
or O
forms O
. O

To O
tackle O
this O
problem O
, O
unsupervised O
methods O
such O
as O
editing-based O
approaches O
( O
Bowman O
et O
al. O
, O
2016 O
; O
Miao O
et O
al. O
, O
2019 O
) O
or O
reinforcement O
learning O
( O
Li O
et O
al. O
, O
2018 O
; O
Siddique O
et O
al. O
, O
2020 O
) O
, O
and O
weakly-supervised O
methods O
such O
as O
retrievalenhanced O
( O
Ding O
et O
al. O
, O
2021 O
; O
Yin O
et O
al. O
, O
2022 O
) O
or O
prompt-based O
do O
not O
introduce O
or O
only O
introduce O
a O
small O
number O
of O
supervised O
signals O
, O
which O
limits O
their O
performance O
such O
that O
underperforms O
supervised O
methods. O
In O
fact O
, O
largescale O
unlabeled O
corpus O
data O
( O
UCD O
) O
and O
labeled O
source O
domain O
data O
( O
LSDD O
) O
, O
as O
well O
as O
a O
few O
labeled O
target O
domain O
data O
( O
LTDD O
) O
, O
can O
be O
easily O
achieved. O
Therefore O
, O
we O
propose O
a O
new O
three-stage O
learning O
paradigm O
: O
pre-training O
, O
meta-learning O
, O
and O
fine-tuning O
, O
aiming O
to O
leverage O
the O
pre-trained O
knowledge O
on O
UCD O
, O
source O
domain O
knowledge O
on O
LSDD O
, O
and O
adapt O
to O
target O
domain O
on O
LSDD O
to O
improve O
the O
performance O
of O
low-resource O
paraphrase O
generation. O
In O
order O
to O
successfully O
implement O
this O
learning O
paradigm O
, O
we O
propose O
a O
simple O
yet O
effective O
model O
which O
combined O
pre-trained O
language O
model O
( O
PLM O
) O
and O
MAML O
( O
Finn O
et O
al. O
, O
2017 O
) O
, O
named O
Learning O
to O
Adapt O
to O
low-resource B-MethodName
PAraphrase I-MethodName
generation I-MethodName
( O
LAPA B-MethodName
) O
. O
Specifically O
, O
before O
meta-learning O
, O
we O
insert O
an O
adapter O
layer O
into O
each O
transformer O
layer O
of O
PLM. O
An O
adapter O
layer O
is O
composed O
of O
a O
few O
parameters O
of O
feedforward O
layer O
and O
residual O
connection. O
During O
meta-training O
and O
fine-tuning O
, O
only O
the O
adapter O
layer O
and O
normalization O
layer O
are O
trainable. O
Parameter O
freezing O
and O
residual O
connection O
can O
retain O
the O
prior O
knowledge O
of O
PLM O
to O
avoid O
negative O
transfer O
effects. O
Smaller-scale O
parameter O
updating O
can O
prevent O
MAML O
from O
gradient O
explosion O
or O
diminishing O
problems O
when O
the O
number O
of O
MAML O
inner O
loop O
iterations O
and O
model O
depth O
increase O
( O
Antoniou O
et O
al. O
, O
2019 O
) O
or O
training O
data O
is O
extremely O
scarce O
. O

Overall O
, O
we O
hold O
the O
idea O
that O
paraphrasing O
is O
a O
fundamental O
ability O
of O
human O
beings. O
The O
paraphrase O
model O
should O
not O
rely O
on O
domain O
and O
seen O
data. O
Therefore O
, O
we O
are O
committed O
to O
characterizing O
the O
basic O
ability O
of O
the O
paraphrase O
model O
, O
obtaining O
gains O
from O
each O
domain O
, O
and O
applying O
it O
to O
a O
specific O
domain. O
Our O
contributions O
are O
summarized O
as O
follows O
: O

• O
We O
define O
a O
novel O
three O
stages O
learning O
paradigm O
for O
low-resource B-TaskName
paraphrase I-TaskName
generation I-TaskName
in O
data O
scarcity O
scenarios O
. O

• O
We O
propose O
that O
LAPA B-MethodName
implement O
this O
learning O
paradigm O
, O
which O
transferred O
the O
PLM O
knowledge O
and O
source O
domain O
knowledge O
to O
complete O
the O
low-resource O
learning O
in O
the O
target O
domain O
quickly O
and O
with O
high O
quality O
. O

• O
The O
supervised O
, O
unsupervised O
and O
weakly O
supervised O
experimental O
results O
of O
LAPA B-MethodName
on O
three O
benchmark O
datasets O
achieve O
state-of-theart O
( O
SOTA O
) O
. O
LAPA B-MethodName
with O
only O
2 O
% O
of O
trainable O
parameters O
and O
1 O
% O
target O
task O
labeled O
data O
can O
achieve O
a O
competitive O
performance O
with O
previous O
works O
. O

Related O
Work O
While O
the O
paraphrase O
generation O
performance O
is O
greatly O
improved O
with O
various O
supervised O
techniques O
( O
Zhao O
et O
al. O
, O
2008 O
; O
Prakash O
et O
al. O
, O
2016 O
; O
Egonmwan O
and O
Chali O
, O
2019 O
; O
Cao O
and O
Wan O
, O
2020 O
; O
Hosking O
and O
Lapata O
, O
2021 O
; O
Chowdhury O
et O
al. O
, O
2022 O
) O
, O
there O
are O
few O
studies O
regarding O
the O
lowresource O
setting. O
West O
et O
al. O
( O
2021 O
) O
and O
Meng O
et O
al. O
( O
2021 O
) O
proposed O
novel O
unsupervised O
paraphrasing O
strategies O
by O
data O
augmentation O
based O
on O
reflective O
decoding O
or O
diverse O
decoding. O
Ding O
et O
al. O
( O
2021 O
) O
and O
Yin O
et O
al. O
( O
2022 O
) O
achieved O
improvements O
on O
various O
low-resource O
datasets O
with O
retrieved O
data O
and O
meta O
reinforcement O
learning. O
However O
, O
these O
studies O
only O
use O
a O
single O
large O
corpus O
for O
training O
the O
full O
PLM O
, O
which O
suffers O
from O
domainshifting O
problems O
( O
Wang O
et O
al. O
, O
2019 O
) O
. O
Besides O
, O
under O
the O
extreme O
low-resource O
setting O
, O
directly O
fine-tuning O
the O
full O
PLM O
will O
cause O
an O
over-fitting O
problem O
( O
Antoniou O
et O
al. O
, O
2019 O
) O
. O
Meta-learning O
helps O
improve O
low-resource O
performance O
in O
various O
recent O
studies O
, O
such O
as O
image O
classification O
( O
Soh O
et O
al. O
, O
2020 O
) O
, O
vehicle O
tracking O
and O
natural O
language O
processing O
( O
Park O
et O
al. O
, O
2021 O
; O
Chen O
and O
Shuai O
, O
2021 O
; O
Hong O
and O
Jang O
, O
2022 O
) O
. O
Finn O
et O
al. O
( O
2017 O
) O
proposed O
a O
meta O
learner O
named O
MAML B-MethodName
, O
which O
uses O
other O
example O
tasks O
to O
learn O
how O
to O
effectively O
initialize O
a O
basic O
learner O
, O
which O
can O
be O
quickly O
generalized O
to O
new O
tasks. O
Adapter O
modules O
have O
been O
mainly O
used O
for O
parameter-efficient O
and O
quick O
fine-tuning O
of O
a O
basic O
PLMs O
to O
new O
tasks O
( O
Houlsby O
et O
al. O
, O
2019 O
; O
Bapna O
and O
Firat O
, O
2019 O
; O
Pfeiffer O
et O
al. O
, O
2020Pfeiffer O
et O
al. O
, O
, O
2021. O
Our O
paper O
proposes O
to O
incorporate O
meta-learning O
approaches O
to O
realize O
multi-domain O
migration O
and O
task O
adapter O
to O
realize O
parameter O
effective O
transfer O
learning O
( O
i.e. O
, O
limited O
trainable O
parameters O
) O
to O
mitigate O
the O
above O
problems O
of O
paraphrase O
generation O
. O

3 O
The O
Approach O

Learning O
Paradigm O
As O
shown O
in O
Figure O
1 O
, O
the O
workflow O
of O
our O
learning O
paradigm O
including O
three O
stages O
: O
1. O
Backbone O
model O
pre-training O
on O
large O
unlabeled O
corpora O
2. O
Adapter O
model O
meta-training O
on O
large O
source O
corpora O
using O
the O
meta-learning O
and O
3. O
Adapter O
model O
fine-tuning O
on O
target O
corpora O
and O
evaluate O
model O
performance. O
The O
prior O
knowledge O
K O
pri O
comes O
from O
first O
two O
stages O
: O
pre-training O
and O
meta-learning. O
We O
denote O
our O
backbone O
model O
by O
f O
( O
θ O
) O
with O
parameters O
θ. O
The O
first O
stage O
is O
pretraining O
on O
unlabeled O
corpora O
D O
pre O
, O
and O
we O
get O
f O
( O
θ O
pre O
) O
. O
The O
second O
stage O
is O
meta-training O
on O
adapter O
model O
f O
[ O
θ O
pre O
, O
Φ O
] O
with O
additional O
parameters O
Φ O
and O
frozen O
θ O
pre O
on O
related O
source O
corpora O
D O
src O
, O
and O
we O
got O
f O
[ O
θ O
pre O
, O
Φ O
src O
] O
. O
Finally O
, O
we O
initialize O
the O
adapter O
model O
with O
[ O
θ O
pre O
, O
Φ O
src O
] O
and O
finetune O
Φ O
src O
on O
the O
target O
corpus O
D O
tgt O
to O
obtain O
a O
target O
model O
f O
[ O
θ O
pre O
, O
Φ O
tgt O
] O
which O
are O
model O
parameters O
after O
target O
adapter O
, O
i.e. O
, O
the O
posterior O
knowledge O
K O
por O
. O

Backbone O
Model O
Because O
PLM O
is O
equipped O
with O
prior O
knowledge O
K O
pri O
and O
exhibits O
strong O
capabilities O
in O
a O
range O
of O
different O
generative O
tasks O
, O
we O
choose O
the O
pretrained B-MethodName
BART I-MethodName
( O
Lewis O
et O
al. O
, O
2020b O
) O
as O
the O
backbone O
model O
for O
paraphrase O
generation. O
Specifically O
, O
given O
a O
labeled O
paraphrase O
pair O
i O
= O
( O
x O
, O
ŷ O
) O
, O
where O
x O
= O
[ O
x O
1 O
, O
. O
. O
. O
, O
x O
N O
] O
, O
ŷ O
= O
[ O
ŷ O
1 O
, O
. O
. O
. O
, O
ŷ O
M O
] O
, O
and O
inputting O
x O
, O
the O
model O
has O
produced O
a O
predicted O
segment O
sequence O
y O
< O
t O
= O
[ O
y O
1 O
, O
. O
. O
. O
, O
y O
t−1 O
] O
before O
time O
t O
, O
then O
the O
probability O
that O
the O
token O
generated O
at O
time O
t O
is O
y O
t O
is O
p O
( O
y O
t O
|y O
< O
t O
, O
x O
, O
θ O
) O
. O
The O
model O
is O
optimized O
by O
minimizing O
the O
negative O
log-likelihood O
: O

L O
i O
( O
f O
( O
θ O
) O
) O
= O
− O
M O
t=1 O
log O
p O
( O
ŷ O
t O
|y O
< O
t O
, O
x O
, O
θ O
) O
. O

Adapter B-MethodName
Model I-MethodName
The O
adapter O
model O
is O
obtained O
by O
inserting O
the O
adapter O
layer O
into O
each O
transformer O
layer O
of O
the O
backbone O
model. O
An O
adapter O
layer O
is O
a O
bottlenecked O
feed-forward O
network O
consisting O
of O
a O
downproject O
layer O
, O
a O
nonlinearity O
function O
and O
an O
upproject O
layer. O
In O
addition O
, O
a O
skip O
connection O
layer O
from O
input O
to O
output O
prevents O
the O
noised O
initialization O
from O
interference O
with O
the O
training O
initially. O
For O
the O
adapter O
in O
layer O
l O
, O
the O
function O
can O
be O
formulated O
as O
: O
Adapter O
( O
z O
l O
) O
= O
W O
l O
u O
ReLU O
( O
W O
l O
d O
z O
l O
) O
+ O
z O
l O
where O
z O
l O
represents O
the O
inputs O
of O
the O
adapter O
in O
layer O
l. O
Besides O
, O
the O
normalization O
layers O
are O
trainable O
and O
initialized O
from O
the O
previous O
training O
stage O
. O

Meta-Learning O
The O
second O
stage O
is O
adapter O
model O
meta O
traning O
based O
on O
MAML B-MethodName
( O
Finn O
et O
al. O
, O
2017 O
) O
. O
The O
learning O
process O
is O
shown O
in O
Algorithm O
1. O
First O
, O
we O
freeze O
the O
backbone O
model O
parameters O
θ O
pre O
that O
have O
been O
pre-trained O
in O
the O
pre-training O
stage O
, O
then O
, O
add O
new O
adapters O
with O
parameters O
Φ O
to O
get O
adapter O
model O
f O
[ O
θ O
pre O
, O
Φ O
] O
. O
Based O
on O
Algorithm O
1 O
, O
we O
first O
complete O
the O
meta-learning O
of O
the O
adapter O
model O
on O
the O
source O
corpus O
D O
src O
to O
help O
the O
adapters O
Φ O
find O
the O
initialization O
parameters O
Φ O
src O
suitable O
for O
paraphrase O
generation O
to O
adapt O
faster O
target O
task. O
At O
this O
Compute O
adapted O
parameters O
with O
gradient O
descent O
: O

[ O
θ O
, O
Φ O
] O
= O
[ O
θ O
, O
Φ O
] O
− O
α∇ O
Φ O
L O
i O
( O
f O
[ O
θ O
, O
Φ O
] O
) O
8 O
: O
end O
for O
9 O
: O
Update O
[ O
θ O
, O
Φ O
] O
← O
[ O
θ O
, O
Φ O
] O
− O
β∇ O
Φ O
T O
i O
∼p O
( O
T O
) O
L O
i O
( O
f O
[ O
θ O
, O
Φ O
] O

Datasets O
We O
conducted O
experiments O
on O
Quora B-DatasetName
1 I-DatasetName
, O
Twitter B-DatasetName
( O
Lan O
et O
al. O
, O
2017 O
) O
and O
MSCOCO B-DatasetName
( O
Lin O
et O
al. O
, O
2014 O
) O
benchmark O
datasets O
, O
and O
followed O
the O
same O
setting O
in O
previous O
works O
( O
Lin O
et O
al. O
, O
2014 O
; O
Liu O
et O
al. O
, O
2020 O
; O
Ding O
et O
al. O
, O
2021 O
) O
. O
For O
meta-learning O
, O
we O
choose O
a O
different O
source O
task O
's O
labeld O
train-set O
from O
the O
target O
task O
to O
randomly O
construct O
meta O
tasks. O
Appendix O
Table O
4 O
describes O
more O
details O
. O

Baselines O
Supervised O
methods O
are O
trained O
with O
all O
parallel O
sentences O
of O
target O
task. O
Unsupervised O
baselines O
( O
Lewis O
et O
al. O
, O
2020b O
) O
. O
Like O
our O
work O
, O
they O
all O
used O
BART B-MethodName
as O
PLM. O
To O
compare O
the O
performance O
of O
our O
method O
against O
the O
previous O
works O
, O
we O
use O
BLEU B-MetricName
( O
Papineni O
et O
al. O
, O
2002 O
) O
, O
iBLEU B-MetricName
( O
Sun O
and O
Zhou O
, O
2012 O
) O
and O
ROUGE B-MetricName
( O
Hovy O
et O
al. O
, O
2006 O
) O
metrics. O
All O
metrics O
are O
computed O
between O
the O
generated O
and O
the O
reference O
paraphrases O
in O
the O
test O
set O
( O
Kumar O
et O
al. O
, O
2020 O
) O
. O
We O
also O
separately O
analyze O
the O
impact O
of O
target O
task O
Example O
Input O
Can O
we O
ever O
store O
energy O
produced O
in O
lightning O
? O

Experimental O
Results O
How O
does O
a O
pencil O
and O
a O
liquid O
eyeliner O
differ O
? O

How O
come O
there O
's O
no O
physical O
evidence O
for O
sea O
dragons O
existing O
if O
they O
're O
the O
largestanimal O
in O
the O
sea. O
Table O
2 O
: O
Examples O
of O
the O
generated O
paraphrases O
on O
Quora B-DatasetName
dataset. O
We O
highlight O
the O
key O
phrases O
in O
the O
paraphrases O
generated O
and O
use O
wavy O
underline O
to O
show O
the O
matched O
parts O
between O
LAPA B-MethodName
and O
reference O
. O

labeled O
data O
scale O
under O
low-resource O
setting. O
Figure O
2 O
shows O
the O
experimental O
results O
on O
the O
Quora B-DatasetName
dataset. O
It O
can O
be O
conclused O
that O
LAPA B-MethodName
has O
a O
significant O
effect O
compared O
with O
BART B-MethodName
under O
the O
same O
small O
data O
size. O
LAPA B-MethodName
can O
achieve O
the O
effect O
of O
89 B-MetricValue
% I-MetricValue
to O
93 B-MetricValue
% I-MetricValue
of O
the O
full O
amount O
of O
data O
when O
not O
using O
any O
target O
task O
labeled O
data O
; O
when O
using O
a O
very O
small O
amount O
of O
data O
such O
as O
0.5k O
( O
i.e O
0.5 O
% O
of O
the O
full O
data O
) O
, O
it O
can O
be O
improved O
to O
94 B-MetricValue
% I-MetricValue
to O
96 B-MetricValue
% I-MetricValue
; O
when O
the O
amount O
of O
data O
increases O
to O
10k O
( O
i.e O
10 O
% O
of O
the O
full O
data O
) O
, O
the O
performance O
is O
almost O
the O
same O
as O
the O
full O
amount O
of O
data O
100k. O
It O
should O
be O
pointed O
out O
that O
which O
dataset O
is O
selected O
as O
the O
source O
data O
can O
not O
have O
a O
substantial O
impact O
on O
the O
migration O
results O
, O
as O
shown O
in O
Figure O
3. O
The O
results O
independent O
of O
the O
source O
dataset O
prove O
that O
LAPA B-MethodName
can O
learn O
the O
paraphrasing O
task O
itself O
on O
any O
dataset O
, O
so O
it O
has O
strong O
adaptability O
to O
the O
target O
task. O
We O
conduct O
an O
ablation O
study O
with O
three O
variants O
under O
the O
low-resource O
setting O
of O
the O
Quora B-DatasetName
dataset O
to O
investigate O
the O
contribution O
of O
each O
component O
in O
the O
proposed O
method. O
The O
experimental O
results O
are O
shown O
in O
Table O
3. O
We O
can O
get O
: O
first O
, O
using O
pre-trained B-MethodName
BART I-MethodName
can O
get O
good O
results O
; O
second O
, O
by O
adding O
the O
source O
task O
dataset O
for O
pre-trained B-MethodName
BART I-MethodName
, O
the O
knowledge O
of O
the O
source O
domain O
can O
be O
effectively O
learned O
, O
thereby O
improving O
the O
performance O
of O
the O
model O
in O
the O
target O
domain O
; O
third O
, O
adding O
our O
proposed O
meta-learning O
framework O
can O
again O
effectively O
improve O
the O
speed O
and O
quality O
of O
learning O
the O
source O
domain O
( O
LAPA B-MethodName
only O
has O
2.8 O
% O
training O
parameters O
compared O
with O
BART B-MethodName
) O
and O
achieve O
the O
best O
performance O
. O

Case O
Study O
Table O
2 O
lists O
some O
paraphrases O
generated O
by O
LAPA B-MethodName
and O
BART B-MethodName
with O
different O
experimental O
settings. O
We O
can O
observe O
that O
paraphrases O
produced O
by O
LAPA B-MethodName
are O
not O
only O
grammatically O
correct O
but O
preserve O
the O
semantics O
of O
Input O
more O
completely O
, O
and O
the O
expression O
is O
closer O
to O
Reference O
than O
the O
other O
methods. O
This O
benefits O
from O
the O
fact O
that O
our O
LAPA B-MethodName
approach O
can O
make O
full O
use O
of O
source O
domain O
data O
and O
task O
features O
, O
and O
better O
preserve O
the O
prior O
knowledge O
of O
PLM O
, O
so O
as O
to O
adapt O
to O
new O
target O
tasks O
quickly O
and O
efficiently O
. O

Conclusion O
In O
this O
work O
, O
we O
investigate O
the O
problem O
of O
paraphrase B-TaskName
generation I-TaskName
under I-TaskName
the I-TaskName
low-resource I-TaskName
setting I-TaskName
and O
propose O
a O
simple O
yet O
effective O
approach O
LAPA. B-MethodName
We O
effectively O
combine O
transfer O
learning O
and O
meta-learning O
by O
using O
adapter O
modules O
as O
the O
bridge. O
Whether O
in O
supervised O
, O
unsupervised O
or O
low-resource O
setting O
, O
the O
results O
that O
our O
approach O
achieves O
the O
SOTA O
results O
on O
benchmark O
datasets. O
In O
the O
future O
, O
we O
plan O
to O
explore O
how O
to O
choose O
a O
smaller O
but O
suitable O
high-quality O
source O
corpus O
for O
learning O
in O
the O
source O
domain O
to O
improve O
the O
effect O
of O
transferring O
to O
the O
target O
domain O
, O
because O
not O
all O
source O
domain O
data O
has O
a O
positive O
effect. O
Second O
, O
we O
plan O
to O
extend O
this O
framework O
to O
other O
AI O
fields O
to O
solve O
low-resource O
problems O
in O
other O
scenarios O
and O
enable O
more O
industrial O
applications O
. O

Limitations O
The O
major O
limitation O
of O
present O
study O
is O
the O
need O
for O
source O
domain O
annotated O
data O
that O
can O
adapt O
to O
the O
target O
domain. O
Because O
this O
is O
the O
source O
of O
data O
for O
the O
knowledge O
of O
the O
learning O
task O
itself O
, O
it O
can O
not O
be O
avoided. O
In O
the O
real O
world O
, O
we O
can O
find O
it O
from O
public O
free O
datasets O
, O
exchange O
it O
commercially O
with O
other O
institutions O
, O
or O
annotate O
a O
batch O
of O
raw O
data O
ourselves O
as O
a O
cold O
start O
to O
solve O
this O
problem. O
Secondly O
, O
this O
study O
also O
has O
insufficient O
research O
on O
related O
variables. O
Due O
to O
the O
limitation O
of O
time O
and O
article O
length O
, O
we O
have O
not O
been O
able O
to O
study. O
These O
findings O
provide O
the O
following O
insights O
for O
future O
research O
: O
What O
is O
the O
lower O
bound O
of O
the O
amount O
of O
source O
domain O
data O
that O
can O
be O
well O
adapted O
to O
the O
target O
task O
? O
Whether O
we O
can O
apply O
weak O
supervision O
, O
data O
augmentation O
and O
other O
methods O
to O
create O
source O
domain O
data O
? O
How O
to O
select O
high-quality O
source O
domain O
data O
to O
get O
a O
better O
adapter O
model O
? O
We O
leave O
these O
questions O
to O
future O
research. O
Twitter O
The O
twitter O
URL O
paraphrasing O
corpus O
is O
built O
by O
Lan O
et O
al. O
( O
2017 O
) O
for O
paraphrase O
identification. O
We O
follow O
the O
setting O
in O
Li O
et O
al. O
( O
2018 O
) O
, O
Kazemnejad O
et O
al. O
( O
2020 O
) O
and O
Siddique O
et O
al. O
( O
2020 O
) O
. O

The O
detailed O
dataset O
statistics O
are O
summarized O
in O
Table O
4 O
. O

A.2 O
Evaluation O
Details O
To O
make O
a O
fair O
and O
comprehensive O
assessment O
, O
we O
follow O
the O
same O
experiment O
setting O
of O
each O
comparison O
work O
( O
Li O
et O
al. O
, O
2018 O
; O
Liu O
et O
al. O
, O
2020 O
; O
Ding O
et O
al. O
, O
2021 O
) O
and O
conduct O
the O
comparison O
respectively. O
For O
data O
preprocessing O
, O
all O
the O
sentences O
are O
lower O
cased O
, O
and O
truncate O
all O
sentences O
to O
up O
to O
20 O
words. O
< O
s O
> O
and O
< O
/ O
s O
> O
are O
spliced O
to O
the O
front O
and O
back O
end O
of O
the O
sentence O
as O
start O
and O
end O
markers O
. O

For O
evaluation O
metrics O
, O
we O
use O
BLEU B-MetricName
, O
i-BLEU B-MetricName
and O
ROUGE B-MetricName
that O
have O
been O
widely O
used O
in O
the O
previous O
work O
to O
measure O
the O
quality O
of O
the O
paraphrases. O
The O
i-BLUE B-MetricName
aims O
to O
measure O
the O
diversity O
of O
expression O
in O
the O
generated O
paraphrases O
by O
penalizing O
copying O
words O
from O
input O
sentences. O
Specifically O
, O
we O
follow O
the O
unsupervised O
paraphrase O
generation O
baselines O
and O
set O
the O
balancing B-HyperparameterName
parameter I-HyperparameterName
α B-HyperparameterName
= O
0.9 B-HyperparameterName
. O

A.3 O
Implementation O
Our O
experiments O
were O
conducted O
with O
PyToch O
on O
NVIDIA O
Tesla O
V100 O
16GB O
GPU. O
Following O
the O
comparison O
methods O
, O
we O
used O
BART-large B-MethodName
as O
the O
pre-trained O
language O
model O
and O
use O
its O
pre-trained O
parameters. O
For O
adapter O
modules O
, O
the O
hidden B-HyperparameterName
size I-HyperparameterName
is O
128. B-HyperparameterValue
For O
meta-training O
, O
unless O
otherwise O
specified O
, O
a O
meta O
batch O
includes O
3 B-HyperparameterValue
tasks B-HyperparameterName
, O
and O
the O
batch B-HyperparameterName
size I-HyperparameterName
of O
each O
task O
is O
10. B-HyperparameterValue
Both O
basic O
learners O
and O
meta O
learners O
use O
the O
AdamW O
( O
Loshchilov O
and O
Hutter O
, O
2019 O
) O
optimizer O
for O
optimization O
, O
and O
the O
learning B-HyperparameterName
rate I-HyperparameterName
is O
set O
by O
grid O
search O
in O
1e-5 B-HyperparameterValue
, O
5e-5 B-HyperparameterValue
, O
1e-6 B-HyperparameterValue
and O
5e-6. B-HyperparameterValue
The O
internal B-HyperparameterName
gradient I-HyperparameterName
step I-HyperparameterName
size I-HyperparameterName
is O
4 B-HyperparameterValue
, O
and O
the O
whole O
model O
has O
enough O
step O
size O
for O
training. O
For O
meta O
verification O
, O
we O
use O
a O
corpus O
excluded O
from O
the O
source O
task O
and O
the O
target O
task. O
For O
fine-tuning O
, O
we O
use O
validation O
set O
to O
select O
the O
best O
model O
for O
metrics O
calculation O
. O

